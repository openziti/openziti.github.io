"use strict";(self.webpackChunkopen_ziti=self.webpackChunkopen_ziti||[]).push([[1477],{30010:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"/articles","metadata":{"permalink":"/blog/articles","source":"@site/blog/articles.md","title":"Articles","description":"Here you\'ll find articles that cover various topics related to developing","date":"2023-01-26T20:49:40.000Z","formattedDate":"January 26, 2023","tags":[],"readingTime":0.35,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"nextItem":{"title":"Building the Ziti C SDK and Sample Apps for arm (BeagleBone)","permalink":"/blog/c-sdk-on-beaglebone"}},"content":"Here you\'ll find articles that cover various topics related to developing\\napplications with Ziti.\\n\\n## Topics\\n\\n* [Ziti Up and Running on BeagleBone](./c-sdk-on-beaglebone.md)\\n* [Bootstrapping Trust](./bootstrapping-trust/part-01.encryption-everywhere.md)\\n\\n## [Zitifications](./zitification/index.md)\\n\\nA Zitification is any open-source project that has been modified to use the OpenZiti Edge SDK for client or server connectivity, or both. Zitified apps are bound to an identity instead of an address.\\n\\n* [Prometheus](./zitification/prometheus/part1.md)\\n* [Kubernetes](./zitification/kubernetes/index.md)\\n* [__SSH__](./zitification/zitifying-ssh/index.md)\\n* [__SCP__](./zitification/zitifying-scp/index.md)"},{"id":"/c-sdk-on-beaglebone","metadata":{"permalink":"/blog/c-sdk-on-beaglebone","source":"@site/blog/c-sdk-on-beaglebone.md","title":"Building the Ziti C SDK and Sample Apps for arm (BeagleBone)","description":"This article walks you through building the Ziti C SDK for Linux-arm and running","date":"2023-01-26T20:49:40.000Z","formattedDate":"January 26, 2023","tags":[],"readingTime":5.645,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"prevItem":{"title":"Articles","permalink":"/blog/articles"},"nextItem":{"title":"Bootstrapping Trust","permalink":"/blog/bootstrapping-trust/part-01.encryption-everywhere"}},"content":"This article walks you through building the Ziti C SDK for Linux-arm and running\\nthe wttr sample application on a [BeagleBone SanCloud](https://beagleboard.org/enhanced).\\n\\n## Configure the Host System\\n\\nThis article uses an Ubuntu 19.10 virtual machine as a development host because it\'s\\nrelatively easy to install a functional toolchain that targets arm-linux.\\n\\n    devbox$ sudo apt-get install gcc-arm-linux-gnueabihf g++-arm-linux-gnueabihf \\\\\\n        binutils-arm-linux-gnueabihf gdb-multiarch cmake git\\n\\n## Build the SDK and Sample Applications\\n\\n\\n    devbox$ git clone --recurse-submodules https://github.com/netfoundry/ziti-sdk-c.git\\n    Cloning into \'ziti-sdk-c\'...\\n    remote: Enumerating objects: 77, done.\\n    remote: Counting objects: 100% (77/77), done.\\n    remote: Compressing objects: 100% (50/50), done.\\n    remote: Total 1287 (delta 35), reused 51 (delta 24), pack-reused 1210\\n    Receiving objects: 100% (1287/1287), 475.44 KiB | 4.85 MiB/s, done.\\n    ...\\n\\n    devbox$ cd ziti-sdk-c\\n    devbox$ mkdir build-Linux-arm\\n    devbox$ cd build-Linux-arm\\n    devbox$ cmake -DCMAKE_TOOLCHAIN_FILE=../toolchains/Linux-arm.cmake ..\\n    project version: 0.9.2.1 (derived from git)\\n    -- The C compiler identification is GNU 9.2.1\\n    -- The CXX compiler identification is GNU 9.2.1\\n    -- Check for working C compiler: /usr/bin/arm-linux-gnueabihf-gcc\\n    ...\\n\\n    $ make\\n    [  1%] Building C object deps/uv-mbed/deps/libuv/CMakeFiles/uv_a.dir/src/fs-poll.c.o\\n    [  1%] Building C object deps/uv-mbed/deps/libuv/CMakeFiles/uv_a.dir/src/idna.c.o\\n    [  2%] Building C object deps/uv-mbed/deps/libuv/CMakeFiles/uv_a.dir/src/inet.c.o\\n    [  2%] Building C object deps/uv-mbed/deps/libuv/CMakeFiles/uv_a.dir/src/random.c.o\\n    ...\\n    [ 99%] Building C object programs/sample_wttr/CMakeFiles/sample_wttr.dir/sample_wttr.c.o\\n    [ 99%] Linking C executable sample_wttr\\n    [ 99%] Built target sample_wttr\\n    [100%] Built target sample-host\\n\\n\\nWhen `make` completes, you\'ll have statically linked binaries for the SDK\'s sample applications.\\n\\n## Set up a Ziti Network\\n\\nFor this article we\'ll use a Ziti Edge Developer Edition to run our network. Follow\\nthe [Ziti Network Quickstart](/docs/learn/quickstarts/network/).\\n\\n### Create the \\"demo-weather\\" Service\\n\\nThe sample_wttr application accesses a service named \\"demo-weather\\", so we\'ll create\\nthat service now. Log in to your Ziti Edge Developer Edition web UI and follow the\\nsteps:\\n\\n1. On the left side nav bar, click \\"Edge Services\\"\\n2. In the top right corner of the screen click the \\"plus\\" image to add a new service\\n3. Choose a name for the service. Enter \\"demo-weather\\"\\n4. Choose Router \\"ziti-gw01\\"\\n5. For Endpoint Service choose:\\n    * protocol = tcp\\n    * host = wttr.in\\n    * port = 80\\n6. Click save\\n\\n## Upload the Artifacts to Your BeagleBone\\n\\nAt this point we have created all of the artifacts that are needed for running the\\nsample application:\\n\\n- The \\"sample_wttr\\" executable\\n- The Ziti identity json file (e.g. \\"NewUser.json\\")\\n\\nNow we need to upload these artifacts to the BeagleBone. The scp command shown here\\nassumes that:\\n\\n - You are in the `build-Linux-arm` subdirectory where the `make` command was executed above.\\n - Your BeagleBone is running sshd and has an IP address of 192.168.2.2 which\\n   can be reached from your development host\\n - The Ziti identity json file that was created when you followed the Ziti Network Quickstart\\n   was downloaded to your ~/Downloads directory.\\n\\n\\n    devbox$ scp ./programs/sample_wttr/sample_wttr root@192.168.2.2:.\\n    $ scp ~/Downloads/NewUser.json ./programs/sample_wttr/sample_wttr debian@192.168.2.2:.\\n    NewUser.json                                  100% 6204     2.5MB/s   00:00\\n    sample_wttr                                   100% 2434KB   5.4MB/s   00:00\\n\\n\\n## Run the Application\\n\\nNow we\'re ready to log into the BeagleBone and run the sample application.\\nLet\'s go!\\n\\n    ubuntu@beaglebone:~$ ./sample_wttr ./NewUser.json\\n    [        0.000] INFO    library/ziti.c:173 NF_init(): ZitiSDK version 0.9.2.1-local @de37e6f(wttr-sample-shutdown-cleanup) starting at (2019-09-05T22:35:12.259)\\n    [        0.000] INFO    library/ziti.c:195 NF_init_with_tls(): ZitiSDK version 0.9.2.1-local @de37e6f(wttr-sample-shutdown-cleanup)\\n    /home/scarey/repos/github.com/netfoundry/ziti-sdk-c/deps/uv-mbed/src/http.c:315 ERR TLS handshake error \\n    /home/scarey/repos/github.com/netfoundry/ziti-sdk-c/deps/uv-mbed/src/http.c:153 WARN received -103 (software caused connection abort)\\n    [        0.210] ERROR   library/ziti.c:433 version_cb(): failed to get controller version from ec2-54-164-120-24.compute-1.amazonaws.com:1280 CONTROLLER_UNAVAILABLE(software caused connection abort)\\n    [        0.210] WARN    library/ziti_ctrl.c:49 code_to_error(): unmapped error code: CONTROLLER_UNAVAILABLE\\n    [        0.210] ERROR   library/ziti.c:419 session_cb(): failed to login: CONTROLLER_UNAVAILABLE[-11](software caused connection abort)\\n    ERROR: status => WTF: programming error\\n    ubuntu@beaglebone:~# \\n\\nOops. Actually The Ziti SDK verifies the certificate from the Ziti Edge Controller,\\nso we need to set the clock on the BeagleBone to a time/date that is within the\\nvalid range of the certificate. Might as well set the clock to the current time:\\n\\n    ubuntu@beaglebone:~# sudo rdate time.nist.gov\\n    Wed Mar 18 15:46:56 2020\\n\\nAnd _now_ we are ready to run the application:\\n\\n    ubuntu@beaglebone:~$ ./sample_wttr ./NewUser.json\\n    [        0.000] INFO    library/ziti.c:173 NF_init(): ZitiSDK version 0.9.2.1-local @de37e6f(wttr-sample-shutdown-cleanup) starting at (2020-03-18T15:46:57.536)\\n    [        0.000] INFO    library/ziti.c:195 NF_init_with_tls(): ZitiSDK version 0.9.2.1-local @de37e6f(wttr-sample-shutdown-cleanup)\\n    [        0.554] INFO    library/ziti.c:438 version_cb(): connected to controller ec2-54-164-120-24.compute-1.amazonaws.com:1280 version v0.9.0(ea556fc18740 2020-02-11 16:09:08)\\n    [        0.696] INFO    library/connect.c:180 connect_get_service_cb(): got service[demo-weather] id[cc90410f-1017-4d23-977a-3695cb58f4e8]\\n    [        0.810] INFO    library/connect.c:209 connect_get_net_session_cb(): got session[d89bfdd8-c7e5-42ff-a39f-63056eeb3a82] for service[demo-weather]\\n    [        0.810] INFO    library/channel.c:148 ziti_channel_connect(): opening new channel for ingress[tls://ec2-54-164-120-24.compute-1.amazonaws.com:3022] ch[0]\\n    sending HTTP request\\n    request success: 99 bytes sent\\n    HTTP/1.1 200 OK\\n    Server: nginx/1.10.3\\n    Date: Wed, 18 Mar 2020 15:47:00 GMT\\n    Content-Type: text/plain; charset=utf-8\\n    Content-Length: 8662\\n    Connection: close\\n    \\n    Weather report: Rochester\\n    \\n         \\\\   /     Sunny\\n          .-.      39 \xb0F          \\n       \u2015 (   ) \u2015   \u2196 0 mph        \\n          `-\u2019      9 mi           \\n         /   \\\\     0.0 in         \\n                                                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                       \\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524  Wed 18 Mar \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n    \u2502            Morning           \u2502             Noon      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518     Evening           \u2502             Night            \u2502\\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\\n    \u2502               Overcast       \u2502               Overcast       \u2502               Cloudy         \u2502               Overcast       \u2502\\n    \u2502      .--.     32..35 \xb0F      \u2502      .--.     35..41 \xb0F      \u2502      .--.     39..44 \xb0F      \u2502      .--.     37..42 \xb0F      \u2502\\n    \u2502   .-(    ).   \u2196 3-4 mph      \u2502   .-(    ).   \u2190 6-8 mph      \u2502   .-(    ).   \u2190 9-16 mph     \u2502   .-(    ).   \u2196 9-17 mph     \u2502\\n    \u2502  (___.__)__)  6 mi           \u2502  (___.__)__)  6 mi           \u2502  (___.__)__)  6 mi           \u2502  (___.__)__)  6 mi           \u2502\\n    \u2502               0.0 in | 0%    \u2502               0.0 in | 0%    \u2502               0.0 in | 0%    \u2502               0.0 in | 0%    \u2502\\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                                                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                       \\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524  Thu 19 Mar \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n    \u2502            Morning           \u2502             Noon      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518     Evening           \u2502             Night            \u2502\\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\\n    \u2502    \\\\  /       Partly cloudy  \u2502               Cloudy         \u2502    \\\\  /       Partly cloudy  \u2502  _`/\\"\\".-.     Patchy light d\u2026\u2502\\n    \u2502  _ /\\"\\".-.     41..44 \xb0F      \u2502      .--.     50 \xb0F          \u2502  _ /\\"\\".-.     53..55 \xb0F      \u2502   ,\\\\_(   ).   50..53 \xb0F      \u2502\\n    \u2502    \\\\_(   ).   \u2190 4-7 mph      \u2502   .-(    ).   \u2190 4-6 mph      \u2502    \\\\_(   ).   \u2196 6-11 mph     \u2502    /(___(__)  \u2196 10-19 mph    \u2502\\n    \u2502    /(___(__)  3 mi           \u2502  (___.__)__)  6 mi           \u2502    /(___(__)  6 mi           \u2502      \u2018 \u2018 \u2018 \u2018  4 mi           \u2502\\n    \u2502               0.0 in | 0%    \u2502               0.0 in | 0%    \u2502               0.0 in | 0%    \u2502     \u2018 \u2018 \u2018 \u2018   0.0 in | 20%   \u2502\\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                                                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                       \\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524  Fri 20 Mar \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n    \u2502            Morning           \u2502             Noon      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518     Evening           \u2502             Night            \u2502\\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\\n    \u2502  _`/\\"\\".-.     Light rain sho\u2026\u2502    \\\\  /       Partly cloudy  \u2502    \\\\  /       Partly cloudy  \u2502               Cloudy         \u2502\\n    \u2502   ,\\\\_(   ).   62 \xb0F          \u2502  _ /\\"\\".-.     66 \xb0F          \u2502  _ /\\"\\".-.     48..51 \xb0F      \u2502      .--.     46 \xb0F          \u2502\\n    \u2502    /(___(__)  \u2191 14-27 mph    \u2502    \\\\_(   ).   \u2197 26-41 mph    \u2502    \\\\_(   ).   \u2192 24-36 mph    \u2502   .-(    ).   \u2192 22-30 mph    \u2502\\n    \u2502      \u2018 \u2018 \u2018 \u2018  6 mi           \u2502    /(___(__)  6 mi           \u2502    /(___(__)  6 mi           \u2502  (___.__)__)  6 mi           \u2502\\n    \u2502     \u2018 \u2018 \u2018 \u2018   0.0 in | 29%   \u2502               0.0 in | 59%   \u2502               0.0 in | 41%   \u2502               0.0 in | 0%    \u2502\\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n    Location: Rochester, Monroe County, New York, United States of America [43.157285,-77.6152139]\\n    \\n    Follow @igor_chubin for wttr.in updates\\n    request completed: Connection closed\\n    [        3.714] INFO    library/ziti.c:238 NF_shutdown(): Ziti is shutting down\\n    ========================"},{"id":"/bootstrapping-trust/part-01.encryption-everywhere","metadata":{"permalink":"/blog/bootstrapping-trust/part-01.encryption-everywhere","source":"@site/blog/bootstrapping-trust/part-01.encryption-everywhere.md","title":"Bootstrapping Trust","description":"Part 1: Encryption Everywhere","date":"2023-01-26T20:49:40.000Z","formattedDate":"January 26, 2023","tags":[],"readingTime":14.4,"hasTruncateMarker":false,"authors":[{"name":"Andrew Martinez","title":"OpenZiti Maintainer","url":"https://github.com/andrewpmartinez","imageURL":"https://avatars.githubusercontent.com/u/199856?v=4","key":"andrewpmartinez"}],"frontMatter":{"authors":"andrewpmartinez"},"prevItem":{"title":"Building the Ziti C SDK and Sample Apps for arm (BeagleBone)","permalink":"/blog/c-sdk-on-beaglebone"},"nextItem":{"title":"Bootstrapping Trust","permalink":"/blog/bootstrapping-trust/part-02.a-primer-on-public-key-cryptography"}},"content":"## Part 1: Encryption Everywhere\\n\\nWhether you are an encryption expert or a newcomer, welcome! This series\\nis for you! It assumes you know nothing and takes you from soup to nuts\\non how to bootstrap trust with the intent to power a Zero Trust security\\nmodel. The process and thinking described in this series are the direct\\noutput of developing the same system for the Ziti open source project.\\nZiti can be found on the GitHub project page for\\n[OpenZiti](https://github.com/openziti). The series starts with the\\nbasics and dovetails into Ziti\'s Enrollment system.\\n\\nThe parts are as follows.\\n\\n- [Part 1: Encryption Everywhere](./part-01.encryption-everywhere.md)\\n- [Part 2: A Primer On Public-Key Cryptography](./part-02.a-primer-on-public-key-cryptography.md)\\n- [Part 3: Certificates](./part-03.certificates.md)\\n- [Part 4: Certificate Authorities & Chains Of Trust](./part-04.certificate-authorities-and-chains-of-trust.md)\\n- [Part 5: Bootstrapping Trust](./part-05.bootstrapping-trust.md)\\n\\n\\n### Zero Trust\\n\\nThis entire series assumes some familiarity with Zero Trust. If you do\\nnot have a strong background in it, that is fine. This section should\\ngive the reader enough context to make use of the entire series. If a\\nmore in-depth understanding is desired, please consider reading *Zero\\nTrust Networks: Building Secure Systems in Untrusted Networks* by Evan\\nGilman.\\n\\nZero Trust is a security model that requires strict identity\\nauthentication and access verification on every connection at all times.\\nIt sets the tone for a system\'s security to say, \\"this system shall\\nnever assume the identity or access of any connection.\\" Before the Zero\\nTrust security models, IT infrastructures were set up as a series of\\nsecurity perimeters. Think of as a castle with walls and moats. The\\ncastle would have a set number of entry points with guards. Once past\\nthe guards and inside the castle, any visitors were trusted and had\\naccess to the castle. In the real world, passing the guards is analogous\\nto authenticating with a machine or, at worst, connect the office\\nnetwork via WiFi or ethernet cable.\\n\\nZero Trust does away with the concept of having a central castle that\\nassumes anyone inside is trusted. It assumes that the castle has already\\nbeen breached. That is to say, we expect attackers to already be inside\\nthe network and for it to be a hostile environment. Any resources inside\\nthe network should be treated as being publicly available on the\\ninternet and must be defended. To accomplish this defense, a series of\\nZero Trust pillars are defined:\\n\\n- Never Trust, Verify - the virtue of a connection should not grant\\n  access\\n- Authenticate Before Connect - authentication should happen before\\n  resources are connected to\\n- Least Privileged Access - access should only grant connectivity to the\\n  minimum number of resources\\n\\nImplementing those pillars is not a simple tweak to existing\\ninfrastructure. The first point alone will have much of this series\\ndedicated to it.\\n\\n### Ziti & Zero Trust\\n\\nIn a Zero Trust model, there needs to exist mechanisms to verify\\nidentities such that trust can be granted. Zero Trust does not mean\\nthere is no trust. Zero Trust means that trust is given only after\\nverification. Even then, that trust is limited to accessing the minimum\\nnetwork resources necessary. To accomplish this, we need a network that\\ncan force all connections through the following process.\\n\\n1. Authenticate\\n2. Request Access To A Resource\\n3. Connect To The Requested Resource\\n\\nThis process is not the typical connection order on a network. Most\\nconnections on a network are done in the reverse order. At first, this\\nmay seem counter-intuitive. To help make Zero Trust and bootstrapping\\ntrust a bit clearer, it helps to have a concrete system to use an\\nexample. It just so happens that the Ziti software system makes a great\\nexample!\\n\\n![Ziti System](./images/ziti-system.png)\\n\\nIn Ziti, all of the above steps require interacting with a Ziti\\nController. The Ziti Controller manages the Ziti overlay network by\\nmaintaining a list of known network services, SDK clients, routers,\\nenrollments, policies, and much more! All of these pieces working\\ntogether to create a Ziti Network. A Ziti Network is an overlay network\\n\\\\- meaning it creates a virtual network on top of a concrete network.\\nThe concrete network may be the internet, a university network, or your\\nown home network. Whatever it is, it is referred to as the underlay\\nnetwork.\\n\\nIn the Ziti Network, all network resources are modeled as services in\\nthe Ziti Controller. All services on a Ziti Network should only be\\naccessible via the Ziti Network for maximum effect. Network services can\\nbe made available via a Ziti Network in a variety of manners. The\\npreferred method is embedding the Ziti SDK inside of applications and\\nservers as it provides the highest degree of Zero Trust security.\\nHowever, it is also possible to configure various overlay-to-underlay\\nconnections to existing network services via \\"router termination\\" or a\\nparticular type of application with the Ziti SDK embedded in it that\\nspecifically deals with underlay-to-overlay translations (i.e. Ziti\\nDesktop Edge/Mobile Edge).\\n\\nThe Ziti Controller also knows about one or more Ziti Routers that form\\na mesh network that can create dynamic circuits amongst themselves.\\nRouters use circuits to move data across the Ziti Network. Routers can\\nbe configured to allow data to enter and exit the mesh. The most common\\nentry/exit points are Ziti SDKs acting as clients or servers.\\n\\nNetwork clients wishing to attach to the network use the Ziti SDK to\\nfirst authenticate with the Ziti Controller. During authentication, the\\nZiti SDK client and Ziti Controller will verify each other. Upon\\nsuccessful authentication, the Ziti Controller can provide a list of\\navailable services to dial (connect) or to bind (host) for the\\nauthenticated SDK Client. The client can then request to dial or bind a\\nservice. If fulfilled, a session is associated with the client and\\nservice. This new session is propagated to the necessary Ziti Routers,\\nand the required circuits are created. The client is returned a list of\\nZiti Routers which can be connected to in order to complete the last\\nmile of communication between the Ziti overlay network and the SDK\\nclient.\\n\\nThis set of steps covers the pillars of the Zero Trust model! The Ziti\\nController and SDK Clients verify each other. The client cannot connect\\nto network resources or services until it authenticates. After\\nauthentication, a client is given the least privilege access allowed by\\nonly being told about and only being able to dial/bind the authenticated\\nidentity\'s assigned services. It is a Zero Trust overlay network!\\n\\nHow did this system come into existence? How do the Ziti SDK client and\\nZiti Controller verify each other? How do the routers and controller\\nknow to validate each other? How is this managed at scale with hundreds\\nof Ziti Routers and thousands of Ziti SDK clients? It seems that this is\\na recursive problem. To terminate the recursion, we have to start our\\nsystem with a well-defined and carefully controlled seed of trust.\\n\\n# Trust\\n\\nIn software systems that require network connectivity, there are at\\nleast two parties in the system. Generally, there are more, and in the\\ncase of a Ziti network, there could be thousands. Between two parties,\\neach time a connection is made, a trust decision is made. Should this\\nconnection be allowed? Mechanisms must be put into place to verify the\\nidentity of the connecting party if that question is to be answered.\\n\\nOne mechanism that might jump out at the reader is a password or secret.\\nIn Ziti, it would be possible to configure the Controller, Routers, and\\nSDK Clients with a secret. Software is easy to deploy with a secret.\\nThrow it into a configuration file, point the software at, and off you\\ngo!\\n\\nIt is also fundamentally weak as there is only one secret in the system\\nnecessary to compromise the entire system. In Ziti, this would mean\\ngiving the secret to network clients that may or may not be owned by the\\nnetwork operator. Also, shared secrets do not individually identify each\\ncomponent, nor do they define how secrets will power other security\\nconcerns, like encryption.\\n\\nThe solution can be improved. Secrets could be generated per software\\ncomponent. The controller, each router, and each SDK client could have a\\nunique secret. This secret would then individually identity each\\ncomponent! It is a significant improvement, but how does each component\\nverify connections? Do they challenge for the incoming connections\\nsecret and compare it to a list? That means that a pair of systems that\\nneed to connect must have each other\'s secrets. Secret sharing will not\\ndo! We can not be copying secrets between every machine. One machine\\nthat is compromised would mean that many secrets are revealed!\\n\\nThis solution can be evolved and improved, but we do not have to do that\\nhard work! If we did, we would end up recreating an existing technology.\\nThat technology is (public-key\\ncryptography)[https://en.wikipedia.org/wiki/Public-key_cryptography],\\nand it provides everything we need.\\n\\nPublic-key cryptography allows each device to have a unique, secret,\\nprivate key that proves its unique identity. That private key is\\nmathematically tied to a public key. The public key can be used to\\nencrypt messages that only the private key holder can decrypt. Also, the\\npublic key cannot be used to derive the original private key. This\\nfunctionality fits perfectly with what our distributed system needs!\\nAlas, public-key cryptography introduces complex behaviors, setup, and\\nmanagement. In the next article, we will dive a little deeper into this\\ntopic. For now, let us take it on faith that it will serve our needs\\nwell.\\n\\n#### Setting It Up\\n\\nSo we have decided that public-key cryptography is the answer. What does\\nthat mean? What do I have to do? Let us explore what would need to be\\ndone by a human or a piece of software automating this process. Don\'t\\nworry if you don\'t get all of this; the gist is all you need for now.\\nLater articles will expand upon this terminology. In fact, after reading\\nthe later articles, consider revisiting this part.\\n\\nConsider the following diagram of a \\"mesh\\" distributed system. This mesh\\ncould be any type of system such as a mesh of Ziti Routers, or maybe it\\nis a system of sensors on an airplane. What they do does not matter.\\nWhat matters is that this system has multiple pieces of software\\nconnecting amongst themselves. Consider what it means to accomplish this\\nusing public-key cryptography.\\n\\n![Mesh](./images/mesh.png)\\n\\nIn the diagram above, each system needs:\\n\\n- a key pair for client and server connections\\n- to have the public keys of each system it is connecting to\\n\\nSo what do we need to do? Drop into a CLI and start generating keys on\\neach machine. Do that by using these commands:\\n\\n```\\nopenssl ecparam -name secp256k1-genkey -param_enc explicit -out private-key.pem\\n```\\n\\n```\\nopenssl req -new -x509 -key private-key.pem -out server.pem -days 360\\n```\\n\\nVoila - you now have a self-signed certificate! What is a self-signed\\ncertificate? For now, let us understand it means that no other system\\nhas expressed trust in your public certificate. In\\n[Part 4: Certificate Authorities & Chains Of Trust](./part-04.certificate-authorities-and-chains-of-trust.md)\\nwe will cover them in more detail.\\n\\nYou can repeat the above process for every piece of software in your\\nmesh network. Preferably, you log into each machine and generate the\\nprivate key there. Moving private keys on and off devices is a security\\nrisk and frowned upon. For maximum security, hardware, such as\\n[Hardware Security Modules (HSMs)](https://en.wikipedia.org/wiki/Hardware_security_module)\\nand [Trusted Platform Modules\\n(TPMs)](https://en.wikipedia.org/wiki/Trusted_Platform_Module), can be\\nused to store the private keys in a manner that does not make them\\ndirectly accessible.\\n\\nThen you will need to copy each public certificate to every other\\nmachine and configure your software so that it trusts that certificate.\\nThe system will need to repeat this process any time the system adds a\\npiece of software. If a machine is compromised, the analogous public\\ncertificate will need to be untrusted on every node in the mesh. Adding\\nor removing trust in a public certificate involves configuring software\\nor operating systems. There are many ways it can be implemented,\\nincluding configuration files, files stored in specific directories, and\\neven via configuration tools such as Windows Certificate Manager\\nsnap-in.\\n\\nThis is a log of careful work to get a simple system running. Consider\\nwhat this means when adding or removing many nodes? Visiting each\\nmachine and reconfiguring them each time is quite a bit of overhead.\\nThere is a solution to these woes. While it is elegant on its own, it\\ndoes add complexity. Let us see how Certificate Authorities (CAs) can\\nhelp! In the next section, we will hit the highlights of CAs. For more\\ndetail, look forward to\\n[Part 4: Certificate Authorities & Chains Of Trust](./part-04.certificate-authorities-and-chains-of-trust.md).\\n\\n\\n#### CAs & Adding Complexity\\n\\nA CA enables trust deferral from multiple individual certificates to a\\nsingle certificate which means that instead of trusting each\\ncertificate, each piece of software will trust the CA. The CA will be\\nused to sign every public certificate our software pieces need to use.\\nHow does \\"signing\\" work? We will cover that in\\n[part three](./part-03.certificates.md) and why it matters part in\\n[four](./part-04.certificate-authorities-and-chains-of-trust.md). For\\nnow, the basics will be provided.\\n\\nHere are the high-level steps of using a CA:\\n\\n1. create a CA configuration via OpenSSL CNF files\\n2. create the CA\\n3. use the CA\'s public key to sign all of the public certificates\\n4. distribute the CA\'s certificate to every machine\\n5. configure the machines certificate store or configure the software\\n\\nFor items one and two, the process can be a bit mystical. There is a\\nmultitude of options involved in managing a CA. To perform number three,\\nyou will need to go through the processing of creating certificate\\nsigning requests (CSRs, see [parts three](./part-03.certificates.md) for\\nmore detail) on behalf of the piece of software, and someone or\\nsomething will have to play the role of the CA and resolve the CSRs. The\\nlast two steps will depend on the operating system and software being\\nused.\\n\\nAll of these actions can be done via a CLI or programmatically. You will\\nhave to spend time and energy, making sure the options are correctly set\\nand learning about all the different capabilities and extensions.\\nMistakes will inevitably occur. It is time-consuming to debug why a\\nspecific public certificate is not working as intended. The tools and\\nsystems that use the certificates are purposely vague in error messages\\nas not to reveal too much information to attackers.\\n\\nThe payoff for using CAs is having the ability to create chains of\\ntrust. Chains of trust allow distributed systems to scale without having\\nto reconfigure each node every time the system grows or shrinks. With a\\nlittle more upfront cost and bookkeeping to run a CA, the system will\\ngreatly decrease the amount of configuration required on each device.\\n\\n#### Further Concerns\\n\\nOnce configured, there are still other concerns that need to be taken\\ninto account. Consider the following list of events that may happen to a\\nCA, and it\'s certificates:\\n\\n- What happens when a certificate expires?\\n- How does a system know not to trust a certificate anymore?\\n- What happens when private keys need to regenerate?\\n\\nCAs do not automatically handle the propagation of these types of\\nevents. CAs are files on a storage device or HSM. Issuing or revoking\\ncertificates does not generate any kind of event without additional\\nsoftware. There is also the issue of certificates expiring. That \\"-days\\n360\\", used in the example above, puts a lifetime on each certificate.\\nThe lifetime can be extended far into the future, but this is a bad\\npractice. Limiting the life span of a certificate reduces attack windows\\nand can be used as a trigger to adopt strong encryption.\\n\\nEven if we ignore all of those concerns, who did we trust to get this\\nsystem setup? What was the seed of trust used to bootstrap trust? So\\nfar, you could have imagined that a human was doing all of this work. In\\nthat case, a human operator is trusted to properly configure all of the\\nsystems - trusting them with access to all of the private keys. The seed\\nof trust is in that human. If this is a software system performing these\\nactions, that means that the system has to be trusted and most likely\\nhave access to every other system coming online. That is workable, but\\nwhat happens when your system can have external systems request to be\\nadded to the network? How can that be handled? How do you trust that\\nsystem in the first place? Using a secret password creates a single,\\nexploitable, weak point. Public-key cryptography could be put in place,\\nbut then we are in a chicken-and-egg scenario. We are putting public-key\\ncryptography in place to automate public-key cryptography.\\n\\nThere are many caveats to bootstrapping trust. In a dynamic distributed\\nsystem where pieces of software can come and go at the whim of network\\noperators, the issues become a mountain of concerns. Thankfully in Ziti,\\na mechanism is provided that abstracts all of these issues. To\\nunderstand how Ziti accomplishes this, we have a few more topics to\\ndiscuss. In\\n[part two](./part-02.a-primer-on-public-key-cryptography.md), we will\\nchip away at those topics by covering public-key cryptography in more\\ndetail to understand its powers and applications.\\n\\n---\\n\\nWritten By: Andrew Martinez  \\nJune 2020"},{"id":"/bootstrapping-trust/part-02.a-primer-on-public-key-cryptography","metadata":{"permalink":"/blog/bootstrapping-trust/part-02.a-primer-on-public-key-cryptography","source":"@site/blog/bootstrapping-trust/part-02.a-primer-on-public-key-cryptography.md","title":"Bootstrapping Trust","description":"Part 2: A Primer On Public-Key Cryptography","date":"2023-01-26T20:49:40.000Z","formattedDate":"January 26, 2023","tags":[],"readingTime":7.63,"hasTruncateMarker":false,"authors":[{"name":"Andrew Martinez","title":"OpenZiti Maintainer","url":"https://github.com/andrewpmartinez","imageURL":"https://avatars.githubusercontent.com/u/199856?v=4","key":"andrewpmartinez"}],"frontMatter":{"authors":"andrewpmartinez"},"prevItem":{"title":"Bootstrapping Trust","permalink":"/blog/bootstrapping-trust/part-01.encryption-everywhere"},"nextItem":{"title":"Bootstrapping Trust","permalink":"/blog/bootstrapping-trust/part-03.certificates"}},"content":"## Part 2: A Primer On Public-Key Cryptography\\n\\nIf you have read through the entire series up to here, welcome! If you\\nhave not, please consider reading the whole series:\\n\\n- [Part 1: Encryption Everywhere](./part-01.encryption-everywhere.md)\\n- [Part 2: A Primer On Public-Key Cryptography](./part-02.a-primer-on-public-key-cryptography.md)\\n- [Part 3: Certificates](./part-03.certificates.md)\\n- [Part 4: Certificate Authorities & Chains Of Trust](./part-04.certificate-authorities-and-chains-of-trust.md)\\n- [Part 5: Bootstrapping Trust](./part-05.bootstrapping-trust.md)\\n\\nIt isn\'t easy to talk about bootstrapping trust without covering the\\nbasics of public-key cryptography. The reader may skip this article if\\nthe concepts of encryption, signing, and public/private keys are\\nfamiliar. However, if not, I implore that you bear the brunt of this\\narticle as later parts will heavily rely on it.\\n\\nIf you wish, you can dive into the mathematics behind it to prove it to\\nyourself, but I promise, no math here. When necessary, I will wave my\\nhands at it, point into the distance, and let the reader journey out.\\n\\n### Keys\\n\\nKeys are blobs of data containing rather large numbers. They can be\\nstored anywhere data can be stored, but are commonly stored as files. A\\nset of public and private keys is referred to as a \\"key set\\" or \\"key\\npair.\\"\\n\\nWithin a key pair, there is only one private key and one public key. The\\ntwo keys are mathematically entangled, given a particular function and\\nits parameters. Today, those functions and parameters are generally\\nelliptical curves and are the basis of a \\"trapdoor function.\\" Trapdoor\\nfunctions are attractive to the cryptographically inclined for two main\\nreasons:\\n\\n1. they make it easy to encrypt with one key of a key pair and decrypt\\n   with the other.\\n2. one key cannot be derived from the other\\n\\nOf the two keys, the private key is the most important. It must be kept\\ntucked away from prying eyes and attackers. Some secure environments\\nstore the private key in hardware such as\\n[Hardware Security Modules (HSMs)](https://en.wikipedia.org/wiki/Hardware_security_module)\\nor\\n[Trusted Platform Modules (TPMs)](https://en.wikipedia.org/wiki/Trusted_Platform_Module).\\nMobile devices, such as laptops and smartphones, use hardware technology\\nsimilar to TPMs. Apple has its Secure Enclave, and Android has its\\nKeymaster Hardware Abstraction Layer. The goal of all of these pieces of\\nhardware is to keep sensitive secrets (e.g., private keys) safe. The\\nfact that an entire industry of embedded hardware has been developed to\\nkeep private keys safe should tip the reader off to how important they\\nare.\\n\\n\\nAs stated above, these two keys have some impressive capabilities. It is\\nnot possible to derive one from the other. This allows the public key to\\nbe handed out freely without compromising the private key. Also, both\\nkeys can generate encrypted data that only the other key can decrypt.\\nMore clearly:\\n\\n1. Anyone with the public key can encrypt data only the private key\\n   holder can decrypt\\n2. Anyone with the public key can decrypt data from the private key\\n   holder\\n\\nNumber one can succinctly be called \\"Public Key Encryption\\" and number\\ntwo \\"Private Key Encryption.\\" This article explores the merits of both.\\n\\n#### Public Key Encryption\\n\\nFrom the list above, number one is what most people think of as\\n\\"encryption.\\" It is \\"secure\\" as it allows anyone with the widely\\navailable public key to send messages only the private key holder can\\nread. This property ensures that communication from the public key\\nholder to the private key holder is being read exclusively by the\\nintended target.\\n\\nThere is quite a bit of pressure to keep the private key extremely safe.\\nWhoever holds the private key, has a guaranteed identity that is tied to\\nand verifiable by the public key. It is verifiable because if one can\\nuse the public key to encrypt data, only the private key holder can\\ndecrypt it. This fact means that data can be encrypted and sent that\\ncoordinates on an additional secret. Since only the private key holder\\ncan decrypt the data to see this second level secret, future\\ncommunication can use the new secret to encrypted and verify traffic in\\nboth directions. This additional exchange is roughly how part of the TLS\\nnegotiation works for HTTPs. TLS, and by proxy HTTPS, use other\\ntechnologies and strategies to provide an incredible security\\nproposition.\\n\\n#### Private Key Encryption\\n\\nFor private key encryption, the same principles apply as with public key\\nencryption with the roles reversed. The private key encrypts data only\\nthe public key can decrypt. On the surface, this seems absurd. When the\\nserver encrypts data with its private key, the public key can decrypt\\nit. The public key is not protected and expected to be widely available.\\nIt seems as if private key encryption is nearly useless as everyone can\\nread it!\\n\\nExcept it isn\'t. Private key encryption verifies the identity of the\\nprivate key holder. The public key cannot interact with anyone else.\\nAdditionally, this property allows us to generate encrypted data that\\ncould only have come from the private key holder. If that data happens\\nto be small and describe another document, we call that a \\"digital\\nsignature\\" or \\"signature\\" for short.\\n\\n### Digital Signatures\\n\\nDigital signatures are similar to handwritten ones used to sign legal\\ndocuments and checkbooks, but with a significant advantage. They\\nvalidate that a document has not been altered since it was signed. With\\ntoday\'s computer\'s graphical abilities, the nefarious can forge images\\nand handwritten signatures. That puts handwritten signatures at a\\nsignificant disadvantage. So how does this work?\\n\\nThe data that will be signed can be anything. What it represents is not\\nimportant. It can be text, JSON, an image, a PDF, or anything at all!\\nThat data is processed by a one-way\\n[cryptographic hashing algorithm](https://en.wikipedia.org/wiki/Cryptographic_hash_function),\\nsuch as SHA-256. This process is idempotent, meaning running it\\nrepeatedly on the same data, parameters, and hashing algorithm gives the\\nsame result. The output of this process is a hash, a string of\\ncharacters that uniquely identifies the input data. With sufficiently\\nlarge input data, the hash is much shorter than the input data as the\\nhash size is usually fixed length.\\n\\nFor example, here is the Ziti logo:\\n\\n![Ziti](./images/ziti.png)\\n\\nThis logo\'s file can be hashed using SHA-256 via the `sha256sum` command\\ncommonly found on Linux.\\n\\n```\\n$> sha256sum ziti.png\\nc3a6681cc81f9c0fa44b3e2921495882c55f0a86c54cd60ee0fdc7d200ad26db  ziti.png\\n```\\n\\nThat long string \\"c3a....6db\\" is the hash of that file! The string is 64\\ncharacters long and is comprised of hex characters (a base 16 numbering\\nsystem of 0-9 and a-f). Each character takes four bits to represent (4^2\\n= 16). Since there are 64 characters at 4 bits each we have: 64 x 4 =\\n256\\\\. This is where SHA-256 gets its name. SHA-256 is a fixed-length\\ncryptographic hashing algorithm who\'s output is 256 bits in length.\\n\\nThe hash itself is not encryption. It is \\"hashing.\\" Hashing of this\\nnature is not reversible while encryption is. For cryptographic hashing,\\nit is impracticable to have two similar sets of data that have the same\\nfunction that produces the same hash. In essence, the hash uniquely\\nrepresents the data: all of it! Changing even a single character would\\ngenerate a different hash.\\n\\nAfter hashing a data or document, the private key holder can encrypt the\\nhash to generate a signature. This process provides the following truths\\nwhen working with the signature:\\n\\n- the private key is the only key capable of producing its signature of\\n  the data\'s hash\\n- the public key can validate the signature given the data and hashing\\n  algorithm used\\n\\nVerifying a signature a straightforward process:\\n\\n- Use the public key to decrypt the signature to reveal the original\\n  hash\\n- Use the hashing algorithm that was used initially on the data,\\n  recreate the hash independently\\n- Compare the two hashes, and if they are the same the signature is\\n  valid\\n\\nSigning data is incredibly powerful. It allows a private key holder to\\nstate that data was approved by them and not altered. It is also\\npublicly verifiable to anyone with the document, signature, and public\\nkey. This allows many decentralized approaches to sharing data that can\\nhave its source and content verified.\\n\\nBearer tokens are an example of the power of signatures. Bearer tokens\\nare a document that is signed by a trusted authentication system and\\ncontain data that provides information about the client presenting the\\ntoken. Signing the token ensures that the content of the token has not\\nbeen changed and has been endorsed by a trusted system. An example of a\\nbearer token is a\\n[JSON Web Token (JWT)](https://en.wikipedia.org/wiki/JSON_Web_Token)\\n\\nA JWT specifies the format of the bearer token as a header, payload, and\\nsignature using JSON. A client can then present a JWT to any system\\nwhich can then verify that the contents are valid and from a trusted\\nidentity. As long as the signature is valid, the JWT can grant access to\\nthe client presenting it based on whatever information is inside the\\nJWT.\\n\\n# Closing\\n\\nThis article should have shed light on public-key cryptography by\\nexplaining the roles of the public and private keys. It should have also\\nprovided a glimpse at the power of encryption and digital signatures. In\\n[part three](././part-03.certificates.md) we will see how key pairs can\\nbe combined with certificates!\\n\\n---\\n\\nWritten By: Andrew Martinez  \\nJune 2020"},{"id":"/bootstrapping-trust/part-03.certificates","metadata":{"permalink":"/blog/bootstrapping-trust/part-03.certificates","source":"@site/blog/bootstrapping-trust/part-03.certificates.md","title":"Bootstrapping Trust","description":"Part 3: Certificates","date":"2023-01-26T20:49:40.000Z","formattedDate":"January 26, 2023","tags":[],"readingTime":6.04,"hasTruncateMarker":false,"authors":[{"name":"Andrew Martinez","title":"OpenZiti Maintainer","url":"https://github.com/andrewpmartinez","imageURL":"https://avatars.githubusercontent.com/u/199856?v=4","key":"andrewpmartinez"}],"frontMatter":{"authors":"andrewpmartinez"},"prevItem":{"title":"Bootstrapping Trust","permalink":"/blog/bootstrapping-trust/part-02.a-primer-on-public-key-cryptography"},"nextItem":{"title":"Bootstrapping Trust","permalink":"/blog/bootstrapping-trust/part-04.certificate-authorities-and-chains-of-trust"}},"content":"## Part 3: Certificates\\n\\nIf you have read through the entire series up to here, welcome! If you\\nhave not, please consider reading the whole series:\\n\\n- [Part 1: Encryption Everywhere](./part-01.encryption-everywhere.md)\\n- [Part 2: A Primer On Public-Key Cryptography](./part-02.a-primer-on-public-key-cryptography.md)\\n- [Part 3: Certificates](./part-03.certificates.md)\\n- [Part 4: Certificate Authorities & Chains Of Trust](./part-04.certificate-authorities-and-chains-of-trust.md)\\n- [Part 5: Bootstrapping Trust](./part-05.bootstrapping-trust.md)\\n\\nIn the series, we have covered public-key cryptography, where we learned\\nabout public keys, private keys, and their uses for encryption and\\nsigning. Using keys to sign data will play an essential role in this\\narticle. It is vital that the reader understand that signatures verify\\nboth the content of the data and its source. For a refresher, see\\n[part two](./part-02.a-primer-on-public-key-cryptography.md) of this\\nseries.\\n\\nThis article covers how certificates and certificate authorities (CAs)\\nwork as \\"trust anchors.\\" When a CA is a trust anchor, it means that a\\nsystem can trust the CA to sign certificates that it can, in turn,\\ntrust. Throughout this entire article, \\"trusting certificates\\" is\\nmentioned. Trusting a certificate (CA or otherwise) is a software or\\noperating system configuration process. This configuration tells the\\nsystem that the specified certificates are trustworthy in the eyes of\\nthe operator.\\n\\n### Certificates\\n\\nPart two of this series covered keys, both public and private, but did \\nnot mention certificates. It is common to hear \\"certificate\\" used \\ninterchangeably with \\"public key\\" and, sometimes, \\"private key.\\" A \\ncertificate must have the public key inside of it. Some storage formats\\nallow certificates to be stored along with the matching private key. \\nOne example of this is PFX files. PFX files, which are PKCS#12 archives,\\nare also sometimes generically referred to as a \\"certificates\\". In this \\narticle \\"certificate\\" will always mean an x509 certificate that contains\\nonly the public key.\\n\\nCertificates are a simple concept, but years of expansions and\\nextensions have added to them and can be daunting uninitiated when you\\nget into the nitty-gritty details. This article will strive to sit above\\nthat detail. If you venture into the realm of generating certificates,\\nusing OpenSSL and its configuration files, it can be a cumbersome\\nexperience to wade through. There are many great articles and tutorials\\navailable to get you started.\\n\\nFor this article, the word \\"certificate\\" will mean an \\"x509\\nCertificate\\". x509 is a public standard and is the de-facto standard for\\nsoftware systems dealing with public-key cryptography. There are other\\nformats, but they are usually environment-specific, such as Card\\nVerifiable Certificates. x509 good enough for general purpose use on\\nmost systems.\\n\\n\\nSo, what is a certificate? It is yet another blob of data that is\\nspecially formatted. It can be stored anywhere data can be stored but is\\nusually a file. For this conversation, we will focus on the following\\nsubset of information that a certificate contains:\\n\\n- Subject information\\n  - A public key\\n  - Distinguished Name\\n- Issuer Information\\n- Validity Period\\n- Usage/Extensions\\n- Signatures\\n\\n#### Subject Information\\n\\nCertificates contain more than keys. The Distinguished Name (DN) are\\ntext fields. They are useful mainly to humans to know what/who owns a\\ncertificate. It is sometimes used by software as display information or\\nfor comparison checks. Since humans provide the DN values or configure\\nsoftware with values, it is not always distinguishing. DN values have an\\nalternate name: relatively distinguished names.\\n\\nRelated to the Subject DN is the Issuer Information. The Issuer\\nInformation is the subject of the certificate that issued the\\ncertificate. Because of this, both the issuer information has similar\\nvalues to the subject DN. Both can include the following information:\\n\\n- CN - common name - a name\\n- SN - surname\\n- SERIALNUMBER - a number that is usually unique per certificate issuer,\\n  but not always\\n- C - country\\n- L - locality name\\n- ST or S - state or province\\n- STREET - street address\\n- O - organization name\\n- OU - organizational unit\\n- T - title\\n- G or GN - given name\\n- E - email address\\n- UID - user id\\n- DC - domain component\\n\\nDo not worry about memorizing that list. Simply knowing they exist and\\nthat they may or may not matter is good enough for now. If the reader is\\nwondering when they might matter, well, that is generally when the\\nsystem you are using complains about them.\\n\\n#### Validity Period\\n\\nThe Validity Period specifies two points in time from when the\\ncertificate is valid. Before and after this window of time, the\\ncertificate is invalid and should not be trusted. Validity periods\\nshould be as small as possible to fit their use case. Shorter periods\\nreduce the window of time that compromised private key can remain useful\\nfor an attack. The cost of this is overhead reissuing certificates as\\nthey reach the end of their validity period.\\n\\n#### Usage/Extensions\\n\\nUsage/Extension Data is interesting because it can limit what roles a\\ncertificate fulfills. Depending on the system, this may be adhered to or\\nnot. Some examples of usage that are common to see:\\n\\n- key usage: client authentication, server authentication, signatures,\\n  etc.\\n- Subject Alternate Names (SANs)\\n  - Limits what IP address, email address, domain name, etc. the\\n    certificate can be associated with\\n- Certificate Authority (CA) flag\\n- and more\\n\\nThis series will not dive into the details of these usages. However, it\\nis essential to be aware of them and that they can affect the roles a\\ncertificate can fulfill.\\n\\n#### Signatures\\n\\nThe signature section of a certificate is a list of signatures from\\nother entities that trust this certificate. A certificate that signs\\nitself is a \\"self-signed certificate.\\" Self-signed certificates must be\\nindividually trusted as no other certificate has expressed trust in it\\nby signing it. Self-signed certificates are sometimes used for testing\\npurposes as they are easy to create. They are also used as Root\\nCertificate Authorities (root CAs).\\n\\nEach signature on a certificate is the result of taking the contents of\\nthe certificate (without signatures), one-way hashing it, and then\\nencrypting the hash with the signator\'s private key. The result is\\nappended to the end of the signature list. During this process, the\\npublic certificate moves between systems to be signed.\\n\\nThe movement of the public certificate between systems is facilitated by\\nCertificate Signing Requests (CSRs). CSRs can be transmitted\\nelectronically as files or as a data stream to the signer. CSRs contain\\nonly the public information of a certificate and a signature from the\\ncertificate\'s private key. Since CSRs only contain public information,\\nthey are not considered sensitive. The signature in a CSR allows the\\nsigner to verify that the CSR is from the subject specified in the CSR.\\nIf the signature is valid, the signator processes the CSR, and the\\nresult is a newly minted certificate with an additional signature.\\n\\n### Conclusion\\n\\nCertificates are keys, usually public ones, with additional metadata\\nthat adds conventions and restrictions around certificate usages. They\\nprovide a place for signatures to resides and, through CSRs, provide a\\nvehicle to request additional signatures. Certificates are useful\\nbecause they package all of these concerns into a neat single file. In\\n[part four](./part-04.certificate-authorities-and-chains-of-trust.md), we\\nwill explore how to create a formidable chain of trust by linking\\nmultiple certificates together.\\n\\n---\\n\\nWritten By: Andrew Martinez  \\nJune 2020"},{"id":"/bootstrapping-trust/part-04.certificate-authorities-and-chains-of-trust","metadata":{"permalink":"/blog/bootstrapping-trust/part-04.certificate-authorities-and-chains-of-trust","source":"@site/blog/bootstrapping-trust/part-04.certificate-authorities-and-chains-of-trust.md","title":"Bootstrapping Trust","description":"Part 4: Certificate Authorities & Chains of Trust","date":"2023-01-26T20:49:40.000Z","formattedDate":"January 26, 2023","tags":[],"readingTime":7.81,"hasTruncateMarker":false,"authors":[{"name":"Andrew Martinez","title":"OpenZiti Maintainer","url":"https://github.com/andrewpmartinez","imageURL":"https://avatars.githubusercontent.com/u/199856?v=4","key":"andrewpmartinez"}],"frontMatter":{"authors":"andrewpmartinez"},"prevItem":{"title":"Bootstrapping Trust","permalink":"/blog/bootstrapping-trust/part-03.certificates"},"nextItem":{"title":"Bootstrapping Trust","permalink":"/blog/bootstrapping-trust/part-05.bootstrapping-trust"}},"content":"## Part 4: Certificate Authorities & Chains of Trust\\n\\nIf you have read through the entire series up to here, welcome! If you\\nhave not, please consider reading the whole series:\\n\\n- [Part 1: Encryption Everywhere](./part-01.encryption-everywhere.md)\\n- [Part 2: A Primer On Public-Key Cryptography](./part-02.a-primer-on-public-key-cryptography.md)\\n- [Part 3: Certificates](./part-03.certificates.md)\\n- [Part 4: Certificate Authorities & Chains Of Trust](./part-04.certificate-authorities-and-chains-of-trust.md)\\n- [Part 5: Bootstrapping Trust](./part-05.bootstrapping-trust.md)\\n\\nThis article makes implicit heavy use of\\n[part 2](./part-02.a-primer-on-public-key-cryptography.md) and\\n[part 3](./part-03.certificates.md) of this series.\\n\\n### Root & Intermediate Certificate Authorities (CAs)\\n\\nNot all certificates are the same! Certificates have different\\ncapabilities depending on their usage attributes and extensions. The\\nprevious article in this series mentioned a few of those attributes and\\nextensions. Two of those were `clientAuth`, for client certificates, and\\n`serverAuth`, for server certificates, which play an essential role in\\nhow a certificate is used during network authentication negotiations.\\nThese roles are crucial, as they are a contract for what attributes and\\nextensions should be included in the certificate to make it useful. For\\nexample, a server certificate usually finds it useful to include Subject\\nAlternate Names (SANs). A SAN can be used to tie a certificate to a\\nspecific domain name (like ziti.dev). However, a client certificate will\\nnot have use for those same fields.\\n\\nThe roles of certificates and the attributes/extensions they have are\\nnot always strictly followed. Some systems, such as web browsers,\\nrequire SANs on a server certificate. That wasn\'t always the case.\\nBefore that, the Common Name field in the subject information contained\\nthe domain name. Some systems still rely on that convention.\\n\\nAnother type of certificate is a Certificate Authority (CA) certificate.\\nA CA is a key pair with a certificate that has a unique purpose: to sign\\nother certificates. CA certificates have a special CA flag set to\\n\\"true.\\" This flag alone does not grant the CA certificate any power, but\\nif a system trusts that CA, it then allows that system to trust any\\ncertificate that CA has signed. As mentioned in previous parts of this\\nseries, trusting a CA is a software or operating system configuration\\nprocess. This process can be done in multiple ways depending on the\\nsystem: adding it to a store, a specific folder, or adding lines to a\\nconfiguration file.\\n\\nYour operating system, right now, has its own set of trusted CAs. Most\\noperating systems come with a default list installed and maintained by\\nyour OS developer. Over time this list is added to and removed from as\\ntrust is granted or withdrawn. Some pieces of software come with a list\\nof CAs that are used instead of or in addition to the OS\'s CAs. The\\npower of a CA comes not by its creation but by it being trusted.\\n\\nCAs come in two flavors: Root CAs and Intermediate CAs. Root CAs are the\\negg or the chicken (depending on your viewpoint) of the CA trust\\nchicken-and-egg problem. Trust for CAs has to start somewhere. With CAs,\\nit is the Root CA. A Root CA can sign certificates that are themselves\\nCAs as well. Those certificates represent Intermediate CAs. Layers of\\nCAs starting with a root and adding intermediates along the way allows\\nthe private key for the Root CAs to be kept in a highly secure\\nenvironment, which is not convenient to use for signing. This security\\nmeans that the Root CA has a far less likely chance of having its\\nprivate key compromised. Intermediate CAs are put into less secure\\nenvironments and, if compromised, can be revoked. Trust is usually put\\ninto the Root CA, and since it was not compromised can remain trusted.\\nCompromised intermediate CAs can be blacklisted.\\n\\nRunning a public CA is serious business if you wish to be publicly\\ntrusted. The organizations running a CA have to have strict protocols\\nthat verify the security and safe handling of the CAs private keys. If\\nthe private key is compromised, it can be used to sign other\\ncertificates for malicious intents. Any system that trusted the\\ncompromised CA will now trust any maliciously signed certificates. This\\nwill compromise all certificates signed by that CA.\\n\\nPublic CAs are maintained by organizations such as DigiCert, Let\'s\\nEncrypt, and others. Anyone can create private CAs. The only difference\\nis that the number of systems that trust a private CA is much smaller\\nthan that of a public one. CAs are a cornerstone of bootstrapping trust.\\nTrusting the proper CAs can grant trust to a large number of systems.\\n\\n### Chains of Trust & PKIs\\n\\n[Part three](./part-03.certificates.md) of this series introduced that\\ncertificates self-sign or sign another certificate. Certificates are\\nusually signed via Certificate Signing Requests (CSRs). A certificate\\nsigning itself is called a \\"self-signed certificate\\" and is an indicator\\nof it being a root CA if the CA flag is also set to true. A root CA can\\nsign other certificates that also have the CA flag set to true. Those\\ntypes of certificates are intermediate CAs. Any CA, root or\\nintermediate, that fulfills a CSR and signs the enclosed certificate\\nwill generate a non-CA certificate as long as the CA flag is false.\\nThese certificates are \\"leaf certificates.\\"\\n\\nThe term Public Key Infrastructure (PKI) is used to describe all of the\\noutputs that are generated when a CA is created. That includes the root,\\nintermediates, and leaf certificates. It also optionally includes all of\\nthe systems, processes, procedures, and data used to manage them. For\\nthe purpose of this article, and simplicity, let us stick to the\\ncertificates only.\\n\\nConsider the following PKI setup:\\n\\n- Two root CAs:\\n  - Root A\\n  - Root B\\n- The root CAs each sign an intermediate CA via CSR:\\n  - Intermediate A\\n  - Intermediate B\\n- A server wishes to have a certificate to have Root A\'s trust extended\\n  to it.\\n  - A key pair is generated\\n- A CSR is created and submitted to Intermediate A to sign\\n- The CSR is fulfilled.\\n  - Server Cert A is created and signed by Intermediate A\\n\\nVisually this would appear as follows:\\n\\n![Chains](./images/chains.png)\\n\\nThis PKI has two chains of trust: Chain A and Chain B. They are called\\nchains because the signatures link the certificates together. Root A has\\nsigned Intermediate A\'s certificate and Intermediate A has signed Server\\nA\'s certificate. Programmatically we can traverse these signatures and\\nverify them using the public certificates of each signatory. Trusting\\nRoot A will trust Server A.\\n\\nThe second chain, Chain B, does not sign any of the certificates on\\nChain A. As expected, Trusting either of the CAs from Chain B does not\\ngrant any trust to the certificates on Chain A. Chain B highlights the\\nfact that any system may have multiple chains of trust that do not\\ninteract in any fashion.\\n\\nReturning to Chain A, trusting Intermediate A designates it as a \\"trust\\nanchor.\\" Any certificate can be a trust anchor. The certificate used as\\na trust anchor determines which certificates will additionally be\\ntrusted. A leaf certificate as a trust anchor only trusts that one\\ncertificate. Trusting a CA trusts all certificates that it has signed\\nitself or any of its intermediates. In the diagram above, trust only\\nflow downward.\\n\\n- Trusting Server Cert A will only trust that one server certificate\\n- Trusting Intermediate A will trust Server Cert A and any other\\n  certificate it signs\\n- Trust Root A will trust Intermediate A and Server Cert A and any other\\n  certificate Root A signs (intermediate CA or not) and in turn, any of\\n  the certificates they sign\\n\\nTrusting a CA that has signed many certificates allows public\\ncertificate trust to scale. This is how trust scales for web traffic.\\nCompanies like DigiCert, IdenTrust, GoDaddy, etc. have their root CA or\\none of their large intermediate CAs trusted. Those CAs sign certificates\\nfor websites. All of our devices trust those website certificates\\nbecause the CA has signed them.\\n\\n### Distributed Systems & CAs\\n\\nThe goal for any private distributed system should be to have\\ncertificates verified on both sides: clients verify servers and vice\\nversa. This behavior is a tenant of Zero Trust - do not trust, verify.\\nVerification should be done on every connection before any data\\nexchange. Over TLS, which secures HTTPS, this would be \\"mutual TLS\\" or\\n\\"mTLS.\\" Most public websites do not require mTLS. Instead, they use TLS\\nwith the client validating the server. For public web traffic, the\\nserver wishes to be trusted widely. The reverse is not necessary. If it\\nis, websites use an additional form of authentications, like usernames\\nand passwords, to verify the client\'s identity. Public key cryptography\\nis a stronger authentication mechanism, but it is also difficult for the\\ngeneral public to set up, manage, and maintain.\\n\\nThe same is true for distributed systems. Most don\'t secure anything at\\nall or only verify servers. It is inherently insecure and can cause\\nissues depending on the setup of the system. Ziti is a distributed\\nsystem that abstracts away this security setup for both its internal\\nrouters and client SDKs. This setup allows application-specific\\nnetworking with strong identity verification, powerful policy\\nmanagement, flexible mesh routing, and more. The goal of this series is\\nto focus on bootstrapping trust. So in the\\n[last article](./part-05.bootstrapping-trust.md) we will come full\\ncircle and see how all of this relates to bootstrapping trust for Zero\\nTrust networks.\\n\\n---\\n\\nWritten By: Andrew Martinez  \\nJune 2020"},{"id":"/bootstrapping-trust/part-05.bootstrapping-trust","metadata":{"permalink":"/blog/bootstrapping-trust/part-05.bootstrapping-trust","source":"@site/blog/bootstrapping-trust/part-05.bootstrapping-trust.md","title":"Bootstrapping Trust","description":"Part 5 Bootstrapping Trust","date":"2023-01-26T20:49:40.000Z","formattedDate":"January 26, 2023","tags":[],"readingTime":5.735,"hasTruncateMarker":false,"authors":[{"name":"Andrew Martinez","title":"OpenZiti Maintainer","url":"https://github.com/andrewpmartinez","imageURL":"https://avatars.githubusercontent.com/u/199856?v=4","key":"andrewpmartinez"}],"frontMatter":{"authors":"andrewpmartinez"},"prevItem":{"title":"Bootstrapping Trust","permalink":"/blog/bootstrapping-trust/part-04.certificate-authorities-and-chains-of-trust"},"nextItem":{"title":"Golang Aha! Moments","permalink":"/blog/golang-aha/article"}},"content":"## Part 5 Bootstrapping Trust\\n\\nIf you have read through the entire series up to here, welcome! If you\\nhave not, please consider reading the whole series:\\n\\n- [Part 1: Encryption Everywhere](./part-01.encryption-everywhere.md)\\n- [Part 2: A Primer On Public-Key Cryptography](./part-02.a-primer-on-public-key-cryptography.md)\\n- [Part 3: Certificates](./part-03.certificates.md)\\n- [Part 4: Certificate Authorities & Chains Of Trust](./part-04.certificate-authorities-and-chains-of-trust.md)\\n- [Part 5: Bootstrapping Trust](./part-05.bootstrapping-trust.md)\\n\\n### Ziti\\n\\nIn this series of articles, we are exploring bootstrapping trust, what\\nthat means, and how it enables Zero Trust security methodologies. Ziti\\nprovides a method to bootstrap trust via its enrollment process. For\\nZiti, the enrollment process is bootstrapping trust. This trust must be\\nin place as all connections in Ziti require verification. All identities\\nin Ziti have a key pair that identifies that individual. The enrollment\\nprocess abstracts the steps of setting up keys, certificates, CSRs, CAs,\\nand deploying them to the proper locations. In addition, the Ziti SDKs\\ncan be embedded within any application and enroll with a Ziti network in\\nthe exact same fashion to bootstrap trust as part of Ziti\'s Zero Trust\\nmodel.\\n\\n\\nZiti has a concept called the \\"Edge.\\" The Edge is a set of software\\nfeatures that sit on top of the \\"Fabric.\\" The Fabric is the core of each\\nZiti component, and it provides long haul mesh routing while the Edge\\nfocuses on enrolling Ziti components, managing access via policies, and\\nmaintaining the trust necessary to provide the foundation of a Zero\\nTrust network without the hassle of setting it up yourself. Together\\nthey are a powerful combination of optimized long haul routing and trust\\nmanagement.\\n\\n![Fabric Edge](./images/fabric-edge.png)\\n\\nA small scale example Ziti system appears as follows:\\n\\n![Ziti System](./images/ziti-system.png)\\n\\nZiti Edge has the concepts of identities for endpoint SDKs and routers.\\nBoth require certificates signed by a trusted CA. Ziti can generate the\\nPKI necessary to manage that trust. The PKI and its CAs will form the\\nbackbone of the trust system that Ziti will deploy for you. In the\\nsystem diagram above, the Ziti Controller will manage an intermediate CA\\nand a secure enrollment process that will bootstrap trust for each\\nrouter and SDK. After bootstrapping trust, the controller will maintain\\ndata to manage the entire life cycle of the certificates it generates.\\nThis life cycle encompasses all the concerns from part one of this\\nseries, including bootstrapping, revoking, renewing, and rotating keys.\\n\\nSo let us review the components a Ziti Controller must have to function:\\n\\n1. A CA (intermediate preferred)\\n2. A server certificate generated for the Controller\'s IP/hostname/etc.\\n   Signed by the CA or a public CA\\n3. A Ziti Controller configured and ready to run\\n\\nThis article series has touched on items one and two, but not three. For\\ninformation on how to configure a Ziti Controller refer to the Ziti\\ndocumentation repository on Github. You will also find details on how to\\nuse the Ziti CLI to generate the PKI necessary to start a Ziti network.\\nHowever, here is a simple command that will help get the controller\\nstarted.\\n\\n```\\n ziti pki create ca test1\\n ziti pki create server --dns myserver.com\\n```\\n\\n## Enrollment\\n\\nOnce a Ziti Controller is up and running, it is possible to create a new\\nidentity and enroll it. Behind the scenes, many things happen, but for\\nnow, let us focus on what an administrator would have to perform.\\n\\n1. Authenticate via the Ziti CLI, Ziti Admin Console (ZAC), or Edge REST\\n   API\\n2. Issue a request to create a new identity for an SDK or router\\n3. Receive an enrollment JWT Use the JWT on the enrolling device/server\\n   to enroll\\n\\nIn those steps, we have performed many complex interactions.\\n\\n- The enrolling identity:\\n  - validated the enrollment JWT cryptographically\\n  - validated the Ziti Controller as a suitable trust anchor\\n    cryptographically\\n  - bootstrapped its trust pool of CAs as additional trust anchors over\\n    a secure connection\\n  - generated a key pair\\n  - generated a CSR\\n- The controller has:\\n  - asserted its identity cryptographically\\n  - asserted the validity of the enrolling identity\\n  - provided a CA store of trust anchors\\n  - fulfilled the CSR request for the identity\\n\\nAll of these items are performed making no assumptions and securely\\nverifying each step. This process does not suffer from man-in-the-middle\\nattacks. It provides many benefits! Below is a detailed image of each\\nstep of the enrollment process.\\n\\n![Enrollment Full](./images/enrollment-full.png)\\n\\nLet\'s break those steps down:\\n\\n1. Via the Ziti CLI, ZAC, or Edge REST API the admin authenticates and\\n   requests to create an identity\\n2. The admin receives a JWT that is signed by the controller and is\\n   cryptographically verifiable. The JWT contains all the information\\n   for the enrolling device/server to contact the controller and verify\\n   its identity. It also includes a secret enrollment token.\\n3. The JWT is given to the enrolling device\\n4. The device parses the JWT, verifies all the information is present to\\n   enroll\\n5. The device retrieves the public certificate from the controller at\\n   the address specified in the JWT\\n6. The device confirms that the server is, in fact, the owner of the\\n   private key for that certificate\\n7. The device uses the retrieved certificate to verify the signature on\\n   the JWT\\n8. Verifies content has not changed\\n9. Verifies the issuing server is the server it is communicating with\\n10. Makes a secure connection to the server and requests the CAs to\\n    trust\\n11. The enrolling identity generates a key pair, if necessary, and a\\n    CSR. The CSR is submitted in a request with the JWT\'s enrollment\\n    token.\\n12. The controller verifies the CSR, verifies the enrollment token,\\n    verifies the client connection, and then returns the necessary\\n    signed certificates.\\n\\nAt the end of the process, which took four simple human steps, but\\nnumerous cryptographically secure software steps, the controller now has\\na record of the certificates issued to a specific identity. That\\nidentity now has certificates that can be used to make connections to\\nother enrolled Ziti components. All components in the system can verify\\nthe identity of any other Ziti component. At every step, every link is\\nverified. No individual piece of software blindly trusts any other for\\ninbound or outbound connections. Trust has been successfully\\nbootstrapped! Now we enter a maintenance window where trust has to be\\nverified continuously and maintained. The enrolled identity can now\\ninteract with the Ziti Controller to either function as a Ziti Router or\\nas Zero Trust network client.\\n\\n# Conclusion\\n\\nThank you for reading this far! If you completed the entire series, I\\nhope it has been helpful. Zero Trust is a complicated topic, and it\\nrequires a serious foundation in bootstrapping trust to get right.\\nHopefully, this series starts you on your way. If you have time, please\\ncheckout (Ziti)[https://github.com/openziti]! It is the Zero Trust\\nnetwork overlay solution that I have personally worked on and was the\\ninspiration for this series.\\n\\n---\\n\\nWritten By: Andrew Martinez  \\nJune 2020"},{"id":"/golang-aha/article","metadata":{"permalink":"/blog/golang-aha/article","source":"@site/blog/golang-aha/article.md","title":"Golang Aha! Moments","description":"Introduction","date":"2023-01-26T20:49:40.000Z","formattedDate":"January 26, 2023","tags":[],"readingTime":9.94,"hasTruncateMarker":false,"authors":[{"name":"Paul Lorenz","title":"OpenZiti Maintainer","url":"https://github.com/plorenz","imageURL":"https://avatars.githubusercontent.com/u/777993?v=4","key":"plorenz"}],"frontMatter":{"authors":"plorenz"},"prevItem":{"title":"Bootstrapping Trust","permalink":"/blog/bootstrapping-trust/part-05.bootstrapping-trust"},"nextItem":{"title":"Wildcard DNS Cheatsheet","permalink":"/blog/wildcard-dns/cheatsheet"}},"content":"## Introduction\\nAs we (the OpenZiti team) progressed on our Go journey, we\'ve stumbled on various\\nobstacles, settled on some best practices and hopefully gotten better at writing Go\\ncode. This document is meant to share some of the \'Aha!\' moments where we overcame \\nstumbling blocks and found solutions that sparked joy. \\nThis is intended both for new team members and for anyone in the go community who \\nmight be interested. We\'d be very happy to hear from others about their own \'aha\'\\nmoments and also how the solutions presented strike your sensibilities.\\n\\n## Channels\\nChannels are a core feature of go. As is typical of go, the channel API is small and\\nsimple, but provides a lot of power. \\n\\nIf you haven\'t read it yet, Dave Cheney\'s [Channel Axioms](https://dave.cheney.net/2014/03/19/channel-axioms)\\n is worth a look.\\n\\n## Closing Channels\\nClosing channels can be complicated. On the reader side things are generally uncomplicated.\\nA closed channel read will return immediately with the zero value and flag indicating that \\nit is closed.\\n\\n```\\nfunc main() {\\n\\tch := make(chan interface{}, 1)\\n\\tch <- \\"hello\\"\\n\\tval, ok := <- ch\\n\\tfmt.Printf(\\"%v, %v\\\\n\\", val, ok) // prints hello, true\\n\\tclose(ch)\\n\\tval, ok = <- ch\\n\\tfmt.Printf(\\"%v, %v\\\\n\\", val, ok) // prints <nil>, false\\n}\\n```\\n\\nOn the writer side, things can be more complicated. If you only have a single writer, \\nit can be responsible for closing the channel. This notifies any blocker readers that\\nthe channel is closed. However, if there are multiple writers, this won\'t work. Writing\\nto a closed channel will cause a panic. Closing an already closed channel will also \\ncause a panic. So, what do we do?\\n\\nThe main thing is to realize that we don\'t have to close the channel. We only have to\\nmake sure the readers and writers are safely notified that they should stop trying to\\nuse the channel. For this, we can use a second channel.\\n\\n```\\npackage main\\n\\nimport (\\n\\t\\"github.com/openziti/foundation/util/concurrenz\\"\\n\\t\\"github.com/pkg/errors\\"\\n)\\n\\ntype Queue struct {\\n\\tch          chan int\\n\\tcloseNotify chan struct{}\\n\\tclosed      concurrenz.AtomicBoolean\\n}\\n\\nfunc (self *Queue) Push(val int) error {\\n\\tselect {\\n\\tcase self.ch <- val:\\n\\t\\treturn nil\\n\\tcase <-self.closeNotify:\\n\\t\\treturn errors.New(\\"queue closed\\")\\n\\t}\\n}\\n\\nfunc (self *Queue) Pop() (int, error) {\\n\\tselect {\\n\\tcase val := <-self.ch:\\n\\t\\treturn val, nil\\n\\tcase <-self.closeNotify:\\n\\t\\treturn 0, errors.New(\\"queue closed\\")\\n\\t}\\n}\\n\\nfunc (self *Queue) Close() {\\n\\tif self.closed.CompareAndSwap(false, true) {\\n\\t\\tclose(self.closeNotify)\\n\\t}\\n}\\n```\\n\\nIf there are several entities which all need to shutdown together, they can even\\nshare a `closeNotify` channel.\\n\\nA variation on this would let readers drain the channel once it\'s closed. Because \\nselect case evaluation is random, we may not read a val from the channel once\\nthe close notify channel is closed. We can ensure that we return a value if it\'s \\navailable by modifying `Pop()` as follows:\\n\\n```\\nfunc (self *Queue) Pop() (int, error) {\\n\\tselect {\\n\\tcase val := <-self.ch:\\n\\t\\treturn val, nil\\n\\tcase <-self.closeNotify:\\n\\t\\tselect {\\n\\t\\tcase val := <-self.ch:\\n\\t\\t\\treturn val, nil\\n\\t\\tdefault:\\n\\t\\t\\treturn 0, errors.New(\\"queue closed\\")\\n\\t\\t}\\n\\t}\\n}\\n```\\n\\nPlaces used:\\n* https://github.com/openziti/channel/blob/main/impl.go (see rxer, txer)\\n\\n## Other Channel Uses\\nLet\'s look at how we can use channels in a few other ways.\\n\\n### Semaphores and Pools\\nBecause channels have a sized buffer and have well defined blocking behavior, \\ncreating a semaphore implementation is very straightforward. We can create a\\nchannel with a buffer of the size we want our semaphore to have. We can then\\nread and write from the channel to acquire and release the semaphore. \\n\\n```\\npackage concurrenz\\n\\nimport \\"time\\"\\n\\ntype Semaphore interface {\\n\\tAcquire()\\n\\tAcquireWithTimeout(t time.Duration) bool\\n\\tTryAcquire() bool\\n\\tRelease() bool\\n}\\n\\nfunc NewSemaphore(size int) Semaphore {\\n\\tresult := &semaphoreImpl{\\n\\t\\tc: make(chan struct{}, size),\\n\\t}\\n\\tfor result.Release() {\\n\\t}\\n\\treturn result\\n}\\n\\ntype semaphoreImpl struct {\\n\\tc chan struct{}\\n}\\n\\nfunc (self *semaphoreImpl) Acquire() {\\n\\t<-self.c\\n}\\n\\nfunc (self *semaphoreImpl) AcquireWithTimeout(t time.Duration) bool {\\n\\tselect {\\n\\tcase <-self.c:\\n\\t\\treturn true\\n\\tcase <-time.After(t):\\n\\t\\treturn false\\n\\t}\\n}\\n\\nfunc (self *semaphoreImpl) TryAcquire() bool {\\n\\tselect {\\n\\tcase <-self.c:\\n\\t\\treturn true\\n\\tdefault:\\n\\t\\treturn false\\n\\t}\\n}\\n\\nfunc (self *semaphoreImpl) Release() bool {\\n\\tselect {\\n\\tcase self.c <- struct{}{}:\\n\\t\\treturn true\\n\\tdefault:\\n\\t\\treturn false\\n\\t}\\n}\\n```\\n\\nWe could use mostly the same implementation for a resource pool. Instead of\\na channel of struct{}, we could have a channel of connections or buffers \\nthat are acquired and released.\\n\\n### Signal\\nWe can use channels as signals. In this example we have something running\\nperiodically, but we want to be able to trigger it to run sooner. With a \\nsingle element channel, we can notify a goroutine. By using `select` with\\n`default`, we can ensure that signalling code doesn\'t block and that the\\nreceiving side only gets a single signal per loop.\\n\\n\\n```\\npackage main\\n\\nimport (\\n\\t\\"fmt\\"\\n\\t\\"github.com/openziti/foundation/util/concurrenz\\"\\n\\t\\"time\\"\\n)\\n\\nfunc NewWorker() *Worker {\\n\\tw := &Worker{\\n\\t\\tsignal:  make(chan struct{}, 1),\\n\\t}\\n\\tgo w.run()\\n\\treturn w\\n}\\n\\ntype Worker struct {\\n\\tsignal chan struct{}\\n\\tstopped concurrenz.AtomicBoolean\\n}\\n\\nfunc (self *Worker) run() {\\n\\tticker := time.NewTicker(time.Minute)\\n\\tdefer ticker.Stop()\\n\\n\\tfor !self.stopped.Get() {\\n\\t\\tselect {\\n\\t\\tcase <-ticker.C:\\n\\t\\t\\tself.work()\\n\\t\\tcase <-self.signal:\\n\\t\\t\\tself.work()\\n\\t\\t}\\n\\t}\\n}\\n\\nfunc (self *Worker) work() {\\n\\tif !self.stopped.Get() {\\n\\t\\tfmt.Println(\\"working hard\\")\\n\\t}\\n}\\n\\nfunc (self *Worker) RunNow() {\\n\\tselect {\\n\\tcase self.signal <- struct{}{}:\\n\\tdefault:\\n\\t}\\n}\\n```\\n\\n### Channel Loops and Event Handler\\n\\nWe often have a loop which is processing inputs from one or channel. Often we have a set of data\\nwe want to keep local to a single goroutine, so we don\'t have to use any synchronization or worry\\nabout cpu cache effects. We use channels to feed data to the goroutine and/or to trigger different\\nkinds of processing. A for with select loop can handle channels of different types. YOu can have\\na channel per type of work, or per type of data. Sometimes it can be convenient to consolidate things \\non a single channel, using an event API.\\n\\nHere\'s a simple example where the processor is maintaining some cached data which can be updated \\nexternally. Presumably the processor would be doing something with the cached data, but we\'ve left\\nthat out to focus on the pattern itself.\\n\\n```\\ntype Event interface {\\n\\t// events are passed the processor so they don\'t each have to include it\\n\\tHandle(*Processor)\\n}\\n\\ntype Processor struct {\\n\\tch          chan Event\\n\\tcloseNotify chan struct{}\\n\\tcache map[string]string\\n}\\n\\nfunc (self *Processor) run() {\\n\\tfor {\\n\\t\\tselect {\\n\\t\\tcase event := <-self.ch:\\n\\t\\t\\tevent.Handle(self)\\n\\t\\tcase <-self.closeNotify:\\n\\t\\t\\treturn\\n\\t\\t}\\n\\t}\\n}\\n\\nfunc (self *Processor) queueEvent(evt Event) {\\n\\tselect {\\n\\tcase self.ch <- evt:\\n\\tcase <-self.closeNotify:\\n\\t\\treturn\\n\\t}\\n}\\n\\nfunc (self *Processor) UpdateCache(k, v string) {\\n\\tself.queueEvent(&updateCache{key: k, value: v})\\n}\\n\\nfunc (self *Processor) Invalidate(k string) {\\n\\tself.queueEvent(invalidate(k))\\n}\\n\\ntype updateCache struct {\\n\\tkey string\\n\\tvalue string\\n}\\n\\nfunc (self *updateCache) Handle(p *Processor) {\\n\\tp.cache[self.key] = self.value\\n}\\n\\ntype invalidate string\\n\\nfunc (self invalidate) Handle(p *Processor) {\\n\\tdelete(p.cache, string(self))\\n}\\n```\\n\\n## Type Aliases\\nAs we demonstrated in the previous example we can alias a type and add functions to it, usually\\nto satisfy some interface.\\n\\n```\\ntype invalidate string\\n\\nfunc (self invalidate) Handle(p *Processor) {\\n        delete(p.cache, string(self))\\n}\\n```\\n\\nThis can be useful if we only have a single piece of data. Rather than wrapping it in a struct, \\nwe can just alias it and add our own funcs. \\n\\nThe main downside to this approach is that you have to unalias the data inside your functions\\nwhich can lead to code that is less clear. See for example this method from an `AtomicBoolean`\\nimplementation:\\n\\n```\\ntype AtomicBoolean int32\\n\\nfunc (ab *AtomicBoolean) Set(val bool) {\\n\\tatomic.StoreInt32((*int32)(ab), boolToInt(val))\\n}\\n\\n```\\n\\n### Function Type Aliases\\n\\nA go feature which can surprise developers is the ability to add function definitions to funcs.\\nThe Event API in the Processor example above could be extended as follows:\\n\\n```\\ntype Event interface {\\n\\tHandle(*Processor)\\n}\\n\\ntype EventF func(*Processor)\\n\\nfunc (self EventF) Handle(p *Processor) {\\n\\tself(p)\\n}\\n```\\n\\nThe `Invalidate` code could now be written as:\\n\\n```\\nfunc (self *Processor) Invalidate(k string) {\\n\\tself.queueEvent(EventF(func(processor *Processor) {\\n\\t\\tdelete(processor.cache, k)\\n\\t}))\\n}\\n```\\n\\nThe need for an `EventF` cast could be removed by adding a helper function.\\n\\n```\\nfunc (self *Processor) queueEventF(evt EventF) {\\n\\tself.queueEvent(evt)\\n}\\n\\nfunc (self *Processor) UpdateCache(k, v string) {\\n\\tself.queueEventF(func(processor *Processor) {\\n\\t\\tprocessor.cache[k] = v\\n\\t})\\n}\\n```\\n\\nI first encountered this style in the go http library where handlers can be defined\\nas structs implementing `Handler` or as functions matching `HandlerFunc`. This is\\nmost useful when you may have both heavy implementations which carry a lot of state\\nas well as very simple implementations which make more sense as a function.\\n\\nThe processor event channel could also be implemented in terms of pure functions, if\\nall event implementations are lightweight.\\n\\n## Interfaces\\n\\nA golang limitation that often trips people up is that packages cannot have circular\\ndependencies. There are a few ways to work around this, but the most common is to \\nintroduce interfaces in the more independent of the packages.\\n\\n## Errors \\n\\nIn some situations, go\'s error handling can be excessively verbose. Especially in \\ncases where you\'re doing a series of I/O operations, your code can look something\\nlike:\\n\\n\\n```\\nfunc WriteExample(w io.Writer) error {\\n\\tif _, err := w.Write([]byte(\\"one\\")); err != nil {\\n\\t\\treturn err\\n\\t}\\n\\tif _, err := w.Write([]byte(\\"two\\")); err != nil {\\n\\t\\treturn err\\n\\t}\\n\\tif _, err := w.Write([]byte(\\"three\\")); err != nil {\\n\\t\\treturn err\\n\\t}\\n\\tif _, err := w.Write([]byte(\\"four\\")); err != nil {\\n\\t\\treturn err\\n\\t}\\n\\treturn nil\\n}\\n```\\n\\nOne way to clean this up is to wrap the error in the operation and only check it at \\nthe end.\\n\\n```\\ntype WriterErr struct {\\n\\terr error\\n\\tw io.Writer\\n}\\n\\nfunc (self *WriterErr) Write(s string) {\\n\\tif self.err == nil {\\n\\t\\t_, self.err = self.w.Write([]byte(s))\\n\\t}\\n}\\n\\nfunc (self *WriterErr) Error() error {\\n\\treturn self.err\\n}\\n\\nfunc WriteExample2(w io.Writer) error {\\n\\twriter := &WriterErr{w: w}\\n\\twriter.Write(\\"one\\")\\n\\twriter.Write(\\"two\\")\\n\\twriter.Write(\\"three\\")\\n\\twriter.Write(\\"four\\")\\n\\treturn writer.Error()\\n}\\n```\\n\\nSee also: \\n* https://go.dev/blog/errors-are-values\\n* https://dave.cheney.net/2019/01/27/eliminate-error-handling-by-eliminating-errors\\n\\nNote: This pattern is could be viewed as an error monad implementation\\n\\n## Gotchas\\n\\n### Loop Variables[^cam]\\n\\nLike many other languages, it\'s possible to get into trouble when capturing loop variables,\\nboth via pointer references and via closures.\\n\\nThe following snippet will print out `world world` since the loop variable\\nremains constant throughout loop iteration.\\n\\n```\\nfunc main() {\\n\\tvar list []*string\\n\\tfor _, v := range []string {\\"hello\\", \\"world\\"} {\\n\\t\\tlist = append(list, &v)\\n\\t}\\n\\tfor _, v := range list {\\n\\t\\tfmt.Printf(\\"%v \\", *v)\\n\\t}\\n\\tfmt.Println()\\n}\\n```\\n\\nSimilarly, the following will output `second second`:\\n\\n```\\nfunc main() {\\n\\tfor _, v := range []string {\\"first\\", \\"second\\"} {\\n\\t\\tgo func() {\\n\\t\\t\\ttime.Sleep(100 * time.Millisecond)\\n\\t\\t\\tfmt.Printf(\\"%v \\", v)\\n\\t\\t}()\\n\\t}\\n\\ttime.Sleep(200 *time.Millisecond)\\n\\tfmt.Println()\\n}\\n```\\n\\n### Common Deadlock Causes\\n\\n#### Non-reentrant Mutexes\\n\\nUnlike in some other languages, the mutexes provide in the sync package are non-reentrant. So if your code\\ngrabs a lock and ends up calling back into something which gets the same lock, the goroutine will deadlock.\\nTypically, if you have to call back in, you\'d either need an indicator that the lock is already acquired,\\nor do the work in a new go-routine, depending on how independent the second access was.\\n\\n#### Channel Deadlocks\\n\\nIf you have a goroutine processing events from a channel, if the event submits an event back onto the channel,\\nthat can cause a deadlock, if the channel is not buffered, or if the buffer is full.\\n\\nFixes include:\\n* Running the next event in-line, if you can detect that you\'re already in the event processing context\\n* Ensure the channel is buffer is big enough that it will never block\\n* Handing the new event submission off to a new go-routine\\n\\nOne benefit to keeping your channel buffers at zero, is that you will detect these deadlocks very quickly.\\nIf you have a small buffer, then the deadlock may not be caught until the system is under load.\\n\\n[^cam]: Suggested by Cameron Otts"},{"id":"/wildcard-dns/cheatsheet","metadata":{"permalink":"/blog/wildcard-dns/cheatsheet","source":"@site/blog/wildcard-dns/cheatsheet.md","title":"Wildcard DNS Cheatsheet","description":"","date":"2023-01-26T20:49:40.000Z","formattedDate":"January 26, 2023","tags":[],"readingTime":1.71,"hasTruncateMarker":false,"authors":[{"name":"Clint Dovholuk","title":"OpenZiti Maintainer","url":"https://github.com/dovholuknf","imageURL":"https://avatars.githubusercontent.com/u/46322585?v=4","key":"dovholuknf"}],"frontMatter":{"authors":"dovholuknf"},"prevItem":{"title":"Golang Aha! Moments","permalink":"/blog/golang-aha/article"},"nextItem":{"title":"Zitification","permalink":"/blog/zitification"}},"content":"```bash\\r\\n# ------------- start docker \\r\\ndocker-compose up\\r\\n\\r\\n# access the docker controller to create the necessary overlay\\r\\ndocker exec -it docker_ziti-controller_1 bash\\r\\n\\r\\n# ------------- log into the ziti cli\\r\\nzitiLogin\\r\\n\\r\\n# ------------- make at least one router to be public \\r\\nziti edge update edge-router ziti-edge-router -a \\"public\\"\\r\\n\\r\\n# ------------- allow all identities to use any edge router with the attribute \\"public\\"\\r\\nziti edge delete edge-router-policy all-endpoints-public-routers \\r\\nziti edge create edge-router-policy all-endpoints-public-routers --edge-router-roles \\"#public\\" --identity-roles \\"#all\\"\\r\\n\\r\\n# ------------- allows all edge-routers to access all services\\r\\nziti edge delete service-edge-router-policy all-routers-all-services\\r\\nziti edge create service-edge-router-policy all-routers-all-services --edge-router-roles \\"#all\\" --service-roles \\"#all\\"\\r\\n\\r\\nziti edge delete identity zititunneller-blue\\r\\nziti edge create identity device zititunneller-blue -o blue.jwt\\r\\nziti edge enroll blue.jwt\\r\\n\\r\\n# ------------- create a client - probably won\'t commit\\r\\nziti edge create identity device zdewclint -o zdewclint.jwt\\r\\n\\r\\n# from outside docker:\\r\\ndocker cp docker_ziti-controller_1:/openziti/zdewclint.jwt /mnt/v/temp/\\r\\n\\r\\n\\r\\n# attach a wholly different docker container with NET_ADMIN priv\\r\\n# so we can make a tun and provide access to the __blue__ network\\r\\ndocker run --cap-add=NET_ADMIN --device /dev/net/tun --name ziti-tunneler-blue --user root --network docker_zitiblue -v docker_ziti-fs:/openziti --rm -it openziti/quickstart /bin/bash\\r\\n\\r\\n# ------------- zititunneller-blue\\r\\napt install wget unzip\\r\\nwget https://github.com/openziti/ziti-tunnel-sdk-c/releases/latest/download/ziti-edge-tunnel-Linux_x86_64.zip\\r\\nunzip ziti-edge-tunnel-Linux_x86_64.zip\\r\\nclear\\r\\n./ziti-edge-tunnel run -i blue.json\\r\\n\\r\\n\\r\\nziti edge delete config \\"basic.dial\\"\\r\\nziti edge create config \\"basic.dial\\" intercept.v1 \'{\\"protocols\\":[\\"tcp\\"],\\"addresses\\":[\\"simple.web.test\\"], \\"portRanges\\":[{\\"low\\":80, \\"high\\":80}]}\'\\r\\n\\r\\nziti edge delete config \\"basic.bind\\"\\r\\nziti edge create config \\"basic.bind\\" host.v1      \'{\\"protocol\\":\\"tcp\\", \\"address\\":\\"web-test-blue\\",\\"port\\":8000}\'\\r\\n\\r\\nziti edge delete service \\"basic.web.test.service\\"\\r\\nziti edge create service \\"basic.web.test.service\\" --configs \\"basic.bind,basic.dial\\"\\r\\n\\r\\nziti edge delete service-policy basic.web.test.service.bind.blue\\r\\nziti edge create service-policy basic.web.test.service.bind.blue Bind --service-roles \\"@basic.web.test.service\\" --identity-roles \\"@zititunneller-blue\\"\\r\\n\\r\\nziti edge delete service-policy basic.web.test.service.dial.zdew\\r\\nziti edge create service-policy basic.web.test.service.dial.zdew Dial --service-roles \\"@basic.web.test.service\\" --identity-roles \\"@zdewclint\\"\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nziti edge delete config \\"wildcard.dial\\"\\r\\nziti edge create config \\"wildcard.dial\\" intercept.v1 \'{\\"protocols\\":[\\"tcp\\"],\\"addresses\\":[\\"*.blue\\"], \\"portRanges\\":[{\\"low\\":8000, \\"high\\":8000}]}\'\\r\\n\\r\\nziti edge delete config \\"wildcard.bind\\"\\r\\nziti edge create config \\"wildcard.bind\\" host.v1      \'{\\"forwardProtocol\\":true, \\"allowedProtocols\\":[\\"tcp\\",\\"udp\\"], \\"forwardAddress\\":true, \\"allowedAddresses\\":[\\"*.blue\\"], \\"forwardPort\\":true, \\"allowedPortRanges\\":[ {\\"low\\":1,\\"high\\":32768}] }\'\\r\\n\\r\\nziti edge delete service \\"wildcard.web.test.service\\"\\r\\nziti edge create service \\"wildcard.web.test.service\\" --configs \\"wildcard.bind,wildcard.dial\\"\\r\\n\\r\\nziti edge delete service-policy wildcard.web.test.service.bind.blue\\r\\nziti edge create service-policy wildcard.web.test.service.bind.blue Bind --service-roles \\"@wildcard.web.test.service\\" --identity-roles \\"@zititunneller-blue\\"\\r\\n\\r\\nziti edge delete service-policy wildcard.web.test.service.dial.zdew\\r\\nziti edge create service-policy wildcard.web.test.service.dial.zdew Dial --service-roles \\"@wildcard.web.test.service\\" --identity-roles \\"@zdewclint\\"\\r\\n```"},{"id":"/zitification","metadata":{"permalink":"/blog/zitification","source":"@site/blog/zitification/index.md","title":"Zitification","description":"\\"Zitification\\" or \\"zitifying\\" is the act of taking an application and incorporating a Ziti SDK into that application. Once an","date":"2023-01-26T20:49:40.000Z","formattedDate":"January 26, 2023","tags":[],"readingTime":1.185,"hasTruncateMarker":false,"authors":[{"name":"Clint Dovholuk","title":"OpenZiti Maintainer","url":"https://github.com/dovholuknf","imageURL":"https://avatars.githubusercontent.com/u/46322585?v=4","key":"dovholuknf"}],"frontMatter":{"authors":"dovholuknf"},"prevItem":{"title":"Wildcard DNS Cheatsheet","permalink":"/blog/wildcard-dns/cheatsheet"},"nextItem":{"title":"Zitifying Kubectl","permalink":"/blog/zitification/kubernetes"}},"content":"\\"Zitification\\" or \\"zitifying\\" is the act of taking an application and incorporating a Ziti SDK into that application. Once an\\r\\napplication has a Ziti SDK incorporated into it, that application can now access network resources securely from anywhere in\\r\\nthe world provided that the computer has internet access: NO VPN NEEDED, NO ADDITIONAL SOFTWARE NEEDED.\\r\\n\\r\\nIntegrating a Ziti SDK into your application and enrolling the application itself into a Ziti Network provides you with *\\r\\ntremendous* additional security. An application using a [Ziti Network][2] configured with a truly zero-trust mindset will be\\r\\n**IMMUNE** to the \\"expand/multiply\\" phases of classic [ransomware attacks][1]. As recent events have shown, it\'s probably not\\r\\na case of if your application will be attacked, but when.\\r\\n\\r\\nIn these posts we\'re going to explore how common applications can be \\"zitified\\". The first application we are going to focus\\r\\non will be `ssh` and it\'s corollary `scp`. At first, you might think, \\"why even bother\\" zitifying (of all things) `ssh`\\r\\nand `scp`? These applications are vital to system administration, and we have been using `ssh` and\\r\\n`scp` \\"safely\\" on the internet for years. Hopefully you\'re now interested enough to find out in the first post:\\r\\n[zitifying ssh][3]\\r\\n\\r\\nIf you\'d prefer to read about other zitifications, a running list of zitified apps will be updated below:\\r\\n\\r\\n* [ssh->zssh][3]\\r\\n* [scp->zscp][4]\\r\\n* [Kubernetes cluster manager - kubectl][5]\\r\\n\\r\\n[1]: https://netfoundry.io/ztna-ransomware/\\r\\n[2]: /docs/learn/introduction/\\r\\n[3]: /blog/zitification/zitifying-ssh/\\r\\n[4]: /blog/zitification/zitifying-scp/\\r\\n[5]: /blog/zitification/kubernetes/"},{"id":"/zitification/kubernetes","metadata":{"permalink":"/blog/zitification/kubernetes","source":"@site/blog/zitification/kubernetes/index.md","title":"Zitifying Kubectl","description":"The previous post showed how to use a zero trust overlay like Ziti for transferring files by zitifying scp. Next up in the list of zitifications is kubectl. Kubernetes is a container orchestration system. Its purpose is to deploy, scale, and manage the deployment containers. Containers are self-contained, pre-built images of software generally with a singular purpose. Developers often like using containers for various reasons. One major reason developers like containers is because it simplifies the deployment of the solutions they are developing. This is where Kubernetes starts to come into focus.","date":"2023-01-26T20:49:40.000Z","formattedDate":"January 26, 2023","tags":[],"readingTime":12.22,"hasTruncateMarker":false,"authors":[{"name":"Clint Dovholuk","title":"OpenZiti Maintainer","url":"https://github.com/dovholuknf","imageURL":"https://avatars.githubusercontent.com/u/46322585?v=4","key":"dovholuknf"}],"frontMatter":{"authors":"dovholuknf"},"prevItem":{"title":"Zitification","permalink":"/blog/zitification"},"nextItem":{"title":"Kubernetes Cheatsheet","permalink":"/blog/zitification/kubernetes/kubernetes-oci"}},"content":"The [previous post][1] showed how to use a zero trust overlay like Ziti for transferring files by zitifying `scp`. Next up in the list of zitifications is `kubectl`. [Kubernetes][2] is a container orchestration system. Its purpose is to deploy, scale, and manage the deployment containers. Containers are self-contained, pre-built images of software generally with a singular purpose. [Developers often like using containers for various reasons][13]. One major reason developers like containers is because it simplifies the deployment of the solutions they are developing. This is where Kubernetes starts to come into focus.\\r\\n\\r\\nIn this article we\'ll use a cloud provider to create a Kubernetes cluster to use. I\'m using Oracle OKE in this article but there are [numerous Kubernetes providers][14] and any of them will work but clearly the commands I\'m running here are Oracle specific. Once created we will then access the cluster three ways:\\r\\n\\r\\n1. Via the public Kubernetes API secured via mTLS. This is the default, out-of-the-box mechanism provided by Kubernetes.\\r\\n2. Via a tunneling app. I run Windows, so I\'ll use the Ziti Desktop Edge for Windows.\\r\\n3. Via a zitified `kubectl`. Here\'s where we\'ll get to see the power of a truly zitified application. We\'ll be able to access our cluster extremely securely using the Ziti overlay network without installing an additional agent. Once access to the cluster comes entirely from the [Ziti Network][8], we will be able to turn public access to the Kubernetes management API **off** entirely!\\r\\n\\r\\n***\\r\\n\\r\\n## About Kubernetes\\r\\n\\r\\nIf you are not already familiar with Kubernetes then it\'s probably best for you to stop reading and learn a little about it first. Though this article only expects you to understand the most rudimentary of commands, it won\'t teach you enough about Kubernetes to understand the what\'s and why\'s. Lots of documentation on this topic already exist and are just a search away in your search engine of choice.\\r\\n\\r\\nKubernetes itself is not a container engine, it\'s an orchestrator. This means that Kubernetes knows how to interface with container engines to perform deployments and management of workloads on the behalf of operators. This provides people with a common abstraction to use when doing this management and deployment. Interacting with the Kubernetes API is made easy by using the command-line tool: `kubectl`.\\r\\n\\r\\n[kubectl][4] provides numerous commands and utilities to interact with your Kubernetes cluster. It does this by creating REST requests to a well-known endpoint. This endpoint is a highly-valuable target as it is the entry-point to the cluster. Plenty of blogs exist already on the internet addressing how to secure this endpoint but in this post we\'ll take it one step further than ever before by removing the Kubernetes control plane from the internet entirely. Following that we will even go one step further by replacing the existing `kubectl` command with a zero-trust implementation leveraging the ziti golang sdk.\\r\\n\\r\\nIf you\'d prefer to watch a video that goes over the same content contained in the rest of this article you can go ahead and click here to watch.\\r\\n\\r\\n[![Secure Kubernetes](https://img.youtube.com/vi/CRoansolpR0/0.jpg)](https://youtu.be/CRoansolpR0)\\r\\n\\r\\n* * *\\r\\n\\r\\n## Setup\\r\\n\\r\\nBelow is an overview of the [Ziti Network][8] I created for this article. On the left you can see that the client, my computer, runs Windows 10. Inside Windows 10 I run linux and bash using Ubuntu via [Windows Subsystem For Linux (WSL)][5]. If you run Windows and don\'t have WSL installed I would encourage you to install and learn it!  In my bash shell I have downloaded the linux version of `kubectl` created by combining the Ziti Golang SDK into it. You can grab it from [this link][6] if you like or go check out [the code on GitHub][7] and build it yourself! :)\\r\\n\\r\\n### Solution Overview\\r\\n\\r\\n![private-kubernetes.svg](./private-kubernetes.svg)\\r\\n\\r\\n### Basic Ziti Setup\\r\\n\\r\\nTo accomplish our stated goals, we will need not only an existing [Ziti Network][8] but we\'ll also have to configure that network accordingly. Here\'s a list of the components necessary to deliver Kubernetes with our zero-trust network:\\r\\n\\r\\n1. A configuration for the `Bind` side of the service. This informs the identity within Kubernetes where to send traffic and how.\\r\\n2. A configuration for the `Dial` side of the service. This is strictly **only** necessary for tunneling apps. In this example, for the Ziti Desktop Edge for Windows and specifies what host and port will be intercepted on the machine running the stock `kubectl`. for Windows.\\r\\n3. The service itself which ties our polices mentioned above together.\\r\\n4. A `Bind` service-policy which specifies which identities are allowed to act as a \\"host\\" for the service (meaning an identity to send traffic to which knows where and how to offload that traffic). In our example this will be the `ziti-edge-tunnel` running in a Kubernetes pod.\\r\\n5. A `Dial` service-policy which specifies the identities allowed to access the service. This will be the identity using\\r\\n   `kubectl`.\\r\\n6. Create two identities - one for the `Bind` side of the service (deployed within the Kubernetes cluster) and one for the `Dial` or client side.\\r\\n\\r\\nHere are some example commands using the [ziti cli][9] which illustrate how to create these services. Some things of note worth mentioning. I\'m setting a variable to make my configuration easier. I reuse these code blocks a lot and by extracting some variables it makes it easy for me to delete/recreate services. First I set the `service_name`\\r\\nvariable. I use this variable in all the names of the Ziti objects I create just to make it more clear and obvious if I have to look back at my configuration again.\\r\\n\\r\\nSince I\'m going to be accessing my Kubernetes API which I\'ve deployed using the Oracle cloud I chose to use `k8s.oci`\\r\\nas my service name. When deployed by a cloud provider, the Kubernetes API is generated or updated with numerous SANS and IP address I can choose from to represent the `Dial` side which will be intercepted by the Ziti Desktop Edge for Windows. The Oracle cloud console informs me that the private IP of `10.0.0.6` was assigned to my cluster when I click on the \'Access Cluster\' button which is why I chose to use that value below. I could have chosen to use any of the DNS names provided by OKE. There are at least five I could choose from, all visible as SANS on the cert that the server returns: `kubernetes`, `kubernetes.default`, `kubernetes.default.svc`, `kubernetes.default.svc.cluster`\\r\\n, `kubernetes.default.svc.cluster.local`. I chose the IP since it\'s pretty obvious that it\'s an internal IP, not on my local network. Also worth pointing out is that I\'m mapping the port as well, changing it from the port that the server provides, 6443, to the common HTTPS port of 443 for the local intercept. With zitified `kubectl` we don\'t even need these intercepts, but we\'ll keep it here so that we can use the unmodified `kubectl` as well. Finally, these commands are all executed inside a bash shell since I\'m using WSL.\\r\\n\\r\\n#### Example Ziti CLI commands\\r\\n```bash\\r\\n# the name of the service\\r\\nservice_name=k8s.oci\\r\\n# the name of the identity you\'d like to see on the kubectl client\\r\\nthe_user_identity=\\"${service_name}\\".client\\r\\n# the name of the identity deployed into the kubernetes cluster\\r\\nthe_kubernetes_identity=\\"${service_name}\\".private\\r\\n\\r\\nziti edge create config \\"${service_name}\\"-host.v1 host.v1 \\\\\\r\\n    \'{\\"protocol\\":\\"tcp\\", \\"address\\":\\"10.0.0.6\\",\\"port\\":6443 }\'\\r\\n    \\r\\nziti edge create config \\"${service_name}\\"-client-config intercept.v1 \\\\\\r\\n    \'{\\"protocols\\":[\\"tcp\\"],\\"addresses\\":[\\"10.0.0.6\\",\\"kubernetes\\"], \\"portRanges\\":[{\\"low\\":443, \\"high\\":443}]}\'\\r\\n    \\r\\nziti edge create service \\\\\\r\\n    \\"${service_name}\\" \\\\\\r\\n    --configs \\"${service_name}\\"-client-config,\\"${service_name}\\"-host.v1\\r\\n    \\r\\nziti edge create service-policy \\"${service_name}\\"-binding Bind \\\\\\r\\n    --service-roles \'@\'\\"${service_name}\\" \\\\\\r\\n    --identity-roles \'#\'\\"${service_name}\\"\'ServerEndpoints\'\\r\\n    \\r\\nziti edge create service-policy \\"${service_name}\\"-dialing Dial \\\\\\r\\n    --service-roles \'@\'\\"${service_name}\\" \\\\\\r\\n    --identity-roles \'#\'\\"${service_name}\\"\'ClientEndpoints\'\\r\\n    \\r\\nziti edge create identity device \\"${the_kubernetes_identity}\\" \\\\\\r\\n    -a \\"${service_name}\\"ServerEndpoints \\\\\\r\\n    -o \\"${the_kubernetes_identity}\\".jwt\\r\\n    \\r\\nziti edge create identity device \\"${the_user_identity}\\" \\\\\\r\\n    -a \\"${service_name}\\"ClientEndpoints \\\\\\r\\n    -o \\"${the_user_identity}\\".jwt\\r\\n```\\r\\n\\r\\n## Kubernetes Config Files\\r\\n\\r\\nOnce we have established the pieces of the [Ziti Network][8], we\'ll want to get the Kubernetes config files from OKE so that we can test access, make sure the cluster works etc. Oracle provides a CLI command which makes it pretty easy to get those config files called `oci`. As of this writing - the guide from [Oracle is here][10]. Once `oci` is installed and configured the Oracle cloud gives you very easy commands to run which will generate two files. One file will be for accessing the Kubernetes API through the public endpoint. The other will get you the file for private access. We\'re going to want both since we\'re on a journey here from \\"public API endpoint\\" to tunneling-app-based access, to the final stage of app-embedded zero-trust directly into `kubeztl`.\\r\\n\\r\\n### Getting the Kubernetes Config Files\\r\\n\\r\\nNotice that we are changing the file location output by these commands and they are being output as two separate Kubernetes config files. If you prefer to merge them all into one big config file and change contexts - feel free. I left them as separate files here because it provides a very clear separation as to which config is being used or modified.\\r\\n```bash\\r\\n# Get this value directly from Oracle\\r\\noci_cluster_id=\\"put-your-cluster-id-here\\"\\r\\n\\r\\noci ce cluster create-kubeconfig \\\\\\r\\n    --cluster-id ${oci_cluster_id} \\\\\\r\\n    --file /tmp/oci/config.oci.public \\\\\\r\\n    --region us-ashburn-1 \\\\\\r\\n    --token-version 2.0.0 \\\\\\r\\n    --kube-endpoint PUBLIC_ENDPOINT\\r\\nchmod 600 /tmp/oci/config.oci.public\\r\\n    \\r\\noci ce cluster create-kubeconfig \\\\\\r\\n    --cluster-id ${oci_cluster_id} \\\\\\r\\n    --file /tmp/oci/config.oci.private \\\\\\r\\n    --region us-ashburn-1 \\\\\\r\\n    --token-version 2.0.0 \\\\\\r\\n    --kube-endpoint PRIVATE_ENDPOINT\\r\\nchmod 600 /tmp/oci/config.oci.private\\r\\n```\\r\\n\\r\\n## Connecting the Pieces\\r\\n\\r\\nAt this point we should have all the pieces in place so that we can start putting them together to test the overall solution. In this section we\'ll access our public Kubernetes api to make sure it works. Then we\'ll install Ziti into the Kubernetes cluster and verify private access works. Finally we\'ll disable public access **entirely** and use the zitified `kubeztl` command to access the cluster with true, app-embedded zero-trust binary.\\r\\n\\r\\n### Testing the Public API\\r\\n\\r\\nThis step is very straight-forward for anyone who\'s used Kubernetes before. Issue the following commands, making sure the path is correct for your public Kubernetes config file, and verify Kubernetes works as expected.\\r\\n```bash\\r\\nexport KUBECONFIG=/tmp/oci/config.oci.public\\r\\nkubectl get pods -v6 --request-timeout=\'5s\'\\r\\nI1019 13:57:31.910962    3211 loader.go:372] Config loaded from file:  /tmp/oci/config.oci.public\\r\\nI1019 13:57:33.676047    3211 round_trippers.go:454] GET https://150.230.150.0:6443/api/v1/namespaces/default/pods?limit=500&timeout=5s 200 OK in 1752 milliseconds\\r\\nNAME                                        READY   STATUS    RESTARTS   AGE\\r\\n```\\r\\nIf your output looks something similar to the above (with or without the pods you expect to see) then great! That means your Kubernetes cluster is indeed up and running. Let\'s move on!\\r\\n\\r\\n#### Deploying Ziti to Kubernetes\\r\\n\\r\\nNext we\'ll grab a few lines from the excellent guide NetFoundry put out for integrating with Kubernetes. There\'s a section in that guide for [installing Ziti with Helm][11]. This comes down to just these steps:\\r\\n\\r\\n1. install the `helm` CLI tool [using this guide][12]\\r\\n2. add the NetFoundry helm repo: `helm repo add netfoundry https://netfoundry.github.io/charts/`\\r\\n3. locate the jwt file for the Kubernetes identity. If you followed the steps above the file will be named: `\\"${the_kubernetes_identity}\\".jwt` (make sure you replace the variable with the correct value)\\r\\n4. use the jwt to add Ziti: `helm install ziti-host netfoundry/ziti-host --set-file enrollmentToken=\\"${the_kubernetes_identity}\\".jwt` (again make sure you replace the variable name) If you need to, make sure you create a persistent volume. The ziti pod requires storage to store a secret.\\r\\n```bash\\r\\napiVersion: v1\\r\\nkind: PersistentVolume\\r\\nmetadata:\\r\\n  name: ziti-host-pv\\r\\n  labels:\\r\\n    type: local\\r\\nspec:\\r\\n  storageClassName: oci\\r\\n  capacity:\\r\\n    storage: 100Mi\\r\\n  accessModes:\\r\\n    - ReadWriteMany\\r\\n  hostPath:\\r\\n    path: \\"/netfoundry\\"\\r\\n```\\r\\n\\r\\n#### Add/Enroll the Client Identity\\r\\n\\r\\nNow consume the one time token (the jwt file) to enroll and create a client-side identity using the Ziti Desktop Edge for Windows (or MacOS or via the `ziti-edge-tunnel` if you prefer). Once you can see the identity in your tunneling app, you should be able to use the private kubernetes config file to access the same exact cluster. Remember though, we have mapped the port on the client side to use 443. That means you\'ll need to update your config file and change 6443 --\x3e 443. Now when you run `get pods` you\'ll see the ziti-host pod deployed:\\r\\n```bash\\r\\nexport KUBECONFIG=/tmp/oci/config.oci.private\\r\\nkubectl get pods\\r\\nNAME                        READY   STATUS    RESTARTS   AGE\\r\\nziti-host-976b84c66-kr4bc   1/1     Running   0          90m\\r\\n```\\r\\n\\r\\n## The Big Finale - Zitified kubectl\\r\\n\\r\\nIf you have made it this far, you\'ve seen us access the Kubernetes API via the public IP. We\'ve even accessed it via the private IP (which btw - is pretty cool in my opinion!). Now we\'re going to download the zitified kubectl command, turn off the public IP and even turn off the locally running tunneling app and still access the API!\\r\\n\\r\\n1. Disable the cluster\'s public IP address in OKE (go to the cluster in Oracle Cloud, click Edit and remove the public IP and click save)\\r\\n2. Turn off the Ziti Desktop Edge for Windows\\r\\n3. Download `kubeztl` (you don\'t need to call the executable `kubeztl` - you can keep it named `kubectl` if you want)\\r\\n```bash\\r\\ncurl -L -o kubeztl https://github.com/openziti-incubator/kubectl/releases/download/v0.0.4/kubectl-linux-amd64\\r\\n```\\r\\n4. Use `kubeztl` to get pods!\\r\\n```bash\\r\\n./kubeztl get pods -c id.json -S k8s.oci\\r\\nNAME                        READY   STATUS    RESTARTS   AGE\\r\\nziti-host-976b84c66-kr4bc   1/1     Running   0          101m\\r\\n```\\r\\n### Modifying KUBECONFIG\\r\\n\\r\\nThe `kubeztl` command has also been modified to allow you to add the service name and config file directly into the file itself. This is convenient since you will not need to supply the ziti identity file, nor will you need to specify which service to use. Modifying the file is straight-forward. Open the config file, find the context listed under the contexts root and add two rows as shown here.\\r\\n```bash\\r\\ncontexts\\r\\n- context:\\r\\n    cluster: cluster-cjw4arxuolq\\r\\n    user: user-cjw4arxuolq\\r\\n    zConfig: /tmp/oci/k8s.id.json\\r\\n    service: k8s.oci\\r\\n```\\r\\n\\r\\nOnce done - you can now simply use the context the same way you have always - `kubeztl get pods`!!!\\r\\n```bash\\r\\n./kubeztl get pods\\r\\nNAME                        READY   STATUS    RESTARTS   AGE\\r\\nziti-host-976b84c66-kr4bc   1/1     Running   0          114m\\r\\n```\\r\\n\\r\\n## Conclusion\\r\\n\\r\\nWe\'ve seen in this post how you can not only secure your Kubernetes API with the normal Kubernetes mechanisms. You can also take your Kubernetes API off the internet **ENTIRELY**. No need to deploy and maintain a special bastian node. Now by having a secure, zero-trust overlay in place you can safely and securely access your Kubernetes API without the fear of that public, high-value API getting attacked.\\r\\n\\r\\n![But Wait, There\'s More](https://i.imgur.com/JRBQMkN.jpg)\\r\\n\\r\\nOnce you\'ve deployed Ziti into the Kubernetes cluster you\'re not done there. Now you can also use Ziti to span cloud networks. You can use it to easily link private data centers or other private Kubernetes clusters all into one secure, zero-trust overlay network! Use Ziti to expose workloads that are **TRULY** private!  In future articles we might explore how we can bring Ziti to bear on these topics, stay tuned!\\r\\n***\\r\\n\\r\\n[1]: /blog/zitification/zitifying-scp/\\r\\n\\r\\n[2]: https://Kubernetes.io/\\r\\n\\r\\n[3]: ./private-kubernetes.svg\\r\\n\\r\\n[4]: https://Kubernetes.io/docs/reference/kubectl/overview/\\r\\n\\r\\n[5]: https://docs.microsoft.com/en-us/windows/wsl/install\\r\\n\\r\\n[6]: https://github.com/openziti-incubator/kubectl/releases/latest/download/kubectl-linux-amd64\\r\\n\\r\\n[7]: https://github.com/openziti-incubator/kubectl\\r\\n\\r\\n[8]: /docs/learn/introduction/\\r\\n\\r\\n[9]: https://github.com/openziti/ziti/releases/latest\\r\\n\\r\\n[10]: https://docs.oracle.com/en-us/iaas/Content/API/SDKDocs/cliinstall.htm\\r\\n\\r\\n[11]: https://developer.netfoundry.io/guides/kubernetes/#install-ziti-with-helm\\r\\n\\r\\n[12]: https://helm.sh/docs/intro/install/\\r\\n\\r\\n[13]: https://appfleet.com/blog/10-reasons-why-developers-love-docker/\\r\\n\\r\\n[14]: https://www.google.com/search?q=kubernetes+cloud+providers&oq=kubernetes+cloud+providers"},{"id":"/zitification/kubernetes/kubernetes-oci","metadata":{"permalink":"/blog/zitification/kubernetes/kubernetes-oci","source":"@site/blog/zitification/kubernetes/kubernetes-oci.md","title":"Kubernetes Cheatsheet","description":"This page exists as the set of commands which were used in the video Secure Kubernetes Cluster using Ziti","date":"2023-01-26T20:49:40.000Z","formattedDate":"January 26, 2023","tags":[],"readingTime":3.79,"hasTruncateMarker":false,"authors":[{"name":"Clint Dovholuk","title":"OpenZiti Maintainer","url":"https://github.com/dovholuknf","imageURL":"https://avatars.githubusercontent.com/u/46322585?v=4","key":"dovholuknf"}],"frontMatter":{"authors":"dovholuknf","title":"Kubernetes Cheatsheet"},"prevItem":{"title":"Zitifying Kubectl","permalink":"/blog/zitification/kubernetes"},"nextItem":{"title":"Enable Prometheus to Scrape Anything from Anywhere","permalink":"/blog/zitification/prometheus/part1"}},"content":"This page exists as the set of commands which were used in the video [Secure Kubernetes Cluster using Ziti][1]\\r\\n\\r\\n### establish some variables just to make commands easier\\r\\n\\r\\n```bash\\r\\nservice_name=k8s.oci\\r\\nthe_user_identity=\\"${service_name}\\".client\\r\\nthe_kubernetes_identity=\\"${service_name}\\".private\\r\\noci_cluster_id=\\"put-your-cluster-id-here\\"\\r\\n```\\r\\n\\r\\n### clean up commands - if needed\\r\\n\\r\\n```bash\\r\\nrm /tmp/oci/config.oci.public\\r\\nrm /tmp/oci/config.oci.private\\r\\nziti edge delete identity \\"${the_kubernetes_identity}\\"\\r\\nziti edge delete identity \\"${the_user_identity}\\"\\r\\n```\\r\\n\\r\\nwork done ahead of time - takes time to establish a cluster:\\r\\n\\r\\n* previously setup kubernetes in OKE\\r\\n  * simple cluster\\r\\n  * standard quick create cluster\\r\\n  * public endpoint\\r\\n  * Shape: VM.Standard2.2\\r\\n  * 1 node\\r\\n  * pasted my public key for access\\r\\n  * exposed the cluster with public ip\\r\\n* already installed oci as well as helm\\r\\n* already deployed a ziti environment using https://openziti.github.io/docs/learn/quickstarts/network/hosted\\r\\n\\r\\n## create kubernetes config files - public and private\\r\\n\\r\\n```bash\\r\\noci ce cluster create-kubeconfig \\\\\\r\\n    --cluster-id ${oci_cluster_id} \\\\\\r\\n    --file /tmp/oci/config.oci.public \\\\\\r\\n    --region us-ashburn-1 \\\\\\r\\n    --token-version 2.0.0 \\\\\\r\\n    --kube-endpoint PUBLIC_ENDPOINT\\r\\nchmod 600 /tmp/oci/config.oci.public\\r\\n    \\r\\noci ce cluster create-kubeconfig \\\\\\r\\n    --cluster-id ${oci_cluster_id} \\\\\\r\\n    --file /tmp/oci/config.oci.private \\\\\\r\\n    --region us-ashburn-1 \\\\\\r\\n    --token-version 2.0.0 \\\\\\r\\n    --kube-endpoint PRIVATE_ENDPOINT\\r\\nchmod 600 /tmp/oci/config.oci.private\\r\\n```\\r\\n\\r\\n### delete any resources if needed\\r\\n\\r\\n```bash\\r\\nexport KUBECONFIG=/tmp/oci/config.oci.public\\r\\nhelm uninstall ziti-host\\r\\nkubectl delete persistentvolume ziti-host-pv\\r\\n```\\r\\n\\r\\n### show it working via public ip from wsl\\r\\n\\r\\n#### wsl\\r\\n\\r\\n```bash\\r\\nexport KUBECONFIG=/tmp/oci/config.oci.public\\r\\nkubectl get pods -v7 --request-timeout=\'5s\'\\r\\n```\\r\\n\\r\\n#### show it failing via private ip from wsl\\r\\n\\r\\n```bash\\r\\nexport KUBECONFIG=/tmp/oci/config.oci.private\\r\\nkubectl get pods -v7 --request-timeout=\'2s\'\\r\\n```\\r\\n\\r\\n### let\'s install ziti in the cluster\\r\\n\\r\\n#### make a new identity\\r\\n\\r\\n```bash\\r\\nziti edge create identity device \\"${the_kubernetes_identity}\\" -a \\"${service_name}\\"ServerEndpoints -o \\"${the_kubernetes_identity}\\".jwt\\r\\nziti edge create identity device \\"${the_user_identity}\\" -a \\"${service_name}\\"ClientEndpoints -o \\"${the_user_identity}\\".jwt\\r\\n```\\r\\n\\r\\n#### Deploying Ziti to Kubernetes\\r\\n\\r\\n1. install the `helm` CLI tool [using this guide](https://helm.sh/docs/intro/install/)\\r\\n2. add the OpenZiti Helm repo:\\r\\n\\r\\n    ```bash\\r\\n    helm repo add openziti https://openziti.github.io/helm-charts/\\r\\n    ```\\r\\n\\r\\n3. locate the jwt file for the Kubernetes identity. If you followed the steps above the file will be named: `\\"${the_kubernetes_identity}\\".jwt` (make sure you replace the variable with the correct value)\\r\\n4. enroll the Kubernetes identity. This exchanges the temporary JWT for a permanent identity JSON file. Several Ziti CLIs have an `enroll` command for this purpose. Here\'s one way to obtain the identity that doesn\'t require you to download a CLI if you already have Docker:\\r\\n\\r\\n    ```bash\\r\\n    # start with JWT file on Docker host in \\r\\n    #  /tmp/${the_kubernetes_identity}.jwt\\r\\n    docker run --rm --volume /tmp:/mnt \\\\\\r\\n        openziti/quickstart /openziti/ziti-bin/ziti edge enroll \\\\\\r\\n        \\"/mnt/${the_kubernetes_identity}.jwt\\"\\r\\n    # now you will have a new file \\r\\n    # /tmp/${the_kubernetes_identity}.json\\r\\n    ```\\r\\n\\r\\n5. use the Kubernetes identity JSON file when you install the Helm chart:\\r\\n\\r\\n    ```bash\\r\\n    helm install ziti-host openziti/ziti-host \\\\\\r\\n        --set-file zitiIdentity=\\"/tmp/${the_kubernetes_identity}.json\\"\\r\\n    ```\\r\\n\\r\\n### verify the ziti identity was bootstrapped by using kubectl logs\\r\\n\\r\\n```bash\\r\\nkubectl logs ziti-host<tab><enter>\\r\\n```\\r\\n\\r\\n---\\r\\n\\r\\nnow go disable the public ip so private access ONLY works... this takes \\"a minute or two or three\\"...\\r\\n\\r\\n---\\r\\n\\r\\n### let\'s setup the ziti bits we need\\r\\n\\r\\nsetup ziti to access the private server address... \\r\\nset environment variables to make it easier to reference:\\r\\n\\r\\n```bash\\r\\nexport KUBECONFIG=/tmp/oci/config.oci.private\\r\\nk8s_private_host_and_port=$(kubectl config view | grep server | cut -d \\"/\\" -f3)\\r\\nk8s_private_host=$(echo ${k8s_private_host_and_port} | cut -d \\":\\" -f1)\\r\\nk8s_private_port=$(echo ${k8s_private_host_and_port} | cut -d \\":\\" -f2)\\r\\necho \\"Private URL: ${k8s_private_host_and_port}, Host: ${k8s_private_host}, Port: ${k8s_private_port}\\"\\r\\n```\\r\\n\\r\\n#### ziti setup\\r\\n\\r\\n```bash\\r\\nk8s_private_dns=kubernetes\\r\\n\\r\\nziti edge delete config \\"${service_name}\\"-host.v1\\r\\nziti edge delete config \\"${service_name}\\"-client-config\\r\\nziti edge delete service \\"${service_name}\\"\\r\\nziti edge delete service-policy \\"${service_name}\\"-binding\\r\\nziti edge delete service-policy \\"${service_name}\\"-dialing\\r\\n\\r\\nziti edge create config \\"${service_name}\\"-host.v1 host.v1 \'{\\"protocol\\":\\"tcp\\", \\"address\\":\\"\'${k8s_private_host}\'\\",\\"port\\":\'${k8s_private_port}\' }\'\\r\\nziti edge create config \\"${service_name}\\"-client-config intercept.v1 \'{\\"protocols\\":[\\"tcp\\"],\\"addresses\\":[\\"\'${k8s_private_host}\'\\",\\"\'${k8s_private_dns}\'\\"], \\"portRanges\\":[{\\"low\\":443, \\"high\\":443}]}\'\\r\\nziti edge create service \\"${service_name}\\" --configs \\"${service_name}\\"-client-config,\\"${service_name}\\"-host.v1\\r\\nziti edge create service-policy \\"${service_name}\\"-binding Bind --service-roles \'@\'\\"${service_name}\\" --identity-roles \'#\'\\"${service_name}\\"\'ServerEndpoints\'\\r\\nziti edge create service-policy \\"${service_name}\\"-dialing Dial --service-roles \'@\'\\"${service_name}\\" --identity-roles \'#\'\\"${service_name}\\"\'ClientEndpoints\'\\r\\n```\\r\\n\\r\\n#### verify windows can access the kubernetes api (using cmd.exe from wsl)\\r\\n\\r\\n```bash\\r\\ncmd.exe /c curl -k \\"https://${k8s_private_dns}\\"\\r\\ncmd.exe /c curl -k \\"https://${k8s_private_host}\\"    \\r\\n```\\r\\n\\r\\n#### at this point from wsl kubectl will work using the ip address - but not dns\\r\\n\\r\\n```bash\\r\\n#enroll the identity\\r\\nziti edge enroll \\"${the_user_identity}\\".jwt\\r\\n\\r\\n# use the identity to get pods:\\r\\n./kubeztl --zConfig \\"${the_user_identity}\\".json --service k8s.oci get pods\\r\\n\\r\\n# update your config to make it so you don\'t need to supply --zConfig or --service\\r\\n# replace \\"${the_user_identity}\\" accordingly:\\r\\nzConfig: /mnt/v/temp/oci/\\"${the_user_identity}\\".json\\r\\nservice: k8s.oci\\r\\n```\\r\\n\\r\\n#### use \\"kubeztl\\"\\r\\n\\r\\n#### download from github\\r\\n\\r\\n```bash\\r\\ncurl -L -o kubeztl https://github.com/openziti-incubator/kubectl/releases/download/v0.0.4/kubectl-linux-amd64 ./kubeztl get pods -c ./id.json -S \\"${service_name}\\"\\r\\n```\\r\\n\\r\\n#### modify config if you want\\r\\n\\r\\nfind your context, add two lines:\\r\\n\\r\\n```bash\\r\\nzConfig: /mnt/v/temp/oci/oci.json\\r\\nservice: k8s.oci\\r\\n```\\r\\n\\r\\n### useful if you need to update either of the identities\\r\\n\\r\\n```bash\\r\\nziti edge update identity \\"${the_user_identity}\\" -a \\"${service_name}\\"ClientEndpoints\\r\\nziti edge update identity \\"${the_kubernetes_identity}\\" -a \\"${service_name}\\"ServerEndpoints\\r\\n```\\r\\n\\r\\n[1]: https://youtu.be/CRoansolpR0"},{"id":"/zitification/prometheus/part1","metadata":{"permalink":"/blog/zitification/prometheus/part1","source":"@site/blog/zitification/prometheus/part1.md","title":"Enable Prometheus to Scrape Anything from Anywhere","description":"_This is part one of a three-part article. This article provides the necessary background and rationale of the series.","date":"2023-01-26T20:49:40.000Z","formattedDate":"January 26, 2023","tags":[],"readingTime":12.27,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"prevItem":{"title":"Kubernetes Cheatsheet","permalink":"/blog/zitification/kubernetes/kubernetes-oci"},"nextItem":{"title":"Configuring OpenZiti to Enable Prometheus","permalink":"/blog/zitification/prometheus/part2"}},"content":"_This is part one of a three-part article. This article provides the necessary background and rationale of the series.\\r\\n[The next article](./part2.md) will be a detailed explanation of the actual steps necessary to implement the solution.\\r\\nIn [the final article](./part3.md), we will explore what we have just created and understand what was just created_\\r\\n\\r\\n---\\r\\n\\r\\n## The Problem With Pulling\\r\\n\\r\\nPrometheus is a server which wants to reach out and pull data from \\"scrape targets\\". It will generally do this using http requests. One\\r\\nproblem with this design is that these targets are often inaccessible, hidden from Prometheus behind a firewall.\\r\\n\\r\\nIf not hidden, it means some port was exposed on some network, thereby giving Prometheus the ability to pull the data it needs. Exposing\\r\\nthat port on a \\"trusted\\" network is a possible attack vector for bad actors. Exposing that port on the open internet (as is often the case)\\r\\nis an open invitation for attack. It\'s much better to keep these servers totally dark to all networks.\\r\\n\\r\\nOpenZiti solves this problem of reach elegantly and natively while also keeping your service dark to all networks. This gives an \\r\\nOpenZiti-enabled Prometheus the ability to literally scrape any target, anywhere. As long as the target is participates on an OpenZiti \\r\\noverlay network, and as long as the proper polices are in place allowing the traffic to flow, Prometheus will be able to reach out and \\r\\npull the data it needs from anything, anywhere.\\r\\n\\r\\nIt doesn\'t matter if the target is in some private cloud data center, some private data center protected by a corporate firewall, or heck\\r\\neven running inside my local docker environment! As long as the target participates on that OpenZiti Prometheus can scrape it! That sort of\\r\\nreach is impossible with classic networks.\\r\\n\\r\\n## Prometheus\\r\\n\\r\\n[Prometheus](https://prometheus.io/) is an incredibly popular [CNCF](https://www.cncf.io/projects/prometheus/)\\r\\nproject which has graduated the gauntlet of progressions to emerge as a \\"graduated\\" CNCF project. If you\'re familiar with Prometheus, there\\r\\nare probably a couple of reasons people mainly choose to deploy it:\\r\\nmetrics collection and visualization and alerting.\\r\\n\\r\\nPrometheus is also tremendously flexible. It has numerous available plugins and supports integrating with a wide number of systems.\\r\\nAccording\\r\\nto [this CNCF survey](https://www.cncf.io/blog/2022/03/08/cloud-native-observability-microsurvey-prometheus-leads-the-way-but-hurdles-remain-to-understanding-the-health-of-systems/)\\r\\n, Prometheus leads the pack when it comes to the project people go to for observability. Its popularity is probably because Prometheus is a\\r\\nCNCF project and is often considered the \\"default\\" solution to deploy on another wildly popular CNCF project\\r\\ncalled [Kubernetes](https://kubernetes.io). One interesting aspect of Prometheus is that it generally favors a poll-based approach to\\r\\nmetrics collection instead of a push-based model.\\r\\n\\r\\n### Poll-based?\\r\\n\\r\\nI don\'t know about you, but historically when I\'ve thought about a metrics collection agent, I tend to think of an agent that reads a log\\r\\nfile or some library that pushes rows into a giant data lake in the cloud. I don\'t generally think about a solution that implements\\r\\npoll-based metrics. Often, this is because the target of a poll-based collecting agent will probably be behind a firewall.\\r\\n\\r\\n![FW](./fw.png)\\r\\n\\r\\nAs you would expect, firewalls make it exceptionally difficult to implement a poll-based solution as firewalls have been known to make a\\r\\nhabit of preventing external actors from accessing random http servers behind it! After all, that is their primary function!\\r\\n\\r\\nThe Prometheus project makes [strong arguments](https://prometheus.io/docs/practices/pushing/) explaining the benefits of a poll-based\\r\\nsolution. They also realize that firewalls are important in creating a safe network and understand the challenges firewalls create for such\\r\\na solution. To deal with these situations, the project also provides a [PushGateway](https://prometheus.io/docs/instrumenting/pushing/).\\r\\nThis allows solutions to push their data to a location outbound of the firewall. Pushing data out of the firewall allows metrics and\\r\\nalerting to function without the worry (and maintenance heartache) of an open, inbound firewall hole.\\r\\n\\r\\n### Acceptable Risk\\r\\n\\r\\nPrometheus is often deployed into Kubernetes clusters, but it can be deployed anywhere. Taking the operational differences out of the\\r\\nequation, there is little difference between deploying Prometheus in a Kubernetes cluster and deploying it in one\'s data center. Once\\r\\ndeployed, the needs will be the same. Prometheus will need to be authorized to reach out and scrape the targets it needs to scrape. All too\\r\\noften, this is done with relatively open network permissions. Even though we all know it\'s not the most secure way of authorizing\\r\\nPrometheus, this is often considered \\"safe enough\\" because we deployed Prometheus into a zone considered \\"safe\\". Managing firewall rules to\\r\\nall the computers Prometheus needs access to, feels like an impossible feat. There are just too many.\\r\\n\\r\\nTo add to our acceptable risk, we will need to be able to access the Prometheus server in some way. We\'ll want to get at the UI, see the\\r\\ncharts and graphs and data it provides and use the server to its fullest. For that, we\'ll **of course**\\r\\nneed a hole in our firewall, or in the case of Kubernetes we will probably deploy some form of \\r\\n[Kubernetes Ingress Controller](https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/) to provide users access \\r\\nthe service.\\r\\n\\r\\nWhat we need are better and richer controls over our network. We need a better way of authorizing Prometheus without the hassle of\\r\\nmaintaining firewall rules on individual machines. We also need a way to do this across multiple clouds, multiple Kubernetes clusters and\\r\\nmultiple data centers. Let\'s see how OpenZiti can solve this problem while also enhancing our overall security.\\r\\n\\r\\n---\\r\\n\\r\\n## OpenZiti\\r\\n\\r\\nThe [OpenZiti](https://openziti.github.io) project allows us to solve all the problems outlined above. It is a fully-featured, zero trust\\r\\noverlay network and enables [zero trust networking principles](https://en.wikipedia.org/wiki/Zero_trust_security_model) to be applied \\r\\nanywhere. This includes bringing those zero trust principles directly into your application through one of the many SDKs provided \\r\\nby the project. Let\'s look at an example and see what a setup might look like before and after applying OpenZiti.\\r\\n\\r\\n### Overview\\r\\n\\r\\nLet\'s imagine that we have already deployed a solution using two Kubernetes clusters, ClusterA and ClusterB. It doesn\'t matter where the\\r\\nclusters are deployed. We are trying to illustrate a real-world situation where we have two separate Kubernetes clusters that we want to\\r\\nmanage. The clusters could be deployed in the same cloud provider, in a private data center, in different cloud providers, it really does\\r\\nnot matter. What is important, is that these clusters are available over the network. To enable access to the workloads inside the \\r\\nclusters, some form of Kubernetes ingress controller will be required on both clusters. In our example, we will have a workload deployed \\r\\nwhich exposes a prometheus scrape target we want Prometheus to monitor.\\r\\n\\r\\n#### Figure 1 - Before OpenZiti\\r\\n\\r\\n![Before OpenZiti](./kubernetes-prometheus-before.svg)\\r\\n\\r\\n### Taking a Closer Look\\r\\n\\r\\nLooking at the diagram above with a discerning eye towards security, there are some immediate observations one can make.\\r\\n\\r\\n#### Listening Ports\\r\\n\\r\\nOne observation we have already accepted from the overview, is that these clusters must be exposed via the internet. At first that doesn\'t \\r\\nseem like a big deal, we expose workloads like this to the internet all the time. This is a perfectly normal action, it\'s likely \\r\\ndone every day somewhere in the world. It\'s so common, we almost don\'t even think about it until the time comes when we **need** to \\r\\nthink about it. This ends up in an exposed port, listening somewhere in the world. There might be a firewall with complex rules to \\r\\nprotect this port, but it\'s just as likely that this isn\'t the case. People might need to access the resources inside these clusters \\r\\nfrom anywhere. \\r\\n\\r\\n#### Kubernetes API Exposed\\r\\n\\r\\nAnother observation is that the Kubernetes API is fully exposed to the internet. This API is a very high-value target and should be \\r\\nsecured as strongly as possible. That probably means yet another complex firewall rule to maintain.\\r\\n\\r\\n#### \\"Trusted\\" Intra-cluster Traffic\\r\\n\\r\\nThe final point to note is that the traffic within the cluster is considered safe. As mentioned above, the Prometheus server needs to be\\r\\nable to scrape the target workloads. That traffic is necessary to be considered safe. Also, notice that the pod for Prometheus contains a\\r\\ncontainer named \\"configmap-reload\\" which is used to trigger a webhook on the Prometheus server when the\\r\\n[Kubernetes config map](https://kubernetes.io/docs/concepts/configuration/configmap/) changes. This is necessary when changing the\\r\\nPrometheus config, adding new scrape configs etc.\\r\\n\\r\\n---\\r\\n\\r\\n---\\r\\nauthors: dovholuknf\\r\\n---\\r\\n\\r\\n### Applying Zero Trust Networking Principles Using OpenZiti\\r\\n\\r\\nNow that we understand the basic setup and understand some possible problems, let\'s see if OpenZiti can address one or more of these\\r\\nissues. When applying OpenZiti, the goal will be to strengthen our security posture for each of the above items.\\r\\n\\r\\n#### Figure 2 - After OpenZiti\\r\\n\\r\\n![after](./kubernetes-prometheus-after.svg)\\r\\n\\r\\n### Taking a Closer Look After OpenZiti\\r\\n\\r\\n#### No External Listening Ports\\r\\n\\r\\nWith a classic deployment as shown in the initial design, we know there will be ports exposed to the open internet. In an ideal scenario,\\r\\nthere would be absolutely no ports exposed on the open internet **nor** in the \\"trusted networking zone\\". It\'s immediately obvious after\\r\\napplying a solution using OpenZiti that those listening ports exposed by the Kubernetes ingress controller are no longer deployed and thus\\r\\nare no longer exposed to the internet. That\'s one attack vector eliminated. OpenZiti will initiate outbound mTLS connections among all the\\r\\nconstituent pieces of the overlay network. This means connections will begin inside the trusted network zone and only create outbound \\r\\nlinks. Once established, those connections can be used to safely transfer data between any participating edge node.\\r\\n\\r\\nThis capability really can\'t be emphasized enough. With OpenZiti and with applications that use an OpenZiti SDK, such as the ones shown,\\r\\nthere are no open ports to attack. This network is nearly impervious to the classical \\"land and expand\\" technique so many bad actors \\r\\nlook to exploit.\\r\\n\\r\\n#### Kubernetes API no Longer Exposed\\r\\n\\r\\nAnother significant benefit provided by OpenZiti is starting to come into focus. By having access to our clusters provided \\r\\nthrough OpenZiti, we can **stop exposing** the Kubernetes APIs for both clusters to the open internet. Prometheus will still be able to \\r\\nmonitor each Kubernetes cluster through the private Kubernetes network. Accessing Prometheus will be provided via OpenZiti, instead of \\r\\nusing a Kubernetes ingress controller. Later, we can ues the built-in capability Prometheus already provides to federate information \\r\\nfrom the clusters to a centralized, [zitified](../index.md) Prometheus server.\\r\\n\\r\\nOnce no longer exposed to the open internet, to maintain our Kubernetes cluster we could then turn to [zitified]\\r\\n(../index.md) tools. The OpenZiti project provides zitified versions of `kubectl` -\\r\\n[kubeztl](https://github.com/openziti-incubator/kubectl) and `helm` -\\r\\n[helmz](https://github.com/openziti-incubator/helm). Each of these tools have an OpenZiti SDK embedded inside them. This allows both \\r\\ntools to connect to the private Kubernetes API over the OpenZiti overlay network. To use them, you will need a strong, OpenZiti identity \\r\\nas well as be authorized to access the service. Also note that we\'re also not replacing the existing security constraints the \\r\\nKubernetes ecosystem already provides. You can (and should) still secure your Kubernetes clusters using namespaces, roles, etc. \\r\\n\\r\\nWe\'ll explore `kubeztl` and `helmz` in future articles.\\r\\n\\r\\n#### \\"Trusted\\" Intra-cluster Traffic\\r\\n\\r\\nLastly, let\'s turn our eyes toward the traffic running inside the Kubernetes cluster. Pay attention to the lines in orange and the lines in\\r\\ndark blue. Orange lines represent \\"private\\" traffic, traffic that needs to traverse the private network space.\\r\\n\\r\\nAt this point we cannot send traffic to the Kubernetes API via the overlay network. The Kubernetes API doesn\'t have an OpenZiti SDK \\r\\nembedded within it. That means when we deploy Prometheus into ClusterA and ClusterB to monitor the cluster, Prometheus will be forced to \\r\\nconnect to a port exposed on the cluster\'s underlay network. Still, while not ideal, we have greatly improved the overall security \\r\\nposture of the cluster. We\'re no longer able to access the Kubernetes API without first gaining access to the zero trust overlay \\r\\nnetwork. Accessing the Kubernetes API will also require the identity to be properly authorized to access the service attaching to the \\r\\nKubernetes API. \\r\\n\\r\\nLet\'s now focus on ClusterA. It contains a Prometheus server that decided against listening on the OpenZiti overlay. This means it\\r\\nwill need to expose ports to the Kubernetes underlay network. The container inside the Prometheus pod will watch for configmap \\r\\nchanges. To trigger the webhook, it will be forced to send unauthenticated webhook traffic to the Prometheus server on the underlay \\r\\nnetwork in order to trigger the config to reload.\\r\\n\\r\\nStill, accessing this cluster and the listening Prometheus server will require being on the OpenZiti overlay. Also, this Prometheus \\r\\nserver does have an OpenZiti SDK built into it. We also deployed the \\"reflectz\\" workload with an OpenZiti SDK built into it as well. \\r\\nThat means the Prometheus server must scrape the \\"reflectz\\" workload exclusively over the OpenZiti overlay. **Only** authorized \\r\\nidentities can access that scrape data.\\r\\n\\r\\nContrast ClusterA with ClusterB. ClusterB deployed a Prometheus server with an embedded OpenZiti SDK and chose to provide its services\\r\\nexclusively on the OpenZiti overlay. We\'ve also deployed a zitified \\"reflectz\\" workload here. Notice how little traffic traverses the \\r\\nKubernetes cluster underlay network. The only traffic which needs to traverse the cluster\'s underlay network in ClusterB is the traffic \\r\\nwhich monitors the Kubernetes API. All other traffic in the cluster is now secured by the OpenZiti overlay network. You will\\r\\nneed a strong identity, and you will need to be authorized on the overlay before even being allowed to connect to the target service.\\r\\n\\r\\n## OpenZiti-Enabled Prometheus\\r\\n\\r\\nWe are now coming to the final piece of the puzzle. We have protected both Kubernetes clusters using OpenZiti. Now we want to bring all \\r\\nthis data back to a centralized Prometheus server to make it easier on our user base. To do this, we\'ll again deploy an OpenZiti-enabled\\r\\nPrometheus server. This time we don\'t care where it is deployed except that we know we are not deploying it into either of the Kubernetes\\r\\nclusters we are already using. Since the Prometheus servers are all now accessible via the overlay network, we can literally deploy our \\r\\nserver anywhere in the world. It could be on development server, it could be deployed in some other cloud, it could be deployed in our \\r\\nprivate data center. Because it\'s part of the overlay network, it no longer matters where we deploy the server. Wherever deployed, \\r\\nall it will need is outbound internet access, a strong identity, and access and authorization to services defined in the OpenZiti overlay \\r\\nnetwork. Once that\'s done, OpenZiti will take care of the rest.\\r\\n\\r\\nIf you have made it this far you\'re might want to try all this for yourself. The [next article](./part2.md) will go into the details\\r\\nnecessary to implement this solution. When complete you\'ll be able to deploy a zitified version of Prometheus and give Prometheus the power\\r\\nto scrape anything from anywhere using OpenZiti."},{"id":"/zitification/prometheus/part2","metadata":{"permalink":"/blog/zitification/prometheus/part2","source":"@site/blog/zitification/prometheus/part2.md","title":"Configuring OpenZiti to Enable Prometheus","description":"_This is part two of a three-part article. This article provides the technical deep dive into the steps necessary to implement the vision","date":"2023-01-26T20:49:40.000Z","formattedDate":"January 26, 2023","tags":[],"readingTime":19.16,"hasTruncateMarker":false,"authors":[{"name":"Clint Dovholuk","title":"OpenZiti Maintainer","url":"https://github.com/dovholuknf","imageURL":"https://avatars.githubusercontent.com/u/46322585?v=4","key":"dovholuknf"}],"frontMatter":{"authors":"dovholuknf"},"prevItem":{"title":"Enable Prometheus to Scrape Anything from Anywhere","permalink":"/blog/zitification/prometheus/part1"},"nextItem":{"title":"Scraping Anything, Anywhere in Action","permalink":"/blog/zitification/prometheus/part3"}},"content":"_This is part two of a three-part article. This article provides the technical deep dive into the steps necessary to implement the vision\\r\\noutlined in [part one](./part1.md). This article will be heavy on OpenZiti CLI commands, explaining what we are doing to configure the \\r\\noverlay network, and why. In [the final article](./part3.md), we will explore what we have just created and understand what was just \\r\\ncreated_\\r\\n\\r\\n---\\r\\n\\r\\n## Goals\\r\\n* Incredibly easy to deploy Prometheus servers\\r\\n* No ports exposed to the internet\\r\\n* Prometheus servers can be deployed listening on the overlay, not on the underlay\\r\\n* Private Kubernetes API\\r\\n\\r\\n## Zitified Prometheus\\r\\n\\r\\nAs described in [the previous article](./part1.md), Prometheus really prefers to be able to gather metrics from the targets it is\\r\\nmonitoring. When the target is behind a firewall, you will be left with two choices.\\r\\n![superhero](https://github.com/openziti/branding/raw/main/images/ziggy/svg/Ziggy%20The%20Superhero.svg)\\r\\nYou can choose to open a hole in the firewall granting access (a generally bad idea), or you can use a PushGateway. Even if you choose to\\r\\nuse the PushGateway, Prometheus will still need to be able to access and pull from the PushGateway so you\'ll still need some port open and\\r\\nlistening for Prometheus to collect data.\\r\\n\\r\\nWhat we really want is to enable Prometheus to scrape data from targets without needing to expose any ports to the internet. It would be **\\r\\neven better** if we didn\'t have to expose any ports at all, even to the local \\"trusted\\" network. This capability is something that is \\r\\nunique to an OpenZiti-enabled application. You can take an OpenZiti SDK and embed it into your application, and give your app zero trust \\r\\nsuperpowers! If we take an OpenZiti SDK and embed it into Prometheus, we can give Prometheus the superpower of invisibility and \\r\\naddressability. Embedding an OpenZiti SDK produces a [zitified](../index.md) version of Prometheus. With an \\r\\nOpenZiti-powered Prometheus, no ports need to be open.\\r\\n\\r\\nThe OpenZiti project has done the work to produce an OpenZiti-enabled version of Prometheus. It\'s also entirely open source. Check it out\\r\\nfrom the OpenZiti Test Kitchen hosted on GitHub https://github.com/openziti-test-kitchen/prometheus.\\r\\n\\r\\n## Solution Overview\\r\\n\\r\\nAs you\'ll recall from [part1](./part1.md), we are trying to use Prometheus to monitor workloads in two different \\r\\nKubernetes clusters. We are going to deploy one cluster which will represent a first step of an OpenZiti solution. \\r\\nIt will use a Prometheus sever which is OpenZiti-enabled, but it will still listen on the underlay network and be \\r\\navailable to local devices on an ip:port. This Prometheus server will use OpenZiti to scrape targets which \\r\\nare available anywhere on the OpenZiti overlay network and we\'ll refer to this as \\"ClusterA\\".\\r\\n\\r\\nWe\'ll also deploy a second OpenZiti-enabled Prometheus server, in a totally separate Kubernetes cluster. This \\r\\nPrometheus server will **not** listen on an ip:port. Instead, it will listen exclusively on the OpenZiti overlay. \\r\\nThis Prometheus server will have no ports available to attack and will only be accessible via a properly authorized \\r\\nand authenticated OpenZiti client. This will be our \\"ClusterB\\"\\r\\n\\r\\nFinally, we\'ll stand up a third Prometheus server and use it to federate metrics back to a \\"central\\" Prometheus \\r\\nserver. This emulates what one might do to provide a central location for humans to go to in order to visualize data \\r\\nor use the Prometheus server. We won\'t care where this is deployed, we\'ll actually deploy it in locally and then \\r\\nmove it to a private server in AWS just to show how easy it that is. \\r\\n\\r\\nThis is what the solution we\'ll build looks like:\\r\\n![after](./kubernetes-prometheus-after.svg)\\r\\n\\r\\n---\\r\\n\\r\\n## Digging In\\r\\n\\r\\nLet\'s get to work and build this solution. We\'ll need some legwork done first. \\r\\n\\r\\n> [!NOTE]\\r\\n> It\'s going to get deep in this article with CLI commands. You\'ll see what the OpenZiti objects are that get created and learn why. \\r\\n> You might not want to replicate the solution on your own and instead are looking for \\"the big reveal\\". If that describes you, just \\r\\n> skim this article lightly and get on to [part3](./part3.md). In part 3 we\'ll explore the deployed solution and see what makes it so \\r\\n> interesting and cool.\\r\\n\\r\\n### Prerequisites\\r\\n\\r\\n![construction worker](https://github.com/openziti/branding/raw/main/images/ziggy/svg/Ziggy%20The%20Construction%20Worker.svg)\\r\\n\\r\\n* You have an OpenZiti overlay network available. If not, for this scenario you will want to use \\r\\n[\\"host your own\\"](/docs/learn/quickstarts/network/hosted). You\'ll also want to have the ziti cli tool on your path\\r\\n* Two Kubernetes clusters provisioned\\r\\n* Necessary tooling installed and available on the path\\r\\n  * kubectl\\r\\n  * helm\\r\\n* bash/zsh shell - tested in bash and some commands will use variables. If you use another shell, change accordingly\\r\\n* a machine with [docker installed](https://docs.docker.com/get-docker/) to run the final Prometheus sever on (your local machine is fine)\\r\\n* Ziti Desktop Edge installed on the development machine. I use \\r\\n[Ziti Desktop Edge for Windows](https://github.com/openziti/desktop-edge-win/releases/latest/).\\r\\n* A temporary folder exists to house files as we need them: /tmp/prometheus\\r\\n\\r\\n---\\r\\n\\r\\n## ClusterA - Using `ziti-host`\\r\\n\\r\\n<img src=\\"./clusterA.svg\\" class=\\"flr\\"/>\\r\\n\\r\\nWe start with an empty OpenZiti network, and two empty Kubernetes clusters. Let\'s start by populating ClusterA. We will deploy three \\r\\npods into this Kubernetes cluster. When done, the Kubernetes cluster will look similar to the image to the right.\\r\\n\\r\\n* Pod 1. **ziti-host**. This pod will provide what is effectively the equivalent of a Kubernetes ingress controller. We\'ll install this \\r\\n  using helm from a NetFoundry provided chart\\r\\n* Pod 2. **prometheuz**. This pod will be our Prometheus server with OpenZiti embedded in it. We won\'t use OpenZiti to listen on the \\r\\n  overlay network. Instead, we will follow a more traditional model of listening on the underlay at a known ip:port combination. We\'ll \\r\\n  install this pod using a chart from the OpenZiti charts repository.\\r\\n* Pod 3. **reflectz**. This pod represents the workload which we want to monitor. This is another chart provided by the OpenZiti chart \\r\\n  repository and will also be installed with helm. If you are interested in viewing the source code for this project you can find it on \\r\\n  [GitHub here](https://github.com/nf-npieros/sdk-golang/tree/feature/reflect-prometheus)\\r\\n\\r\\n> [!NOTE]\\r\\n> Running the ziti cli commands shown below as shown will expect you to have the ziti binary on your path. Also it is expected that all \\r\\n> the commands run will run from the same \\"development\\" machine with the expected tools available. Reach out on discourse if you get stuck.\\r\\n\\r\\n### Pod 1 - `ziti-host`\\r\\n\\r\\nWe will start off deploying Pod 1, ziti-host, to provide access to Kubernetes ClusterA.  The ziti-host pod will require a single \\r\\nidentity to be provisioned. We will use a shortened name for the cluster and we\'ll embed that name into the identity to make it easier \\r\\nfor us to understand what identity we provisioned and why, should we ever need to reference these identities later.  We\'ll refer to \\r\\nClusterA as simply \\"kubeA\\". Let\'s make the identity now. Notice we are also passing the \\"-a\\" attribute during creation to add a role \\r\\nattribute to the identity of `kubeA.services`. This will be used later when setting up policies.\\r\\n\\r\\n#### Create the Identity\\r\\n\\r\\n```text\\r\\nziti edge create identity device kubeA.ziti.id -o /tmp/prometheus/kubeA.ziti.id.jwt -a \\"kubeA.services\\"\\r\\n```\\r\\n\\r\\nYou should see confirmation output such as:\\r\\n\\r\\n```text\\r\\nNew identity kubeA.ziti.id created with id: BeyyFUZFDR\\r\\nEnrollment expires at 2022-04-22T01:18:53.402Z\\r\\n```\\r\\n#### Deploy `ziti-host` into ClusterA\\r\\n\\r\\nOnce created, we can use helm to install the `ziti-host` pod. The jwt is a one-use token and will be useless after being consumed by \\r\\n`ziti-host`. As this is probably your first time running this helm chart, you will need to install it. The command is idempotent to \\r\\nrunning it over and over is of no concern. Run the following:\\r\\n\\r\\n```text\\r\\nhelm repo add netfoundry https://netfoundry.github.io/charts/\\r\\nhelm repo update\\r\\nhelm install ziti-host netfoundry/ziti-host --set-file enrollmentToken=\\"/tmp/prometheus/kubeA.ziti.id.jwt\\"\\r\\n```\\r\\n\\r\\nYou will see the confirmation output from helm. Now when you look at your Kubernetes cluster with `kubectl`, you will see a pod deployed:\\r\\n\\r\\n```text\\r\\nkubectl get pods\\r\\nNAME                        READY   STATUS    RESTARTS   AGE\\r\\nziti-host-db55b5c4b-rpc7f   1/1     Running   0          2m40s\\r\\n```\\r\\n\\r\\nAwesome, we have our first deployed pod. It\'s useless at the moment as we have defined no services, nor authorized any services. Right \\r\\nnow there\'s nothing to connect to, so we can simply move on and install the next pod, `reflectz`.\\r\\n\\r\\n### Pod 2 - `reflectz`\\r\\n\\r\\nThe first pod we want to have access to is the `reflectz` pod. It is a workload we will deploy that will do two things. First, it will \\r\\nlisten on the OpenZiti overlay network for connections. When a connection is made, and when bytes are sent, the workload sill simply \\r\\nreturn back to the caller whatever was sent to it adding \\"you sent me: \\" to the payload. It\'s not much, but it\'s a demo after all. The \\r\\nsecond service provided is a scrape target for Prometheus. There is one metric exposed by `reflectz` we will care about, the total number of connections established to this workload. This pod also needs an identity provisioned, and this time around we will also provision some services. We will also use the `ziti` cli to enroll this identity. This helm chart wants you to provide an enrolled identity as part of the helm command. Let\'s do all this now.\\r\\n\\r\\n#### Create and Enroll the Identity\\r\\n\\r\\n```text\\r\\nziti edge create identity user kubeA.reflect.id -o /tmp/prometheus/kubeA.reflect.id.jwt\\r\\nziti edge enroll /tmp/prometheus/kubeA.reflect.id.jwt -o /tmp/prometheus/kubeA.reflect.id.json\\r\\n```\\r\\n\\r\\n#### Create Configs and Services (including Tunneling-based Access)\\r\\n\\r\\nThe `reflectz` chart also needs two services to be declared and specified at the time of the helm chart installation. We will want to be \\r\\nable to test the service to ensure they work. To enable testing the services, we will create two configs of type `intercept.v1`. This \\r\\nwill allow identities using tunneling apps to be able to access the services, this is how we\'ll verify the services work. Make the \\r\\nconfigs and services now.\\r\\n\\r\\n```text\\r\\n# create intercept configs for the two services\\r\\nziti edge create config kubeA.reflect.svc-intercept.v1 intercept.v1 \\\\\\r\\n  \'{\\"protocols\\":[\\"tcp\\"],\\"addresses\\":[\\"kubeA.reflect.svc.ziti\\"],\\"portRanges\\":[{\\"low\\":80, \\"high\\":80}]}\'\\r\\nziti edge create config \\"kubeA.reflect.svc-intercept.v1.scrape\\" intercept.v1 \\\\\\r\\n  \'{\\"protocols\\":[\\"tcp\\"],\\"addresses\\":[\\"kubeA.reflect.scrape.svc.ziti\\"], \\"portRanges\\":[{\\"low\\":80, \\"high\\":80}], \\"dialOptions\\":{\\"identity\\":\\"kubeA.reflect.id\\"}}\'\\r\\n\\r\\n# create the two services\\r\\nziti edge create service \\"kubeA.reflect.svc\\" --configs \\"kubeA.reflect.svc-intercept.v1\\" -a \\"kubeA.reflect.svc.services\\"\\r\\nziti edge create service \\"kubeA.reflect.scrape.svc\\" --configs \\"kubeA.reflect.svc-intercept.v1.scrape\\"\\r\\n```\\r\\n\\r\\n#### Authorize the Workload and Clients\\r\\n\\r\\nServices are not valuable if there are no identities which can use the services. The identity used in the helm installation will also \\r\\nneed to be authorized to bind these services. Tunneling apps will need to be authorized to dial these services but also remember \\r\\nPrometheus servers will need to be able to dial these services too. We will now create `service-policies` to authorize the tunneling \\r\\nclients, Prometheus scrapes, and the `reflectz` server to bind the service.\\r\\n\\r\\n```text\\r\\n# create the bind service policies and authorize the reflect id to bind these services\\r\\nziti edge create service-policy \\"kubeA.reflect.svc.bind\\" Bind \\\\\\r\\n  --service-roles \\"@kubeA.reflect.svc\\" --identity-roles \\"@kubeA.reflect.id\\"\\r\\nziti edge create service-policy \\"kubeA.reflect.scrape.svc.bind\\" Bind \\\\\\r\\n  --service-roles \\"@kubeA.reflect.scrape.svc\\" --identity-roles \\"@kubeA.reflect.id\\"\\r\\n\\r\\n# create the dial service policies and authorize the reflect id to bind these services\\r\\nziti edge create service-policy \\"kubeA.reflect.svc.dial\\" Dial \\\\\\r\\n  --service-roles \\"@kubeA.reflect.svc\\" --identity-roles \\"#reflectz-clients\\"\\r\\nziti edge create service-policy \\"kubeA.reflect.svc.dial.scrape\\" Dial \\\\\\r\\n  --service-roles \\"@kubeA.reflect.scrape.svc\\" --identity-roles \\"#reflectz-clients\\"\\r\\n```\\r\\n\\r\\n#### Deploy `reflectz`\\r\\n\\r\\nWith the identity enrolled, we can now install the helm chart from openziti, and install our demonstration workload: `reflectz`. Notice \\r\\nthat to deploy `reflectz` we need to supply an identity to the workload using `--set-file reflectIdentity`. This identity will be used \\r\\nto \'Bind\' the services the workload exposes. We also need to define what the service names are we want to allow that identity to bind. \\r\\nWe do this using the `--set serviceName` and `--set prometheusServiceName` flags.\\r\\n\\r\\n```text\\r\\nhelm repo add openziti-test-kitchen https://openziti-test-kitchen.github.io/helm-charts/\\r\\nhelm repo update\\r\\nhelm install reflectz openziti-test-kitchen/reflect \\\\\\r\\n  --set-file reflectIdentity=\\"/tmp/prometheus/kubeA.reflect.id.json\\" \\\\\\r\\n  --set serviceName=\\"kubeA.reflect.svc\\" \\\\\\r\\n  --set prometheusServiceName=\\"kubeA.reflect.scrape.svc\\"\\r\\n```\\r\\n\\r\\nAfter running helm, pod 2 should be up and running. Let\'s take a look using `kubectl`\\r\\n\\r\\n```text\\r\\nkubectl get pods\\r\\nNAME                        READY   STATUS    RESTARTS   AGE\\r\\nreflectz-775bd45d86-4sjwh   1/1     Running   0          7s\\r\\nziti-host-db55b5c4b-rpc7f   1/1     Running   0          4m\\r\\n```\\r\\n\\r\\n### Pod 3 - `Prometheuz`\\r\\n\\r\\n#### Overlay Work - Setting Up OpenZiti\\r\\n\\r\\nNow we have access to the cluster and a workload to monitor. Now we want to deploy Prometheus and monitor this workload. Remember that \\r\\nthe workload only exposes a scrape target over the OpenZiti overlay. For Prometheus to be able to scrape the workload, even when \\r\\nresident inside the Kubernetes cluster (!), Prometheus will need to be OpenZiti-enabled. That will require a few things. We\'ll need a \\r\\nnew identity for Prometheus, we\'ll need to authorize Prometheus to access the workload\'s target, and we\'ll need to configure Prometheus \\r\\nto scrape that workload. When we create this identity we\'ll assign two attributes. The `reflectz-clients` attribute gives this identity \\r\\nthe ability to dial the two services defined above. The `prometheus-clients` attribute is currently unused. We\'ll put that to use later, \\r\\nbut we can define it now.\\r\\n\\r\\n#### Create and Enroll the Identity\\r\\n\\r\\n```text\\r\\n# create and enroll the identity.\\r\\nziti edge create identity user kubeA.prometheus.id -o /tmp/prometheus/kubeA.prometheus.id.jwt -a \\"reflectz-clients\\",\\"prometheus-clients\\"\\r\\nziti edge enroll /tmp/prometheus/kubeA.prometheus.id.jwt -o /tmp/prometheus/kubeA.prometheus.id.json\\r\\n```\\r\\n\\r\\n#### Create Configs and Services (including Tunneling-based Access)\\r\\n\\r\\n```text\\r\\n# create the config and service for the kubeA prometheus server\\r\\nziti edge create config \\"kubeA.prometheus.svc-intercept.v1\\" intercept.v1 \\\\\\r\\n  \'{\\"protocols\\":[\\"tcp\\"],\\"addresses\\":[\\"kubeA.prometheus.svc\\"],\\"portRanges\\":[{\\"low\\":80, \\"high\\":80}]}\'\\r\\nziti edge create config \\"kubeA.prometheus.svc-host.v1\\" host.v1 \\\\\\r\\n  \'{\\"protocol\\":\\"tcp\\", \\"address\\":\\"prometheuz-prometheus-server\\",\\"port\\":80}\'\\r\\nziti edge create service \\"kubeA.prometheus.svc\\" \\\\\\r\\n  --configs \\"kubeA.prometheus.svc-intercept.v1\\",\\"kubeA.prometheus.svc-host.v1\\"\\r\\n```\\r\\n\\r\\n#### Authorize the Workload and Clients\\r\\n\\r\\n```text\\r\\n# grant the prometheus clients the ability to dial the service and the kubeA.prometheus.id the ability to bind\\r\\nziti edge create service-policy \\"kubeA.prometheus.svc.dial\\" Dial \\\\\\r\\n  --service-roles \\"@kubeA.prometheus.svc\\" \\\\\\r\\n  --identity-roles \\"#prometheus-clients\\"\\r\\nziti edge create service-policy \\"kubeA.prometheus.svc.bind\\" Bind \\\\\\r\\n  --service-roles \\"@kubeA.prometheus.svc\\" \\\\\\r\\n  --identity-roles \\"@kubeA.ziti.id\\"\\r\\n```\\r\\n\\r\\n#### Deploying `Prometheuz` {#deploying-prometheuz-1}\\r\\n\\r\\nWith our services, configs and service-policies in place we are now ready to start our Prometheus server. Remember this server will not \\r\\nlisten on a the OpenZiti overlay. It\'s going to listen exclusively on the underlay. We are still exploring OpenZiti, and we are not yet\\r\\ncomfortable deploying our Prometheus server dark. We\'ll change this soon, don\'t worry. For now, we\'ll imagine that we\'re still \\r\\nevaluating the tech and chose to deploy it on the underlay, not on the overlay. \\r\\n\\r\\nAlthough Prometheus is listening on the underlay, we **have** deployed our workload listening on the overlay network. It won\'t be \\r\\navailable on the underlay at all. The workload has **no listening ports**. This means that we\'ll still need an OpenZiti-enabled \\r\\nPrometheus to access and scrape that workload. To do this we\'ll use helm, and use a chart provided by the OpenZiti charts repo.\\r\\n\\r\\nSome interesting things to notice below in the `helm install` command. Notice that we are passing helm two `--set` parameters. These \\r\\nparameters are informing the helm chart that the Prometheus server is not \\"zitified\\", meaning it will be accessible via the underlay \\r\\nnetwork. We\'re also passing one `--set-file` parameter to tell Prometheus what identity we want to be stored in the pod (as a secret). \\r\\nThis secret will be used when we configure Prometheus to scrape the workload. Go ahead and run this command now and run \\r\\n`kubectl get pods` until all the containers are running.\\r\\n\\r\\n```text\\r\\nhelm repo add openziti-test-kitchen https://openziti-test-kitchen.github.io/helm-charts/\\r\\nhelm repo update\\r\\nhelm install prometheuz openziti-test-kitchen/prometheus \\\\\\r\\n  --set server.ziti.enabled=\\"false\\" \\\\\\r\\n  --set-file server.scrape.id.contents=\\"/tmp/prometheus/kubeA.prometheus.id.json\\"\\r\\n```\\r\\n\\r\\n---\\r\\n\\r\\n## ClusterB - Fully Dark\\r\\n\\r\\n<img src=\\"./clusterB.svg\\" class=\\"flr\\"/>\\r\\n\\r\\nNow that we have deployed our first Kubernetes cluster, it\'s now time to deploy the second Kubernetes cluster. This time, we are going \\r\\nto keep our entire deployment **fully dark**! There will be no listening ports, not even local to the Kubernetes cluster itself. To get \\r\\nany traffic to this Prometheus server, you will need a strong identity and need to be authorized on the OpenZiti overlay. When complete, \\r\\nClusterB will look like the image to the right.\\r\\n\\r\\nThis time, \\"Pod1\\" will be the `reflectz` workload. Since this is a **fully dark** deployment, listening entirely on the OpenZiti overlay,\\r\\nwe won\'t need a `ziti-host` pod. Remember, in ClusterA `ziti-host` is used to provide internal access to the Kubernetes cluster via the\\r\\nOpenZiti overlay. It\'s similar in role to an ingress controller, but doesn\'t require you to expose your workloads to the internet. While\\r\\nthat\'s pretty good we want to go fully dark this time. We\'ll have no `ziti-host`. We\'ll only need to deploy two pods: `reflectz` and \\r\\n`prometheuz`.\\r\\n\\r\\nThe good news is that the same commands you\'ve run for ClusterA, will mostly be used for ClusterB. You will want to beware that where \\r\\nyou used \\"kubeA\\" before, make sure you change those to \\"kubeB\\". There will be small other changes we\'ll make along the way too, we\'ll see \\r\\nthose changes and explain them below. \\r\\n\\r\\n### Pod1 - `reflectz`\\r\\n\\r\\nThe `relectz` workload we\'ll deploy for ClusterB will be nearly identical to the ClusterA workload. We will create a service for \\r\\nthe actual \'reflect\' service. We will make a service for Prometheus to scrape the workload. We\'ll also need another identity, so \\r\\nwe\'ll create that identity, authorize it to bind the services, and authorize clients to access the workload. Since this process is very \\r\\nsimilar to what we did for ClusterA, there\'s not much to explain. Setup ClusterB\'s `reflectz` now.\\r\\n\\r\\n#### Create the Identity\\r\\n```text\\r\\nziti edge create identity user kubeB.reflect.id -o /tmp/prometheus/kubeB.reflect.id.jwt\\r\\nziti edge enroll /tmp/prometheus/kubeB.reflect.id.jwt -o /tmp/prometheus/kubeB.reflect.id.json\\r\\n```\\r\\n\\r\\n#### Create Configs and Services (including Tunneling-based Access)\\r\\n```text\\r\\n# create intercept configs for the two services\\r\\nziti edge create config kubeB.reflect.svc-intercept.v1 intercept.v1 \\\\\\r\\n  \'{\\"protocols\\":[\\"tcp\\"],\\"addresses\\":[\\"kubeB.reflect.svc.ziti\\"],\\"portRanges\\":[{\\"low\\":80, \\"high\\":80}]}\'\\r\\nziti edge create config \\"kubeB.reflect.svc-intercept.v1.scrape\\" intercept.v1 \\\\\\r\\n  \'{\\"protocols\\":[\\"tcp\\"],\\"addresses\\":[\\"kubeB.reflect.scrape.svc.ziti\\"], \\"portRanges\\":[{\\"low\\":80, \\"high\\":80}], \\"dialOptions\\":{\\"identity\\":\\"kubeB.reflect.id\\"}}\'\\r\\n\\r\\n# create the two services\\r\\nziti edge create service \\"kubeB.reflect.svc\\" --configs \\"kubeB.reflect.svc-intercept.v1\\" -a \\"kubeB.reflect.svc.services\\"\\r\\nziti edge create service \\"kubeB.reflect.scrape.svc\\" --configs \\"kubeB.reflect.svc-intercept.v1.scrape\\"\\r\\n```\\r\\n\\r\\n#### Authorize the Workload to Bind the Services\\r\\n```text\\r\\n# create the bind service policies and authorize the reflect id to bind these services\\r\\nziti edge create service-policy \\"kubeB.reflect.svc.bind\\" Bind \\\\\\r\\n  --service-roles \\"@kubeB.reflect.svc\\" --identity-roles \\"@kubeB.reflect.id\\"\\r\\nziti edge create service-policy \\"kubeB.reflect.scrape.svc.bind\\" Bind \\\\\\r\\n  --service-roles \\"@kubeB.reflect.scrape.svc\\" --identity-roles \\"@kubeB.reflect.id\\"\\r\\n```\\r\\n\\r\\n#### Authorize Clients to Access the Services\\r\\n```text\\r\\n# create the dial service policies and authorize the reflect id to bind these services\\r\\nziti edge create service-policy \\"kubeB.reflect.svc.dial\\" Dial \\\\\\r\\n  --service-roles \\"@kubeB.reflect.svc\\" --identity-roles \\"#reflectz-clients\\"\\r\\nziti edge create service-policy \\"kubeB.reflect.svc.dial.scrape\\" Dial \\\\\\r\\n  --service-roles \\"@kubeB.reflect.scrape.svc\\" --identity-roles \\"#reflectz-clients\\"\\r\\n  ```\\r\\n\\r\\n#### Deploy `reflectz` {#deploy-reflectz-1}\\r\\n```text\\r\\nhelm repo add openziti-test-kitchen https://openziti-test-kitchen.github.io/helm-charts/\\r\\nhelm repo update\\r\\nhelm install reflectz openziti-test-kitchen/reflect \\\\\\r\\n  --set-file reflectIdentity=\\"/tmp/prometheus/kubeB.reflect.id.json\\" \\\\\\r\\n  --set serviceName=\\"kubeB.reflect.svc\\" \\\\\\r\\n  --set prometheusServiceName=\\"kubeB.reflect.scrape.svc\\"\\r\\n```\\r\\n\\r\\n### Pod 2 - `Prometheuz`\\r\\n\\r\\nFor ClusterB we want `Prometheuz` to be **totally dark**. It will exclusively listen on the OpenZiti overlay and there will be no \\r\\nlistening ports on the underlay. We will need another identity, of course, and most of the configuration and commands appear the same on \\r\\nthe surface with very subtle differences. We\'ll explore these differences as we go. In this section we\'ll be making an identity, **one \\r\\nconfig** (a difference from the ClusterA install), a service, and two service-policies. Let\'s get to it.\\r\\n\\r\\n#### Create the Identity\\r\\n```text\\r\\nziti edge create identity user kubeB.prometheus.id -o /tmp/prometheus/kubeB.prometheus.id.jwt -a \\"reflectz-clients\\",\\"prometheus-clients\\"\\r\\nziti edge enroll /tmp/prometheus/kubeB.prometheus.id.jwt -o /tmp/prometheus/kubeB.prometheus.id.json\\r\\n```\\r\\n\\r\\n#### Create **One** Config and Service\\r\\nHere\'s a difference from ClusterA. Since we are going to listen on the OpenZiti overlay, we are not installing `ziti-host`. That means \\r\\nwe don\'t need to create a `host.v1` config. A `host.v1` config is necessary for services which have a \'Bind\' configuration and are being \\r\\nbound by a tunneling application. We\'re not doing that, here Prometheus will \'Bind\' this service, thus we don\'t need that `host.v1` \\r\\nconfig.\\r\\n```text\\r\\n# create the config and service for the kubeB prometheus server\\r\\nziti edge create config \\"kubeB.prometheus.svc-intercept.v1\\" intercept.v1 \\\\\\r\\n  \'{\\"protocols\\":[\\"tcp\\"],\\"addresses\\":[\\"kubeB.prometheus.svc\\"],\\"portRanges\\":[{\\"low\\":80, \\"high\\":80}], \\"dialOptions\\": {\\"identity\\":\\"kubeB.prometheus.id\\"}}\'\\r\\n# no need for the host.v1 config\\r\\nziti edge create service \\"kubeB.prometheus.svc\\" \\\\\\r\\n  --configs \\"kubeB.prometheus.svc-intercept.v1\\"\\r\\n```\\r\\n\\r\\n#### Authorize Clients and Prometheus to Bind the Service\\r\\n\\r\\nAt first, these commands appear identical. You need to look very closely to notice the difference between these command and the ones we \\r\\nran for ClusterA, other than the obvious changes from \\"kubeA\\" to \\"kubeB\\". Pay close attention to the supplied `--identity-roles` for the \\r\\nbind policy specified below. With ClusterA, we did not have Prometheus listen on the overlay and we allowed Prometheus to listen on the \\r\\nunderlay. That meant we needed to deploy `ziti-host` into that cluster to provide access to the service, and that means the service had \\r\\nto be bound by the `ziti-host` identity.\\r\\n\\r\\nHere we are flipping that script. We are allowing Prometheus to bind this service! That means we\'ll need to authorize the \\r\\n`kubeB.prometheus.id` to be able to bind the service.\\r\\n\\r\\n```text\\r\\n# grant the prometheus clients the ability to dial the service and the kubeB.prometheus.id the ability to bind\\r\\nziti edge create service-policy \\"kubeB.prometheus.svc.dial\\" Dial \\\\\\r\\n  --service-roles \\"@kubeB.prometheus.svc\\" \\\\\\r\\n  --identity-roles \\"#prometheus-clients\\"\\r\\nziti edge create service-policy \\"kubeB.prometheus.svc.bind\\" Bind \\\\\\r\\n  --service-roles \\"@kubeB.prometheus.svc\\" \\\\\\r\\n  --identity-roles \\"@kubeB.prometheus.id\\"\\r\\n```\\r\\n\\r\\n#### Deploying `Prometheuz`\\r\\n\\r\\nAt this point we have the OpenZiti overlay all configured. What\'s left, is to deploy Prometheus into ClusterB. This command is substantially\\r\\ndifferent from what we ran while deploying Prometheus into ClusterA. You\'ll see that we need to supply two other identities for this\\r\\ninstallation. Remember, Prometheus will be entirely dark once deployed into ClusterB, listening only on the OpenZiti overlay. The container\\r\\nin the pod which monitors configmap changes won\'t be able to trigger a webhook using the underlay! This `configmap-reloadz` is a second\\r\\n\\"zitification\\" we didn\'t realize we were deploying in ClusterA, because we did not need it. We need it for ClusterB.\\r\\n\\r\\nYou\'ll see for configmapReload we need to supply the identity which the container will use to hit the Prometheus webhook. We do that by \\r\\npassing `--set-file configmapReload.ziti.id.contents=\\"/tmp/prometheus/kubeB.prometheus.id.json\\"`. Then we\'ll supply the service which \\r\\n`configmap-reloadz` will dial, and we\'ll also specify what identity we expect to be hosting the service.\\r\\n\\r\\nNext you\'ll see we need to supply the identity to the Prometheus server we want to allow to listen on the OpenZiti overlay (\\r\\n`-set-file server.ziti.id.contents`). Similar to `configmap-reloadz` we will also specify the service and identity name to bind.\\r\\n\\r\\nFinally, to allow the server to scrape targets we need to supply a final identity which will be used when scraping targets with\\r\\n`--set-file server.scrape.id.contents`.\\r\\n\\r\\nYou\'ll notice for simplicities sake, we are using the same identity for all three needs which is perfectly fine. If you wanted to use a \\r\\ndifferent identity, you could. That choice is up to you. To keep it simple we just authorized this identity for all these purposes.\\r\\n\\r\\n```text\\r\\n# install prometheus\\r\\nhelm repo add openziti-test-kitchen https://openziti-test-kitchen.github.io/helm-charts/\\r\\nhelm repo update\\r\\nhelm install prometheuz openziti-test-kitchen/prometheus \\\\\\r\\n  --set-file configmapReload.ziti.id.contents=\\"/tmp/prometheus/kubeB.prometheus.id.json\\" \\\\\\r\\n       --set configmapReload.ziti.targetService=\\"kubeB.prometheus.svc\\" \\\\\\r\\n       --set configmapReload.ziti.targetIdentity=\\"kubeB.prometheus.id\\" \\\\\\r\\n  --set-file server.ziti.id.contents=\\"/tmp/prometheus/kubeB.prometheus.id.json\\" \\\\\\r\\n       --set server.ziti.service=\\"kubeB.prometheus.svc\\" \\\\\\r\\n       --set server.ziti.identity=\\"kubeB.prometheus.id\\" \\\\\\r\\n  --set-file server.scrape.id.contents=\\"/tmp/prometheus/kubeB.prometheus.id.json\\"\\r\\n```\\r\\n\\r\\n## What\'s Next\\r\\n\\r\\nIn this article we\'ve done a lot of OpenZiti CLI work, run some `kubectl` and `helm` commands but we still haven\'t explored what it is \\r\\nwe are building and why it\'s so cool. We\'ll do that in the [last, and final](./part3.md) article. Hopefully, the payoff for you will be \\r\\nas rewarding as it was for me while building this article series.\\r\\n\\r\\n---\\r\\n\\r\\n#### Addendum - a Quicker Start\\r\\n\\r\\nAll the commands above are also available in github as `.sh` scripts. If you would prefer, you can clone the \\r\\n[ziti-doc repository](https://github.com/openziti/ziti-doc) and access the scripts from the path mentioned below. \\"Cleanup\\" scripts are \\r\\nprovided if desired. \\r\\n\\r\\n```text\\r\\n${checkout_root}/docusaurus/blog/zitification/prometheus/scripts\\r\\n```"},{"id":"/zitification/prometheus/part3","metadata":{"permalink":"/blog/zitification/prometheus/part3","source":"@site/blog/zitification/prometheus/part3.md","title":"Scraping Anything, Anywhere in Action","description":"_This is part three of a three-part article. This article builds on the previous two articles. Here we will take a look at what we built","date":"2023-01-26T20:49:40.000Z","formattedDate":"January 26, 2023","tags":[],"readingTime":11.74,"hasTruncateMarker":false,"authors":[{"name":"Clint Dovholuk","title":"OpenZiti Maintainer","url":"https://github.com/dovholuknf","imageURL":"https://avatars.githubusercontent.com/u/46322585?v=4","key":"dovholuknf"}],"frontMatter":{"authors":"dovholuknf"},"prevItem":{"title":"Configuring OpenZiti to Enable Prometheus","permalink":"/blog/zitification/prometheus/part2"},"nextItem":{"title":"Zitifying SCP","permalink":"/blog/zitification/zitifying-scp"}},"content":"_This is part three of a three-part article. This article builds on the previous two articles. Here we will take a look at what we built \\r\\nand use it to explore the power of a zitified Prometheus. See [part one](./part1.md) for the necessary background about the series. See \\r\\n[part two](./part2.md) for detailed instructions covering how to setup the environment you\'re about to explore_\\r\\n\\r\\n## The Payoff\\r\\n\\r\\nOk. Here it is. We are at the end of the series and here is where we\'ll put it all together and really start to understand the sort of \\r\\ninnovations you can create when you zitify an application. As a reminder, we are working with [Prometheus](https://prometheus.io/), a \\r\\nCNCF project which we will use to monitor a workload deployed in two separate [Kubernetes](https://kubernetes.io) clusters. To save you \\r\\nfrom flipping back to a previous article, here is what that solution looks like.\\r\\n\\r\\n![overview](./kubernetes-prometheus-after.svg)\\r\\n\\r\\nNow we are ready to start using our Prometheus servers. We\'ll use our OpenZiti overlay network to connect to a workload which will \\r\\ngenerate a metric we want to display in Prometheus. We\'ll then configure Prometheus to scrape the workload and put it on a graph to \\r\\nprove it works. Once that\'s complete, we\'ll play around with the setup and see if we really can scrape anything, anywhere. Let\'s begin.\\r\\n\\r\\n## Developer Access\\r\\n\\r\\nIn the [previous article](./part2.md), we established our entire solution using the OpenZiti overlay, `kubectl` and `helm`. We saw \\r\\neverything get installed and it all \\"seems to work\\". But how do we **know** it works?  Let\'s provision an identity for yourself now and \\r\\nlet\'s enroll it in your local tunneling app and find out. Go out and get [a tunneling client](/docs/learn/core-concepts/clients/choose) running \\r\\nlocally. Once you have that installed, provision an identity and enroll it with your tunneling client. \\r\\n\\r\\n```text\\r\\nziti edge create identity user dev.client -a \\"prometheus-clients\\",\\"reflectz-clients\\"\\r\\n```\\r\\n\\r\\nYou should have access to six total services when this identity is enrolled:\\r\\n\\r\\n```text\\r\\nService Name: kubeA.prometheus.svc\\r\\n   Intercept: kubeA.prometheus.svc:80\\r\\nService Name: kubeA.reflect.svc\\r\\n   Intercept: kubeA.reflect.svc.ziti:80\\r\\nService Name: kubeA.reflect.scrape.svc\\r\\n   Intercept: kubeA.reflect.scrape.svc.ziti:80\\r\\n\\r\\nService Name: kubeB.prometheus.svc\\r\\n   Intercept: kubeB.prometheus.svc:80\\r\\nService Name: kubeB.reflect.svc\\r\\n   Intercept: kubeB.reflect.svc.ziti:80\\r\\nService Name: kubeB.reflect.scrape.svc\\r\\n   Intercept: kubeB.reflect.scrape.svc.ziti:80\\r\\n```\\r\\n\\r\\n## ClusterA\\r\\n\\r\\nWith your developer access you should be able to navigate your browser to http://kubea.prometheus.svc/targets. \\r\\n\\r\\n> [!NOTE]\\r\\n> We won\'t dwell on this for long in this article but notice that this is showing off another superpower of OpenZiti, private DNS. \\r\\n> Notice that you were able to browse to a totally fictitious domain name: kubea.prometheus.svc. \\".svc\\" is **not** a legitimate top level \\r\\n> domain. \\r\\n> [Look at the full list of top level domains starting with S](https://en.wikipedia.org/wiki/List_of_Internet_top-level_domains#S). You \\r\\n> won\'t find \\".svc\\" on that list at this time\\r\\n\\r\\n<img src=\\"./kubea.prom.init.png\\" class=\\"flr\\"/>\\r\\n\\r\\nYou should see the following. You might have noticed that the chart deployed has a few other containers we have not discussed yet. We\'ll \\r\\nnot go into those containers in this article. What\'s important is that this Prometheus server has a few targets already for us to access. \\r\\nNeat, but this isn\'t what we want to actually monitor.\\r\\n\\r\\nWhat we really want to monitor is the workload we deployed: `reflectz`. We can do this by editing the Prometheus configmap using \\r\\n`kubectl`. Let\'s go ahead and do this now:\\r\\n\\r\\n```text\\r\\nkubectl edit cm prometheuz-prometheus-server\\r\\n```\\r\\n\\r\\nThis will open an editor in your terminal and allow you to update the config map for the pod. Once the editor is open, find the section \\r\\nlabeled \\"scrape_config\\" and add the following entry:\\r\\n\\r\\n```text\\r\\n    - job_name: \'kubeA.reflectz\'\\r\\n      scrape_interval: 5s\\r\\n      honor_labels: true\\r\\n      scheme: \'ziti\'\\r\\n      params:\\r\\n        \'match[]\':\\r\\n          - \'{job!=\\"\\"}\'\\r\\n        \'ziti-config\':\\r\\n          - \'/etc/prometheus/scrape.json\'\\r\\n      static_configs:\\r\\n        - targets:\\r\\n          - \'kubeA.reflect.scrape.svc-kubeA.reflect.id\'\\r\\n```\\r\\n\\r\\nThis is yaml and yaml is sensitive to spaces. The block above is properly indented for the config that the helm chart installs. You \\r\\nshould be able to simply copy it and add it under the scrape_config. Remember, there is a `configmap-reload` container in \\r\\nthe pod which monitors the configmap. On successful edit, this container will notice and will issue a web hook to the \\r\\n`prometheus-server` container. The trigger is not immediate, don\'t worry if it takes a while. It can take around a minute for the \\r\\ntrigger to fire. \\r\\n\\r\\nWhile we wait for the trigger, let\'s explain what this is doing. This is informing the Prometheus server to monitor a workload which can \\r\\nbe found at the provided target of `kubeA.reflect.scrape.svc-kubeA.reflect.id`. Notice that no port is included in this target, and also \\r\\nnotice that this is a very strange looking FQDN. That\'s because this is a zitified version of Prometheus. We have extended Prometheus to \\r\\nunderstand a \\"scheme\\" of `ziti`. When we configure this job with a scheme of ziti, we can then supply targets to the job which represent \\r\\nan OpenZiti service.  We need to supply the `ziti-config` node with the path to the identity we want Prometheus to use to issue the \\r\\nscrape. This will always be `/etc/prometheus/scrape.json` at this time. Should the community desire it, we can look into changing the \\r\\nlocation of the identity.\\r\\n\\r\\nIf you would like to tail the `configmap-reloadz` container, you can issue this one liner. This will instruct `kubectl` to tail the logs \\r\\nfrom `configmap-reloadz`. \\r\\n\\r\\n```text\\r\\npod=$(kubectl get pods | grep server | cut -d \\" \\" -f1); echo POD: $pod; kubectl logs -f \\"$pod\\" prometheus-server-configmap-reload\\r\\n```\\r\\n\\r\\nWhen the trigger happens for ClusterA you will see a message like the one below. Notice that `configmap-reloadz` is using the underlay \\r\\nnetwork: `http://127.0.0.1:9090/-/reload`\\r\\n\\r\\n```text\\r\\n2022/04/23 20:01:23 config map updated\\r\\n2022/04/23 20:01:23 performing webhook request (1/1/http://127.0.0.1:9090/-/reload)\\r\\n2022/04/23 20:01:23 successfully triggered reload\\r\\n```\\r\\n\\r\\n### Config Reloaded\\r\\n\\r\\nOnce you\'ve correctly updated the configmap, and `configmap-reloadz` detected the change and told Prometheus to reload. You\'ll see a new \\r\\ntarget has been reported by Prometheus at http://kubea.prometheus.svc/targets. You should now see \\"kubeA.reflectz (1/1 up)\\" showing. \\r\\nCongratulations! You have just successfully scraped a target from zitified Prometheus! Remember this workload does not listen on the \\r\\nKubernetes underlay network. It\'s only accessible from the OpenZiti overlay. \\r\\n\\r\\n![kubea.target1.png](./kubea.target1.png)\\r\\n\\r\\n### Let\'s Graph It!\\r\\n\\r\\nCool, we have a target. The target can be scraped by Prometheus over the OpenZiti overlay. We\'re also able to securely access the \\r\\nPrometheus UI over the same OpenZiti overlay. Let\'s use the Prometheus UI to graph the data point we want to see, the\\r\\n`reflect_total_connections` metric. \\r\\n\\r\\n1. Navigate to http://kubea.prometheus.svc/graph\\r\\n2. enter `reflect_total_connections`\\r\\n3. click Graph (notice I changed my time to \'10s\', located just under Graph)\\r\\n4. click Execute\\r\\n5. Notice there are no connections (0)\\r\\n\\r\\n![grpah it](./kubea.graph.png)\\r\\n\\r\\n### Generate Some Data\\r\\n\\r\\n\\r\\nNow let\'s change that graph of `reflect_total_connections` from 0 to 1 (or more). One of the services you will have access to will \\r\\nintercept `kubeA.reflect.svc.ziti:80`. \\r\\n\\r\\n> [!NOTE]\\r\\n> If you are using Windows and Windows Subsystem for Linux (WSL) as I am, you **might** need to understand how get WSL to use your Ziti \\r\\n> Desktop Edge for Windows as your DNS resolver when inside WSL. Generally speaking this is as easy as editing /etc/resolv.conf and \\r\\n> adding the IP as the first nameserver: `nameserver 100.64.0.1` (or whatever the DNS IP is). Try it first, depending on how you setup \\r\\n> WSL it might \'just work\' for you. You can also just use cygwin or any other netcat tool from Windows (not WSL) too.\\r\\n\\r\\nNow we can use netcat to open a connection through this intercept a few times. The metric tracks the total number of connections to the \\r\\nreflect service. Connect, send some text, the use ctrl-c to disconnect. Do that a few times then click \'execute\' again on the graph page.\\r\\nYou can see I did this over a minute and moved my total count on kubeA to 8, shown below.\\r\\n\\r\\n```text\\r\\n/tmp/prometheus$ nc kubeA.reflect.svc.ziti 80\\r\\nkubeA reflect test\\r\\nyou sent me: kubeA reflect test\\r\\n^C\\r\\n/tmp/prometheus$ nc kubeA.reflect.svc.ziti 80\\r\\nanother reflect test\\r\\nyou sent me: another reflect test\\r\\n^C\\r\\n/tmp/prometheus$ nc kubeA.reflect.svc.ziti 80\\r\\nanother reflect test\\r\\nyou sent me: another reflect test\\r\\n^C\\r\\n```\\r\\n\\r\\n![kubea.more.total.conn.png](./kubea.more.total.conn.png)\\r\\n\\r\\n### Scrape Something Else\\r\\n\\r\\nHopefully you agree with me that this is pretty neat. Well what if we take it to the next level? What if we tried to scrape the \\r\\nworkload we deployed to ClusterB? Could we get that to work? Recall from above how we enabled the job named \'kubeA.reflectz\'. What if we \\r\\nsimply copied/pasted that into the configmap changing kubeA --\x3e kubeB. Would it work? Let\'s see. \\r\\n\\r\\n```text\\r\\n# edit the configmap on ClusterA:\\r\\nkubectl edit cm prometheuz-prometheus-server\\r\\n\\r\\n#add the job - and wait for the configmap to reload\\r\\n\\r\\n    - job_name: \'kubeB.reflectz\'\\r\\n      scrape_interval: 5s\\r\\n      honor_labels: true\\r\\n      scheme: \'ziti\'\\r\\n      params:\\r\\n        \'match[]\':\\r\\n          - \'{job!=\\"\\"}\'\\r\\n        \'ziti-config\':\\r\\n          - \'/etc/prometheus/scrape.json\'\\r\\n      static_configs:\\r\\n        - targets:\\r\\n          - \'kubeB.reflect.scrape.svc-kubeB.reflect.id\'\\r\\n```\\r\\n\\r\\nAfter watching the logs from `configmap-reloadz` on ClusterA and seeing the webhook trigger. Just go back to the Prometheus server in \\r\\nthe browser. You should be at the \'graph\' url but if not navigate back and execute another graph for `reflect_total_connections`. When \\r\\nwe do that it probably doesn\'t look much different but... Wait a second? In the legend? Can it be? That\'s right. From Kubernetes \\r\\nClusterA, we have just scraped a workload from Kubernetes ClusterB, entirely over the OpenZiti overlay.\\r\\n\\r\\n![kubeA-and-kubeB.png](./kubeA-and-kubeB.png)\\r\\n\\r\\nGenerate some data like you did before by running a few netcat connection/disconnects and click \'Execute\' again. Don\'t forget to send \\r\\nthe connection request to kubeB though!\\r\\n\\r\\n```text\\r\\nnc kubeB.reflect.svc.ziti 80\\r\\nthis is kubeb\\r\\nyou sent me: this is kubeb\\r\\n^C\\r\\nnc kubeB.reflect.svc.ziti 80\\r\\nanother to kube b\\r\\nyou sent me: another to kube b\\r\\n^C\\r\\nnc kubeB.reflect.svc.ziti 80\\r\\none more for fun and profit\\r\\nyou sent me: one more for fun and profit\\r\\n^C\\r\\n```\\r\\n\\r\\n![kubeB from kubeA](./kubeB-from-kubeA.png)\\r\\n\\r\\n## Scraping All the Things!\\r\\n\\r\\nBy now, you are probably starting to get the idea just how powerful this is for Prometheus. A zitified Prometheus can scrape things \\r\\neasily and natively by just deploying a `Prometheuz` instance into the location you want to scrape. Or, you can just enable a scrape \\r\\ntarget using a tunneling app, or in Kubernetes using the `ziti-host` helm chart.  Let\'s complete our vision now and stand up a \\r\\nPrometheus server on our local workstation using Docker.\\r\\n\\r\\nWhen we run `Prometheuz` locally using docker we\'ll need a config file to give to docker using a volume mount. We also provide the \\r\\nidentity used to connect to the OpenZiti overlay in the same fashion. Let\'s start up a docker container locally and see if we can grab \\r\\ndata from our two Prometheus instances using a locally deployed `Prometheuz` via docker.\\r\\n\\r\\nGitHub has a sample Prometheus [file you can download](https://raw.githubusercontent.com/openziti/ziti-doc/main/docusaurus/blog/zitification/prometheus/scripts/local.prometheus.yml).\\r\\nBelow, I used curl to download it and put it into the expected location.\\r\\n\\r\\n```text\\r\\ncurl -s https://raw.githubusercontent.com/openziti/ziti-doc/main/docusaurus/blog/zitification/prometheus/scripts/local.prometheus.yml > /tmp/prometheus/prometheus.config.yml\\r\\n\\r\\nziti edge create identity user local.prometheus.id -o /tmp/prometheus/local.prometheus.id.jwt -a \\"reflectz-clients\\",\\"prometheus-clients\\"\\r\\nziti edge enroll /tmp/prometheus/local.prometheus.id.jwt -o /tmp/prometheus/local.prometheus.id.json\\r\\n\\r\\ndocker run \\\\\\r\\n  -v /tmp/prometheus/local.prometheus.id.json:/etc/prometheus/ziti.id.json \\\\\\r\\n  -v /tmp/prometheus/prometheus.config.yml:/etc/prometheus/prometheus.yml \\\\\\r\\n  -p 9090:9090 \\\\\\r\\n  openziti/prometheuz\\r\\n```\\r\\n\\r\\n![local-docker-targets.png](./local-docker-targets.png)\\r\\n\\r\\nLook at what we\'ve just done. We have started a Prometheus instance locally, and used it to connect to four Prometheus targets via \\r\\nscrape configurations when all four targets are hidden entirely from my local computer (and any computer) unless the computer has an \\r\\nOpenZiti identity. I personally think that is incredibly cool!\\r\\n\\r\\n## Taking it to 11\\r\\n\\r\\nBut wait, I\'m not done. That docker instance is listening on an underlay network. It\'s exposed to attack by anything on my local network.\\r\\nI want to fix that too. Let\'s start this docker container up listening only on the OpenZiti overlay. Just like in [part 2](./part2.md) \\r\\nwe will make a config, a service and two policies to enable identities on the OpenZiti overlay.\\r\\n\\r\\n```text\\r\\ncurl -s https://raw.githubusercontent.com/openziti/ziti-doc/main/docusaurus/blog/zitification/prometheus/scripts/local.prometheus.yml > /tmp/prometheus/prometheus.config.yml\\r\\n\\r\\n# create the config and service for the local prometheus server\\r\\nziti edge create config \\"local.prometheus.svc-intercept.v1\\" intercept.v1 \\\\\\r\\n  \'{\\"protocols\\":[\\"tcp\\"],\\"addresses\\":[\\"local.prometheus.svc\\"],\\"portRanges\\":[{\\"low\\":80, \\"high\\":80}], \\"dialOptions\\": {\\"identity\\":\\"local.prometheus.id\\"}}\'\\r\\n\\r\\nziti edge create service \\"local.prometheus.svc\\" \\\\\\r\\n  --configs \\"local.prometheus.svc-intercept.v1\\"\\r\\n\\r\\n# grant the prometheus clients the ability to dial the service and the local.prometheus.id the ability to bind\\r\\nziti edge create service-policy \\"local.prometheus.svc.dial\\" Dial \\\\\\r\\n  --service-roles \\"@local.prometheus.svc\\" \\\\\\r\\n  --identity-roles \\"#prometheus-clients\\"\\r\\nziti edge create service-policy \\"local.prometheus.svc.bind\\" Bind \\\\\\r\\n  --service-roles \\"@local.prometheus.svc\\" \\\\\\r\\n  --identity-roles \\"@local.prometheus.id\\"\\r\\n```\\r\\n\\r\\nOnce that\'s done - let\'s see if we can start the docker container. The helm charts are configured to translate the `--set` flags \\r\\nprovided into \\"container friendly\\" settings like environment variables, volumes and mounts etc. In docker we need to provide those. If \\r\\nyou\'re familiar with docker these will probably all make sense. The most important part of the command below is the **lack** of a `-p` \\r\\nflag. The `-p` flag is used to expose a port from inside docker, outside docker. Look at the previous docker sample and you\'ll find we \\r\\nwere mapping local underlay port 9090 to port 9090 in the docker container. In this example, **we will do no such thing**! :)\\r\\n\\r\\n```text\\r\\ndocker run \\\\\\r\\n    -e ZITI_LISTENER_SERVICE_NAME=local.prometheus.svc \\\\\\r\\n    -e ZITI_LISTENER_IDENTITY_FILE=/etc/prometheus/ziti.server.json \\\\\\r\\n    -e ZITI_LISTENER_IDENTITY_NAME=local.prometheus.id \\\\\\r\\n    -v /tmp/prometheus/prometheus.config.yml:/etc/prometheus/prometheus.yml \\\\\\r\\n    -v /tmp/prometheus/local.prometheus.id.json:/etc/prometheus/ziti.id.json \\\\\\r\\n    -v /tmp/prometheus/local.prometheus.id.json:/etc/prometheus/ziti.server.json \\\\\\r\\n    openziti/prometheuz\\r\\n```\\r\\n\\r\\n### But - Does It Work?\\r\\n\\r\\nAfter configuring the OpenZiti overlay, we just need to open a browser and navigate to http://local.prometheus.svc/targets. SUCCESS!\\r\\n\\r\\n![local-docker-targets-no-listener.png](./local-docker-targets-no-listener.png)\\r\\n\\r\\n### SUCCESS!\\r\\n![local-docker-graph-no-listener.png](./local-docker-graph-no-listener.png)\\r\\n\\r\\n## Wrap Up\\r\\n\\r\\nThis was quite the journey and a lot of fun. We have taken a wildly popular open source project and brought OpenZiti to it with really \\r\\nnot much code at all. Then using OpenZiti we were able to give Prometheus superpowers and enable it to scrape any target regardless of \\r\\nwhere that target is or what network it is on. \\r\\n\\r\\nThink of the possibilities here. Are you a cloud provider looking to monitor your client\'s services which are deployed on-prem? That\'s \\r\\nso easy with OpenZiti and without sacrificing security **at all**. In fact, using OpenZiti like this provides amazing reach while \\r\\n**strengthening** the security posture of the solution because you\'re now using the concepts of\\r\\n[zero trust networking principles](https://en.wikipedia.org/wiki/Zero_trust_security_model) and applying them to your alerting and \\r\\nmonitoring solution.\\r\\n\\r\\nWhat do you think? Was this series interesting? Do you think OpenZiti is cool and you are looking to try it out? What are you going to \\r\\nzitify? Tell us on twitter or on discourse! Both links are included in this page. Let us know what you think! Go star the \\r\\n[openziti/ziti](http://github.com/openziti/ziti) repo and help us spread the word of OpenZiti to the world!"},{"id":"/zitification/zitifying-scp","metadata":{"permalink":"/blog/zitification/zitifying-scp","source":"@site/blog/zitification/zitifying-scp/index.md","title":"Zitifying SCP","description":"In the previous post we talked about how we could take a well-known application and improve its security by zitifying it, producing zssh. The logical next step after zitifying ssh would be to extend the functionality of zssh to cover moving files securely as well, enter zscp. A zitified scp effectively creates a more secure command line tool for sending and receiving files between ziti-empowered devices. Once zitified, we can use zscp using ziti identity names just like we did in zitifying ssh. I recommend reading the previous article) if you haven\'t to learn more about the benefits of zitifying tools like ssh and scp.","date":"2023-01-26T20:49:40.000Z","formattedDate":"January 26, 2023","tags":[],"readingTime":4.99,"hasTruncateMarker":false,"authors":[{"name":"Clint Dovholuk","title":"OpenZiti Maintainer","url":"https://github.com/dovholuknf","imageURL":"https://avatars.githubusercontent.com/u/46322585?v=4","key":"dovholuknf"}],"frontMatter":{"authors":"dovholuknf"},"prevItem":{"title":"Scraping Anything, Anywhere in Action","permalink":"/blog/zitification/prometheus/part3"},"nextItem":{"title":"`zscp` Cheat Sheet","permalink":"/blog/zitification/zitifying-scp/zscp-cheatsheat"}},"content":"In the [previous post][1] we talked about how we could take a well-known application and improve its security by zitifying it, producing `zssh`. The logical next step after zitifying `ssh` would be to extend the functionality of `zssh` to cover moving files securely as well, enter `zscp`. A zitified `scp` effectively creates a more secure command line tool for sending and receiving files between ziti-empowered devices. Once zitified, we can use `zscp` using ziti identity names just like we did in [zitifying ssh][1]. I recommend reading the [previous article][1]) if you haven\'t to learn more about the benefits of zitifying tools like `ssh` and `scp`.\\n\\n* * *\\n\\n## First Things First\\n\\n`zscp` functions with the same prerequisites as `zssh`:\\n\\n* Establish a [Ziti Network][2]\\n* Create and enroll two Ziti Endpoints (one for our `ssh` server, one for the client)\\n    * the `sshd` server will run `ziti-tunnel` for this demonstration. Conveniently it will run on the same machine I used to setup the [Ziti Network][3].\\n    * the client, in this case, is my local machine and I\'ll `zscp` files both to and from both the remote machine.\\n* Create the [Ziti Service][4] we\'ll use and authorize the two endpoints to use this service\\n* Use the `zscp` binary from the client side and the `ziti-tunnel` binary from the serving side to connect\\n* Harden `sshd` further by removing port 22 from any internet-based firewall configuration (for example, from within the security-groups wizard in AWS) or by forcing `sshd` to only listen on `localhost/127.0.0.1`\\n\\nAfter ensuring these steps are complete, you will have the ability to copy files across your Ziti Network. The traffic will be even more secure since now a Ziti Network is required for the connection, requiring that strong identity before even being able to access the `sshd` server. And of course now `sshd` is \'dark\' - it no longer needs the typical port 22 to be exposed to any network.\\n\\nGiven all the prerequisites are satisfied, we can put `zscp` to use. Simply download the binary for your platform:\\n\\n* [linux][5]\\n* [windows][6]\\n* [MacOs][7]\\n\\n<span></span>\\n\\n* * *\\n\\n## Sending and Receiving Files with Zscp\\n\\nOnce you have the executable downloaded, make sure it is named `zscp` and for simplicity\'s sake we\'ll assume it\'s on the path. Just like `zssh` to `ssh`, `zscp` provides the same basic functionality as `scp`. As with most tooling, executing the binary with no arguments will display the expected usage.\\n\\nThere are two main functions of `zscp`. Just like `scp` you can send and receive from the remote host.\\n\\nTo send files we use this basic syntax:\\n\\n```bash\\n./zscp LOCAL_FILEPATHS... <REMOTE_USERNAME>@TARGET_IDENTITY:REMOTE_FILEPATH\\n```\\n\\nThen, to retrieve remote files we use a similar syntax:\\n\\n```bash\\n./zscp <REMOTE_USERNAME>@TARGET_IDENTITY:REMOTE_FILEPATH LOCAL_FILEPATH\\n```\\n\\nBelow is a working example of using `zscp` to send a file to a remote machine. In this case the remote username is not the same as my local username. Just like with `scp`, I\'ll need to supply the username in my command and it will use the same syntax that regular `scp` uses. Here I am `zscp\'ing` as username `ubuntu` to the remote computer that is joined to the Ziti Network using the identity named `ziti-tunnel-aws`.\\n\\n```bash\\n./zscp local/1.txt ubuntu@ziti-tunnel-aws:remote\\nINFO    connection to edge router using token 6c2e8b79-ce8e-483e-a9f8-a930530e706a\\nINFO    sent file: /Users/name/local/1.txt ==> /home/ubuntu/remote/1.txt\\n```\\n\\nThis is only a basic example on how we can use `zscp` to send a singular file to a remote computer. In the next section, we will go over how to use `zscp` flags for extended functionality.\\n\\n* * *\\n\\n## Zscp Flags\\n\\nJust like `zssh`, `zscp` has the same flags to pass in: ssh key, ziti configuration file, service name, and one to toggle debug logging. All the defaults are the same as with `zssh`, thus both `zscp` and `zssh` will work without the `-i` and `-c` flag providing the files exist at the default locations. Refer to \\\\[zitifying-ssh\\\\]\\\\[2\\\\] for instructions on how to use the flags below.\\n\\n```bash\\n    -i, --SshKeyPath string   Path to ssh key. default: $HOME/.ssh/id_rsa\\n    -c, --ZConfig string      Path to ziti config file. default: $HOME/.ziti/zssh.json\\n    -d, --debug               pass to enable additional debug information\\n    -s, --service string      service name. (default \\"zssh\\")\\n```\\n\\nIn addition to the flags above, `zscp` has a flag to enable recursive copying:\\n\\n```bash\\n    -r, --recursive           pass to enable recursive file transfer\\n```\\n\\nTo use the recursive flag, you must input a directory into the `LOCAL_FILEPATH` argument. Just like `scp`, `zscp` will copy all file contents under the provided directory. You can see below how we can use the `-r` flag to send all contents of `big_directory`.\\n\\nContents of `big_directory` on local computer:\\n\\n```bash\\ntree local\\nlocal\\n\u2514\u2500\u2500 big_directory\\n    \u251c\u2500\u2500 1.txt\\n    \u251c\u2500\u2500 2.txt\\n    \u251c\u2500\u2500 3.txt\\n    \u251c\u2500\u2500 small_directory1\\n    \u2502   \u2514\u2500\u2500 4.txt\\n    \u251c\u2500\u2500 small_directory2\\n    \u2502   \u2514\u2500\u2500 5.txt\\n    \u2514\u2500\u2500 small_directory3\\n        \u2514\u2500\u2500 6.txt\\n```\\n\\nHere is the command and output:\\n\\n```bash\\n$ zscp -r big_directory ubuntu@ziti-tunnel-aws:remote\\nINFO    connection to edge router using token d6c268ee-e4f5-4836-bd38-2fc1558257aa\\nINFO    sent file: /Users/name/local/big_directory/1.txt ==> /home/ubuntu/remote/big_directory/1.txt\\nINFO    sent file: /Users/name/local/big_directory/2.txt ==> /home/ubuntu/remote/big_directory/2.txt\\nINFO    sent file: /Users/name/local/big_directory/3.txt ==> /home/ubuntu/remote/big_directory/3.txt\\nINFO    sent file: /Users/name/local/big_directory/small_directory1/4.txt ==> /home/ubuntu/remote/big_directory/small_directory1/4.txt\\nINFO    sent file: /Users/name/local/big_directory/small_directory2/5.txt ==> /home/ubuntu/remote/big_directory/small_directory2/5.txt\\nINFO    sent file: /Users/name/local/big_directory/small_directory3/6.txt ==> /home/ubuntu/remote/big_directory/small_directory3/6.txt\\n```\\n\\nAfter `zssh\'ing` to the remote machine, we can prove that all files have been transferred to remote device:\\n\\n```bash\\nubuntu@IP:~$ tree remote/\\nremote/\\n\u2514\u2500\u2500 big_directory\\n    \u251c\u2500\u2500 1.txt\\n    \u251c\u2500\u2500 2.txt\\n    \u251c\u2500\u2500 3.txt\\n    \u251c\u2500\u2500 small_directory1\\n    \u2502   \u2514\u2500\u2500 4.txt\\n    \u251c\u2500\u2500 small_directory2\\n    \u2502   \u2514\u2500\u2500 5.txt\\n    \u2514\u2500\u2500 small_directory3\\n        \u2514\u2500\u2500 6.txt\\n```\\n\\nRecursive copying also works to retrieve all contents of a directory on the remote machine.\\n\\n* * *\\n\\nI hope this post has helped you get familiar with another ziti-empowered developer\'s tool and hopefully it\'s becoming more clear why zitifying your application will make it more resilient to attack and make the act of connecting to remote services trivial.\\n\\nHave a look at the code over at [GitHub][8] or continue reading on to the next zitification - [kubectl][9]!\\n\\n[1]: /blog/zitification/zitifying-ssh/\\n\\n[2]: /docs/learn/quickstarts/network/hosted\\n\\n[3]: /docs/learn/introduction/\\n\\n[4]: /docs/learn/core-concepts/services/overview\\n\\n[5]: https://github.com/openziti-incubator/zssh/releases/latest/download/zscp-linux-amd64\\n\\n[6]: https://github.com/openziti-incubator/zssh/releases/latest/download/zscp-windows-amd64.exe\\n\\n[7]: https://github.com/openziti-incubator/zssh/releases/latest/download/zscp-macos-amd64\\n\\n[8]: https://github.com/openziti-incubator/zssh/tree/main/zssh/zscp\\n\\n[9]: /blog/zitification/kubernetes/"},{"id":"/zitification/zitifying-scp/zscp-cheatsheat","metadata":{"permalink":"/blog/zitification/zitifying-scp/zscp-cheatsheat","source":"@site/blog/zitification/zitifying-scp/zscp-cheatsheat.md","title":"`zscp` Cheat Sheet","description":"","date":"2023-01-26T20:49:40.000Z","formattedDate":"January 26, 2023","tags":[],"readingTime":0.985,"hasTruncateMarker":false,"authors":[{"name":"Clint Dovholuk","title":"OpenZiti Maintainer","url":"https://github.com/dovholuknf","imageURL":"https://avatars.githubusercontent.com/u/46322585?v=4","key":"dovholuknf"}],"frontMatter":{"authors":"dovholuknf"},"prevItem":{"title":"Zitifying SCP","permalink":"/blog/zitification/zitifying-scp"},"nextItem":{"title":"Zitifying SSH","permalink":"/blog/zitification/zitifying-ssh"}},"content":"```bash\\r\\n# establish some variables which are used below\\r\\nservice_name=zscpSvc\\r\\nclient_identity=\\"${service_name}\\"Client\\r\\nserver_identity=\\"${service_name}\\"Server\\r\\nthe_port=22\\r\\n\\r\\n# create two identities. one host - one client. Only necessary if you want/need them. Skippable if you\\r\\n# already have an identity. provided here to just \'make it easy\' to test/try\\r\\nziti edge create identity device \\"${server_identity}\\" -a \\"${service_name}\\"ServerEndpoints -o \\"${server_identity}\\".jwt\\r\\nziti edge create identity device \\"${client_identity}\\" -a \\"${service_name}\\"ClientEndpoints -o \\"${client_identity}\\".jwt\\r\\n\\r\\n# if you want to modify anything, often deleting the configs/services is easier than updating them\\r\\n# it\'s easier to delete all the items too - so until you understand exactly how ziti works, \\r\\n# make sure you clean them all up before making a change\\r\\nziti edge delete config \\"${service_name}\\"-host.v1\\r\\nziti edge delete config \\"${service_name}\\"-client-config\\r\\nziti edge delete service \\"${service_name}\\"\\r\\nziti edge delete service-policy \\"${service_name}\\"-binding\\r\\nziti edge delete service-policy \\"${service_name}\\"-dialing\\r\\n\\r\\nziti edge create config \\"${service_name}\\"-host.v1 host.v1 \'{\\"protocol\\":\\"tcp\\", \\"address\\":\\"localhost\\",\\"port\\":\'\\"${the_port}\\"\', \\"listenOptions\\": {\\"bindUsingEdgeIdentity\\":true}}\'# intercept is not needed for zscp/zssh but make it for testing if you like\\r\\nziti edge create config \\"${service_name}\\"-client-config intercept.v1 \'{\\"protocols\\":[\\"tcp\\"],\\"addresses\\":[\\"\'\\"${service_name}.ziti\\"\'\\"], \\"portRanges\\":[{\\"low\\":\'\\"${the_port}\\"\', \\"high\\":\\"\'${the_port}\\"\'}]}\'\\r\\nziti edge create service \\"${service_name}\\" --configs \\"${service_name}\\"-client-config,\\"${service_name}\\"-host.v1\\r\\nziti edge create service-policy \\"${service_name}\\"-binding Bind --service-roles \'@\'\\"${service_name}\\" --identity-roles \'#\'\\"${service_name}\\"\'ServerEndpoints\'\\r\\nziti edge create service-policy \\"${service_name}\\"-dialing Dial --service-roles \'@\'\\"${service_name}\\" --identity-roles \'#\'\\"${service_name}\\"\'ClientEndpoints\'\\r\\n\\r\\n```"},{"id":"/zitification/zitifying-ssh","metadata":{"permalink":"/blog/zitification/zitifying-ssh","source":"@site/blog/zitification/zitifying-ssh/index.md","title":"Zitifying SSH","description":"As we learned in the opening post, \\"zitifying\\" an application means to embed a Ziti SDK into an application and leverage the power of a Ziti Network to provide secure, truly zero-trust access to your application no matter where in the world that application goes. In this post we are going to see how we have zitified ssh and why. Future posts will expand on this even further by showing how NetFoundry uses zssh to support our customers.","date":"2023-01-26T20:49:40.000Z","formattedDate":"January 26, 2023","tags":[],"readingTime":7.885,"hasTruncateMarker":false,"authors":[{"name":"Clint Dovholuk","title":"OpenZiti Maintainer","url":"https://github.com/dovholuknf","imageURL":"https://avatars.githubusercontent.com/u/46322585?v=4","key":"dovholuknf"}],"frontMatter":{"authors":"dovholuknf"},"prevItem":{"title":"`zscp` Cheat Sheet","permalink":"/blog/zitification/zitifying-scp/zscp-cheatsheat"},"nextItem":{"title":"`zssh` Cheat Sheet","permalink":"/blog/zitification/zitifying-ssh/zssh-cheat-sheet"}},"content":"As we learned in the [opening post][1], \\"zitifying\\" an application means to embed a Ziti SDK into an application and leverage the power of a [Ziti Network][2] to provide secure, truly zero-trust access to your application no matter where in the world that application goes. In this post we are going to see how we have zitified `ssh` and why. Future posts will expand on this even further by showing how NetFoundry uses `zssh` to support our customers.\\r\\n\\r\\n<iframe width=\\"560\\" height=\\"315\\" src=\\"https://www.youtube.com/embed/WyZ8GRvtgGs\\" title=\\"YouTube video player\\" allow=\\"autoplay; picture-in-picture\\" allowfullscreen></iframe>\\r\\n\\r\\n* * *\\r\\n\\r\\n## Why SSH?\\r\\n\\r\\nAs I sit here typing these words, I can tell you\'re skeptical. I can tell you\'re wondering why in the world we would even attempt to mess with `ssh` at all. After all, `ssh` has been a foundation of the administration of not only home networks but also corporate networks and the internet itself. Surely if millions (billions?) of computers can interact every day safely and securely using `ssh` there is \\"no need\\" for us to be spending time zitifying `ssh` right? (Spoiler alert: wrong)\\r\\n\\r\\nI\'m sure you\'ve guessed that this is not the case whatsoever. After all, attackers don\'t leave `ssh` alone just because it\'s not worth it to try! Put a machine on the open internet, expose `ssh` on port 22 and watch for yourself all the attempts to access `ssh` using known default/weak/bad passwords flood in. Attacks don\'t only come from the internet either! Attacks from a single compromised machine on your network very well could behave in the same way as an outside attacker. This is particularly true for ransomware-style attacks as the compromised machine attempts to expand/multiply. The problems don\'t just stop here either. DoS attacks, other zero-day type bugs and more are all waiting for any service sitting on the open internet.\\r\\n\\r\\nA zitified `ssh` client is superior since the port used by `ssh` can be eliminated from the internet-based firewall preventing any connections whatsoever from any network client. In this configuration the `ssh` process is effectively \\"\\r\\ndark\\". The only way to `ssh` to a machine configured in this way is to have an identity authorized for that [Ziti Network][2].\\r\\n\\r\\nIt doesn\'t stop there though. A Ziti Network mandates the use of a strong identity. You cannot access any services defined in a [Ziti Network][2] without having gone through the enrollment process to create a strong identity used for bidirectional authentication and authorization. With Ziti, you can\'t even connect to SSH without first being authorized to connect to the remote SSH server.\\r\\n\\r\\nContrast that to SSH. With SSH you need access the sshd port before starting the authentication process. This requires the port to be exposed to the network, exposing it to attack. With SSH you are also usually allowed to authenticate without providing a strong identity using a username and password. Even if you are choosing to use the more secure pub/private key authentication for SSH, the remote machine still needed the public key added to the authorized_keys file before allowing connections to it via SSH. This is all-too-often a step which a human will do, making the process of authorizing a user or revoking access relatively cumbersome. Ziti provides a secure, centralized location to manage authorization of users to services. Ziti makes it trivial to grant or revoke access to a given set of services to users immediately.\\r\\n\\r\\nLastly, Ziti provides support for continual authorization through the use of policy checks. These policy checks run continuously. If a user suddenly fails to meet a particular policy, access to the services provided via the [Ziti Network][2] are revoked immediately.\\r\\n\\r\\nCool right? Let\'s see how we did it and how you can do the same thing using a [Ziti Network][2].\\r\\n\\r\\n#### Overview of SSH - notice how port 22 is open to inbound connections:\\r\\n\\r\\n![ssh-overview.svg](./ssh-overview.svg)\\r\\n\\r\\n* * *\\r\\n\\r\\n## How It\'s Done\\r\\n\\r\\nThere are a few steps necessary before being able to use `zssh`:\\r\\n\\r\\n* Establish a [Ziti Network][4]\\r\\n* Create and enroll two Ziti Endpoints (one for our `ssh` server, one for the client)\\r\\n    * the `sshd` server will run `ziti-tunnel` for this demonstration. Conveniently it will run on the same machine I used to setup the [Ziti Network][2].\\r\\n    * the client will run `zssh` from my local machine, and I\'ll `zssh` to the other endpoint\\r\\n* Create the [Ziti Service][5] we\'ll use and authorize the two endpoints to use this service\\r\\n* Use the `zssh` binary from the client side and the `ziti-tunnel` binary from the serving side to connect\\r\\n* Harden `sshd` further by removing port 22 from any internet-based firewall configuration (for example, from within the security-groups wizard in AWS) or by forcing `sshd` to only listen on `localhost/127.0.0.1`\\r\\n\\r\\n#### Overview of ZSSH - notice port 22 is no longer open to inbound connections:\\r\\n\\r\\n![zssh-overview.svg](./zssh-overview.svg)\\r\\n\\r\\nAfter performing these steps you\'ll have an `sshd` server that is dark to the internet. Accessing the server via `ssh`\\r\\nmust now occur using the Ziti Network. Since the service is no longer accessible directly through a network, it is no longer susceptible to the types of attacks mentioned previously!\\r\\n\\r\\n* * *\\r\\n\\r\\n## Zssh in Action\\r\\n\\r\\nOnce the prerequisites are satisfied, we can see `zssh` in action. Simply download the binary for your platform:\\r\\n\\r\\n* [linux][7]\\r\\n* [windows][8]\\r\\n* [MacOs][9]\\r\\n\\r\\nOnce you have the executable download, make sure it is named `zssh` and for simplicity\'s sake we\'ll assume it\'s on the path. A goal for `zssh` is to make the usage of the command very similar to the usage of `ssh`. Anyone familiar with `ssh` should be able to pick up `zssh` easily. As with most tooling, executing the binary with no arguments will display the expected usage. The general format when using `zssh` will be similar to that of `ssh`: `zssh <remoteUsername>@<targetIdentity>`\\r\\n\\r\\nBelow you can see me `zssh` from my local machine to the AWS machine secured by `ziti-tunnel`:\\r\\n\\r\\n```bash\\r\\n./zssh ubuntu@ziti-tunnel-aws\\r\\nINFO[0000] connection to edge router using token 95c45123-9415-49d6-930a-275ada9ae06f\\r\\nconnected.\\r\\nubuntu@ip-172-31-27-154:~$\\r\\n```\\r\\n\\r\\nIt really was that simple! Now let\'s break down the current flags for `zssh` and exactly how this worked.\\r\\n\\r\\n* * *\\r\\n\\r\\n## Zssh Flags\\r\\n\\r\\nWe know that `zssh` requires access to a [Ziti Network][2] but it is not clear from the example above is where `zzsh`\\r\\nfound the credentials required to access the network. `zssh` supports three basic flags:\\r\\n\\r\\n-i, --SshKeyPath string Path to ssh key. default: $HOME/.ssh/id_rsa -c, --ZConfig string Path to ziti config file. default: $HOME/.ziti/zssh.json -d, --debug pass to enable additional debug information -h, --help help for this command -s, --service string service name. default: zssh (default \\"zssh\\")\\r\\n\\r\\nWhat you see above is exactly the output `zssh` provides should you pass the `-h/--help` flag or execute `zssh` without any parameters. The `-i/--SshKeyPath` flag is congruent to the `-i` flag for `ssh`. You would use it to supply your key to the `ssh` client. Under the hood of `zssh` is a full-fledged `ssh` client that works similarly to how `ssh` does. If your `~/.ssh/id_rsa` file is in the `authorized_keys` of the remote machine, then you won\'t need to specify the `-i/`\\r\\nflag (as I didn\'t in my example). Using `zssh` requires the use of a public/private key in order for the `zssh` client to connect to the remote machine.\\r\\n\\r\\nThe `-c/--ZConfig` flag controls access to the network. A configuration file must be supplied to use `zssh` but does not need to be supplied as part of the command. By default, `zssh` will look at your home directory in a folder named `.ziti` for a file named `zssh.json`. In bash this is would be the equivalent of `$HOME`. In Windows this is the equivalent the environment variable named `USERPROFILE`. You do not need to supply this flag if a file exists at the default location. You can specify this flag to use `zssh` with other networks.\\r\\n\\r\\nThe `-s/--service` flag is for passing in a different service name other than \\"zssh\\". By default, the service name will be \\"zssh\\", but if you would like to access a different service use the `-s` flag followed by the service name.\\r\\n\\r\\nThe `-d/--debug` flag outputs additional information to assist you with debugging. For example:\\r\\n\\r\\n```bash\\r\\n$ ./zssh ubuntu@ziti-tunnel-aws -d\\r\\nINFO[0000]     sshKeyPath set to: /home/myUser/.ssh/id_rsa\\r\\nINFO[0000]        ZConfig set to: /home/myUser/.ziti/zssh.json\\r\\nINFO[0000]       username set to: ubuntu\\r\\nINFO[0000] targetIdentity set to: ziti-tunnel-aws\\r\\nINFO[0000] connection to edge router using token 95c45123-a234-412e-8997-96139fbd1938\\r\\nconnected.\\r\\nubuntu@ip-172-31-27-154:~$\\r\\n```\\r\\n\\r\\nShown above is also one additional piece of information, the remote username. Shown in the example above I have `zssh`ed to an ubuntu image in AWS. When it was provisioned AWS used the username `ubuntu`. In order to `zssh` to this machine I need to tell the remote `sshd` server that I wish to attach as the `ubuntu` user. If your username is the same for your local environment as the remote machine you do not need to specify the username. For example, my local username is `cd` (my initials). When I `zssh` to my dev machine I can simply use `zssh ClintLinux`:\\r\\n\\r\\n```bash\\r\\n$ ./zssh ClintLinux\\r\\nINFO[0000] connection to edge router using token 909dfb4f-fa83-4f73-af8e-ed251bcd30be\\r\\nconnected.\\r\\ncd@clint-linux-vm ~\\r\\n```\\r\\n\\r\\nHopefully this post has been helpful and insightful. Zitifying an application is *POWERFUL*!!!!\\r\\n\\r\\nThe next post in this series will cover how we extended the same code we used for `zssh` and [zitified scp][10].\\r\\n\\r\\nHave a look at the code over at [GitHub][11]\\r\\n\\r\\n[1]: /blog/zitification/\\r\\n\\r\\n[2]: /docs/learn/introduction/\\r\\n\\r\\n[3]: ./ssh-overview.svg\\r\\n\\r\\n[4]: /docs/learn/quickstarts/network/hosted\\r\\n\\r\\n[5]: /docs/learn/core-concepts/services/overview\\r\\n\\r\\n[6]: ./zssh-overview.svg\\r\\n\\r\\n[7]: https://github.com/openziti-incubator/zssh/releases/latest/download/zssh-linux-amd64\\r\\n\\r\\n[8]: https://github.com/openziti-incubator/zssh/releases/latest/download/zssh-windows-amd64.exe\\r\\n\\r\\n[9]: https://github.com/openziti-incubator/zssh/releases/latest/download/zssh-macos-amd64\\r\\n\\r\\n[10]: /blog/zitification/zitifying-scp/\\r\\n\\r\\n[11]: https://github.com/openziti-incubator/zssh/tree/main/zssh/zssh"},{"id":"/zitification/zitifying-ssh/zssh-cheat-sheet","metadata":{"permalink":"/blog/zitification/zitifying-ssh/zssh-cheat-sheet","source":"@site/blog/zitification/zitifying-ssh/zssh-cheat-sheet.md","title":"`zssh` Cheat Sheet","description":"","date":"2023-01-26T20:49:40.000Z","formattedDate":"January 26, 2023","tags":[],"readingTime":0.99,"hasTruncateMarker":false,"authors":[{"name":"Clint Dovholuk","title":"OpenZiti Maintainer","url":"https://github.com/dovholuknf","imageURL":"https://avatars.githubusercontent.com/u/46322585?v=4","key":"dovholuknf"}],"frontMatter":{"authors":"dovholuknf"},"prevItem":{"title":"Zitifying SSH","permalink":"/blog/zitification/zitifying-ssh"}},"content":"```bash\\r\\n# establish some variables which are used below\\r\\nservice_name=zsshSvc\\r\\nclient_identity=\\"${service_name}\\"Client\\r\\nserver_identity=\\"${service_name}\\"Server\\r\\nthe_port=22\\r\\n\\r\\n# create two identities. one host - one client. Only necessary if you want/need them. Skippable if you\\r\\n# already have an identity. provided here to just \'make it easy\' to test/try\\r\\nziti edge create identity device \\"${server_identity}\\" -a \\"${service_name}\\"ServerEndpoints -o \\"${server_identity}\\".jwt\\r\\nziti edge create identity device \\"${client_identity}\\" -a \\"${service_name}\\"ClientEndpoints -o \\"${client_identity}\\".jwt\\r\\n\\r\\n# if you want to modify anything, often deleting the configs/services is easier than updating them\\r\\n# it\'s easier to delete all the items too - so until you understand exactly how ziti works,\\r\\n# make sure you clean them all up before making a change\\r\\nziti edge delete config \\"${service_name}\\"-host.v1\\r\\nziti edge delete config \\"${service_name}\\"-client-config\\r\\nziti edge delete service \\"${service_name}\\"\\r\\nziti edge delete service-policy \\"${service_name}\\"-binding\\r\\nziti edge delete service-policy \\"${service_name}\\"-dialing\\r\\n\\r\\nziti edge create config \\"${service_name}\\"-host.v1 host.v1 \'{\\"protocol\\":\\"tcp\\", \\"address\\":\\"localhost\\",\\"port\\":\'\\"${the_port}\\"\', \\"listenOptions\\": {\\"bindUsingEdgeIdentity\\":true}}\'\\r\\n# intercept is not needed for zscp/zssh but make it for testing if you like\\r\\nziti edge create config \\"${service_name}\\"-client-config intercept.v1 \'{\\"protocols\\":[\\"tcp\\"],\\"addresses\\":[\\"\'\\"${service_name}.ziti\\"\'\\"], \\"portRanges\\":[{\\"low\\":\'\\"${the_port}\\"\', \\"high\\":\'\\"${the_port}\\"\'}]}\'\\r\\nziti edge create service \\"${service_name}\\" --configs \\"${service_name}\\"-client-config,\\"${service_name}\\"-host.v1\\r\\nziti edge create service-policy \\"${service_name}\\"-binding Bind --service-roles \'@\'\\"${service_name}\\" --identity-roles \'#\'\\"${service_name}\\"\'ServerEndpoints\'\\r\\nziti edge create service-policy \\"${service_name}\\"-dialing Dial --service-roles \'@\'\\"${service_name}\\" --identity-roles \'#\'\\"${service_name}\\"\'ClientEndpoints\'\\r\\n```"}]}')}}]);